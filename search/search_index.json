{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to Blind75py! This project provides a comprehensive resource for the Blind 75 LeetCode problems, a curated list of essential questions for mastering data structures and algorithms. Each problem includes: Clear Problem Statement: Understand the challenge at hand. Python Solution: Efficient and well-commented code. Detailed Explanation: A thorough breakdown of the logic, time, and space complexity. (Coming Soon) Visualizations: Where applicable, diagrams and illustrations to aid understanding. Explore Problems by Category We've organized the problems into logical categories to help you focus on specific areas: Arrays & Hashing Two Pointers Sliding Window Stack Binary Search Linked Lists Trees Tries Dynamic Programming Graphs Intervals Bit Manipulation Backtracking Getting Started To view this project locally, navigate to the Blind75py directory in your terminal and run: mkdocs serve Then, open your web browser and go to http://127.0.0.1:8000 . Happy coding!","title":"Home"},{"location":"#welcome-to-blind75py","text":"This project provides a comprehensive resource for the Blind 75 LeetCode problems, a curated list of essential questions for mastering data structures and algorithms. Each problem includes: Clear Problem Statement: Understand the challenge at hand. Python Solution: Efficient and well-commented code. Detailed Explanation: A thorough breakdown of the logic, time, and space complexity. (Coming Soon) Visualizations: Where applicable, diagrams and illustrations to aid understanding.","title":"Welcome to Blind75py!"},{"location":"#explore-problems-by-category","text":"We've organized the problems into logical categories to help you focus on specific areas: Arrays & Hashing Two Pointers Sliding Window Stack Binary Search Linked Lists Trees Tries Dynamic Programming Graphs Intervals Bit Manipulation Backtracking","title":"Explore Problems by Category"},{"location":"#getting-started","text":"To view this project locally, navigate to the Blind75py directory in your terminal and run: mkdocs serve Then, open your web browser and go to http://127.0.0.1:8000 . Happy coding!","title":"Getting Started"},{"location":"3sum/","text":"9. 3Sum Problem Statement Given an integer array nums , return all the triplets [nums[i], nums[j], nums[k]] such that i != j , i != k , and j != k , and nums[i] + nums[j] + nums[k] == 0 . Notice that the solution set must not contain duplicate triplets. Example 1: Input: nums = [-1,0,1,2,-1,-4] Output: [[-1,-1,2],[-1,0,1]] Explanation: nums[0] + nums[1] + nums[2] = (-1) + 0 + 1 = 0. nums[1] + nums[2] + nums[4] = 0 + 1 + (-1) = 0. nums[0] + nums[3] + nums[4] = (-1) + 2 + (-1) = 0. The distinct triplets are [-1,0,1] and [-1,-1,2]. Notice that the order of the output and the order of the triplets does not matter. Example 2: Input: nums = [0,1,1] Output: [] Explanation: The only possible triplet does not sum up to 0. Example 3: Input: nums = [0,0,0] Output: [[0,0,0]] Explanation: The only possible triplet sums up to 0. Solution class Solution : def threeSum ( self , nums : list [ int ]) -> list [ list [ int ]]: nums . sort () result = [] n = len ( nums ) for i in range ( n - 2 ): # Skip duplicate elements for the first number if i > 0 and nums [ i ] == nums [ i - 1 ]: continue left , right = i + 1 , n - 1 while left < right : total = nums [ i ] + nums [ left ] + nums [ right ] if total < 0 : left += 1 elif total > 0 : right -= 1 else : result . append ([ nums [ i ], nums [ left ], nums [ right ]]) # Skip duplicate elements for the second and third numbers while left < right and nums [ left ] == nums [ left + 1 ]: left += 1 while left < right and nums [ right ] == nums [ right - 1 ]: right -= 1 left += 1 right -= 1 return result Explanation This solution efficiently finds all unique triplets that sum to zero by first sorting the array. Sorting allows us to use the two-pointer technique. Sort the array: This is crucial for the two-pointer approach and for handling duplicates. Iterate through the array: We use a loop to fix the first number of the triplet ( nums[i] ). Two-Pointer Approach: For each nums[i] , we use two pointers, left and right , to find the other two numbers. left starts at i + 1 , and right starts at the end of the array. If the sum is less than zero, we need a larger sum, so we move left to the right. If the sum is greater than zero, we need a smaller sum, so we move right to the left. If the sum is zero, we've found a triplet. We add it to our result list. Skip Duplicates: After finding a valid triplet, we move both left and right pointers and also skip any duplicate elements to avoid adding the same triplet multiple times. The time complexity is dominated by the sorting step, which is O(n log n). The two-pointer scan is O(n^2) in the worst case. So, the overall time complexity is O(n^2). The space complexity is O(1) (or O(n) if you count the space for the output).","title":"3Sum"},{"location":"3sum/#9-3sum","text":"","title":"9. 3Sum"},{"location":"3sum/#problem-statement","text":"Given an integer array nums , return all the triplets [nums[i], nums[j], nums[k]] such that i != j , i != k , and j != k , and nums[i] + nums[j] + nums[k] == 0 . Notice that the solution set must not contain duplicate triplets. Example 1: Input: nums = [-1,0,1,2,-1,-4] Output: [[-1,-1,2],[-1,0,1]] Explanation: nums[0] + nums[1] + nums[2] = (-1) + 0 + 1 = 0. nums[1] + nums[2] + nums[4] = 0 + 1 + (-1) = 0. nums[0] + nums[3] + nums[4] = (-1) + 2 + (-1) = 0. The distinct triplets are [-1,0,1] and [-1,-1,2]. Notice that the order of the output and the order of the triplets does not matter. Example 2: Input: nums = [0,1,1] Output: [] Explanation: The only possible triplet does not sum up to 0. Example 3: Input: nums = [0,0,0] Output: [[0,0,0]] Explanation: The only possible triplet sums up to 0.","title":"Problem Statement"},{"location":"3sum/#solution","text":"class Solution : def threeSum ( self , nums : list [ int ]) -> list [ list [ int ]]: nums . sort () result = [] n = len ( nums ) for i in range ( n - 2 ): # Skip duplicate elements for the first number if i > 0 and nums [ i ] == nums [ i - 1 ]: continue left , right = i + 1 , n - 1 while left < right : total = nums [ i ] + nums [ left ] + nums [ right ] if total < 0 : left += 1 elif total > 0 : right -= 1 else : result . append ([ nums [ i ], nums [ left ], nums [ right ]]) # Skip duplicate elements for the second and third numbers while left < right and nums [ left ] == nums [ left + 1 ]: left += 1 while left < right and nums [ right ] == nums [ right - 1 ]: right -= 1 left += 1 right -= 1 return result","title":"Solution"},{"location":"3sum/#explanation","text":"This solution efficiently finds all unique triplets that sum to zero by first sorting the array. Sorting allows us to use the two-pointer technique. Sort the array: This is crucial for the two-pointer approach and for handling duplicates. Iterate through the array: We use a loop to fix the first number of the triplet ( nums[i] ). Two-Pointer Approach: For each nums[i] , we use two pointers, left and right , to find the other two numbers. left starts at i + 1 , and right starts at the end of the array. If the sum is less than zero, we need a larger sum, so we move left to the right. If the sum is greater than zero, we need a smaller sum, so we move right to the left. If the sum is zero, we've found a triplet. We add it to our result list. Skip Duplicates: After finding a valid triplet, we move both left and right pointers and also skip any duplicate elements to avoid adding the same triplet multiple times. The time complexity is dominated by the sorting step, which is O(n log n). The two-pointer scan is O(n^2) in the worst case. So, the overall time complexity is O(n^2). The space complexity is O(1) (or O(n) if you count the space for the output).","title":"Explanation"},{"location":"add_two_numbers/","text":"53. Add Two Numbers Problem Statement You are given two non-empty linked lists representing two non-negative integers. The digits are stored in reverse order , and each of their nodes contains a single digit. Add the two numbers and return the sum as a linked list. You may assume the two numbers do not contain any leading zero, except the number 0 itself. Example 1: Input: l1 = [2,4,3], l2 = [5,6,4] Output: [7,0,8] Explanation: 342 + 465 = 807. Example 2: Input: l1 = [0], l2 = [0] Output: [0] Example 3: Input: l1 = [9,9,9,9,9,9,9], l2 = [9,9,9,9] Output: [8,9,9,9,0,0,0,1] Solution # Definition for singly-linked list. class ListNode : def __init__ ( self , val = 0 , next = None ): self . val = val self . next = next class Solution : def addTwoNumbers ( self , l1 : ListNode , l2 : ListNode ) -> ListNode : dummy_head = ListNode ( 0 ) current = dummy_head carry = 0 while l1 or l2 or carry : val1 = l1 . val if l1 else 0 val2 = l2 . val if l2 else 0 total_sum = val1 + val2 + carry carry = total_sum // 10 digit = total_sum % 10 current . next = ListNode ( digit ) current = current . next if l1 : l1 = l1 . next if l2 : l2 = l2 . next return dummy_head . next Explanation This problem simulates the process of adding two numbers digit by digit, just like we do manually, but with the digits stored in reverse order in linked lists. Dummy Head: We create a dummy_head node. This is a common practice in linked list problems to simplify the handling of the first node of the result list. We also use a current pointer, initially pointing to dummy_head . carry Variable: We initialize a carry variable to 0, which will store any carry-over from the sum of digits. Iteration: We iterate using a while loop as long as there are still digits in l1 , l2 , or there is a carry remaining. Get Digit Values: In each iteration, we get the value of the current digit from l1 and l2 . If a list has been exhausted, we treat its value as 0. Calculate Sum and Carry: We calculate the total_sum of the two digit values and the carry from the previous step. The new carry is total_sum // 10 (integer division). The digit to be added to the result list is total_sum % 10 (the remainder). Create New Node: We create a new ListNode with this digit and append it to current.next . Advance Pointers: We then advance current to the newly created node, and also advance l1 and l2 to their next nodes if they exist. Return Result: After the loop finishes, dummy_head.next will point to the head of the resulting linked list. Time and Space Complexity: Time Complexity: O(max(m, n)), where m and n are the lengths of l1 and l2 respectively. We iterate through the longer of the two lists once. Space Complexity: O(max(m, n)), as the length of the new linked list will be at most max(m, n) + 1 (for a potential final carry).","title":"Add Two Numbers"},{"location":"add_two_numbers/#53-add-two-numbers","text":"","title":"53. Add Two Numbers"},{"location":"add_two_numbers/#problem-statement","text":"You are given two non-empty linked lists representing two non-negative integers. The digits are stored in reverse order , and each of their nodes contains a single digit. Add the two numbers and return the sum as a linked list. You may assume the two numbers do not contain any leading zero, except the number 0 itself. Example 1: Input: l1 = [2,4,3], l2 = [5,6,4] Output: [7,0,8] Explanation: 342 + 465 = 807. Example 2: Input: l1 = [0], l2 = [0] Output: [0] Example 3: Input: l1 = [9,9,9,9,9,9,9], l2 = [9,9,9,9] Output: [8,9,9,9,0,0,0,1]","title":"Problem Statement"},{"location":"add_two_numbers/#solution","text":"# Definition for singly-linked list. class ListNode : def __init__ ( self , val = 0 , next = None ): self . val = val self . next = next class Solution : def addTwoNumbers ( self , l1 : ListNode , l2 : ListNode ) -> ListNode : dummy_head = ListNode ( 0 ) current = dummy_head carry = 0 while l1 or l2 or carry : val1 = l1 . val if l1 else 0 val2 = l2 . val if l2 else 0 total_sum = val1 + val2 + carry carry = total_sum // 10 digit = total_sum % 10 current . next = ListNode ( digit ) current = current . next if l1 : l1 = l1 . next if l2 : l2 = l2 . next return dummy_head . next","title":"Solution"},{"location":"add_two_numbers/#explanation","text":"This problem simulates the process of adding two numbers digit by digit, just like we do manually, but with the digits stored in reverse order in linked lists. Dummy Head: We create a dummy_head node. This is a common practice in linked list problems to simplify the handling of the first node of the result list. We also use a current pointer, initially pointing to dummy_head . carry Variable: We initialize a carry variable to 0, which will store any carry-over from the sum of digits. Iteration: We iterate using a while loop as long as there are still digits in l1 , l2 , or there is a carry remaining. Get Digit Values: In each iteration, we get the value of the current digit from l1 and l2 . If a list has been exhausted, we treat its value as 0. Calculate Sum and Carry: We calculate the total_sum of the two digit values and the carry from the previous step. The new carry is total_sum // 10 (integer division). The digit to be added to the result list is total_sum % 10 (the remainder). Create New Node: We create a new ListNode with this digit and append it to current.next . Advance Pointers: We then advance current to the newly created node, and also advance l1 and l2 to their next nodes if they exist. Return Result: After the loop finishes, dummy_head.next will point to the head of the resulting linked list. Time and Space Complexity: Time Complexity: O(max(m, n)), where m and n are the lengths of l1 and l2 respectively. We iterate through the longer of the two lists once. Space Complexity: O(max(m, n)), as the length of the new linked list will be at most max(m, n) + 1 (for a potential final carry).","title":"Explanation"},{"location":"balanced_binary_tree/","text":"58. Balanced Binary Tree Problem Statement Given a binary tree, determine if it is height-balanced. For this problem, a height-balanced binary tree is defined as: a binary tree in which the left and right subtrees of every node differ in height by no more than 1. Example 1: Input: root = [3,9,20,null,null,15,7] Output: true Example 2: Input: root = [1,2,2,3,3,null,null,4,4] Output: false Example 3: Input: root = [] Output: true Solution # Definition for a binary tree node. class TreeNode : def __init__ ( self , val = 0 , left = None , right = None ): self . val = val self . left = left self . right = right class Solution : def isBalanced ( self , root : TreeNode ) -> bool : def dfs_height_check ( node ): if not node : return 0 # Height of an empty tree is 0 left_height = dfs_height_check ( node . left ) if left_height == - 1 : # Left subtree is unbalanced return - 1 right_height = dfs_height_check ( node . right ) if right_height == - 1 : # Right subtree is unbalanced return - 1 # Check if current node is balanced if abs ( left_height - right_height ) > 1 : return - 1 # Return the height of the current subtree return 1 + max ( left_height , right_height ) return dfs_height_check ( root ) != - 1 Explanation This problem can be solved efficiently using a recursive Depth-First Search (DFS) approach. The key is to check the balance condition while simultaneously calculating the height of each subtree. Core Idea: We need to check two things for each node: Its left subtree is balanced. Its right subtree is balanced. The absolute difference between the heights of its left and right subtrees is no more than 1. Recursive dfs_height_check Function: This function returns the height of the subtree rooted at node if it's balanced, and -1 if it's unbalanced. Base Case: If node is None , its height is 0, and it's considered balanced. Return 0. Recursive Calls: Recursively call dfs_height_check on the node.left to get left_height . Recursively call dfs_height_check on the node.right to get right_height . Check for Unbalanced Subtree: If left_height or right_height is -1 , it means one of the subtrees is already unbalanced. In this case, the entire tree rooted at node is also unbalanced, so we propagate the -1 up. Check Current Node's Balance: If both subtrees are balanced, we then check if the current node itself is balanced by comparing abs(left_height - right_height) . If the difference is greater than 1, return -1 . Return Height: If all checks pass, the current subtree is balanced, and its height is 1 + max(left_height, right_height) . Main Function: The isBalanced function simply calls dfs_height_check on the root and returns True if the result is not -1 , indicating a balanced tree. Time and Space Complexity: Time Complexity: O(N), where N is the number of nodes in the binary tree. Each node is visited exactly once. Space Complexity: O(H) in the worst case, where H is the height of the tree, due to the recursion stack. In a skewed tree, H can be N (O(N)), and in a balanced tree, H is log N (O(log N)).","title":"Balanced Binary Tree"},{"location":"balanced_binary_tree/#58-balanced-binary-tree","text":"","title":"58. Balanced Binary Tree"},{"location":"balanced_binary_tree/#problem-statement","text":"Given a binary tree, determine if it is height-balanced. For this problem, a height-balanced binary tree is defined as: a binary tree in which the left and right subtrees of every node differ in height by no more than 1. Example 1: Input: root = [3,9,20,null,null,15,7] Output: true Example 2: Input: root = [1,2,2,3,3,null,null,4,4] Output: false Example 3: Input: root = [] Output: true","title":"Problem Statement"},{"location":"balanced_binary_tree/#solution","text":"# Definition for a binary tree node. class TreeNode : def __init__ ( self , val = 0 , left = None , right = None ): self . val = val self . left = left self . right = right class Solution : def isBalanced ( self , root : TreeNode ) -> bool : def dfs_height_check ( node ): if not node : return 0 # Height of an empty tree is 0 left_height = dfs_height_check ( node . left ) if left_height == - 1 : # Left subtree is unbalanced return - 1 right_height = dfs_height_check ( node . right ) if right_height == - 1 : # Right subtree is unbalanced return - 1 # Check if current node is balanced if abs ( left_height - right_height ) > 1 : return - 1 # Return the height of the current subtree return 1 + max ( left_height , right_height ) return dfs_height_check ( root ) != - 1","title":"Solution"},{"location":"balanced_binary_tree/#explanation","text":"This problem can be solved efficiently using a recursive Depth-First Search (DFS) approach. The key is to check the balance condition while simultaneously calculating the height of each subtree. Core Idea: We need to check two things for each node: Its left subtree is balanced. Its right subtree is balanced. The absolute difference between the heights of its left and right subtrees is no more than 1. Recursive dfs_height_check Function: This function returns the height of the subtree rooted at node if it's balanced, and -1 if it's unbalanced. Base Case: If node is None , its height is 0, and it's considered balanced. Return 0. Recursive Calls: Recursively call dfs_height_check on the node.left to get left_height . Recursively call dfs_height_check on the node.right to get right_height . Check for Unbalanced Subtree: If left_height or right_height is -1 , it means one of the subtrees is already unbalanced. In this case, the entire tree rooted at node is also unbalanced, so we propagate the -1 up. Check Current Node's Balance: If both subtrees are balanced, we then check if the current node itself is balanced by comparing abs(left_height - right_height) . If the difference is greater than 1, return -1 . Return Height: If all checks pass, the current subtree is balanced, and its height is 1 + max(left_height, right_height) . Main Function: The isBalanced function simply calls dfs_height_check on the root and returns True if the result is not -1 , indicating a balanced tree. Time and Space Complexity: Time Complexity: O(N), where N is the number of nodes in the binary tree. Each node is visited exactly once. Space Complexity: O(H) in the worst case, where H is the height of the tree, due to the recursion stack. In a skewed tree, H can be N (O(N)), and in a balanced tree, H is log N (O(log N)).","title":"Explanation"},{"location":"binary_tree_level_order_traversal/","text":"62. Binary Tree Level Order Traversal Problem Statement Given the root of a binary tree, return the level order traversal of its nodes' values . (i.e., from left to right, level by level). Example 1: Input: root = [3,9,20,null,null,15,7] Output: [[3],[9,20],[15,7]] Example 2: Input: root = [1] Output: [[1]] Example 3: Input: root = [] Output: [] Solution from collections import deque # Definition for a binary tree node. class TreeNode : def __init__ ( self , val = 0 , left = None , right = None ): self . val = val self . left = left self . right = right class Solution : def levelOrder ( self , root : TreeNode ) -> list [ list [ int ]]: result = [] if not root : return result queue = deque ([ root ]) while queue : level_size = len ( queue ) current_level_nodes = [] for _ in range ( level_size ): node = queue . popleft () current_level_nodes . append ( node . val ) if node . left : queue . append ( node . left ) if node . right : queue . append ( node . right ) result . append ( current_level_nodes ) return result Explanation This problem is a classic application of Breadth-First Search (BFS). Core Idea: BFS explores a tree level by level. We use a queue to keep track of the nodes to visit. Initialization: Create an empty list result to store the level order traversal. If the root is None , return an empty result . Initialize a deque (double-ended queue) and add the root to it. Level-by-Level Traversal: The while queue: loop continues as long as there are nodes to visit. Inside the loop, we first get the level_size (the number of nodes currently in the queue). This is crucial because it tells us how many nodes belong to the current level. Create an empty list current_level_nodes to store the values of nodes at the current level. Iterate level_size times: Dequeue a node from the front of the queue . Append node.val to current_level_nodes . If the node has a left child, enqueue it. If the node has a right child, enqueue it. After processing all nodes at the current level, append current_level_nodes to the result . Return Result: Once the queue is empty, all nodes have been visited, and result contains the level order traversal. Time and Space Complexity: Time Complexity: O(N), where N is the number of nodes in the binary tree. Each node is visited and processed exactly once. Space Complexity: O(W) in the worst case, where W is the maximum width of the tree (the maximum number of nodes at any single level). In a complete binary tree, W can be N/2, so O(N). In a skewed tree, W is 1, so O(1).","title":"Binary Tree Level Order Traversal"},{"location":"binary_tree_level_order_traversal/#62-binary-tree-level-order-traversal","text":"","title":"62. Binary Tree Level Order Traversal"},{"location":"binary_tree_level_order_traversal/#problem-statement","text":"Given the root of a binary tree, return the level order traversal of its nodes' values . (i.e., from left to right, level by level). Example 1: Input: root = [3,9,20,null,null,15,7] Output: [[3],[9,20],[15,7]] Example 2: Input: root = [1] Output: [[1]] Example 3: Input: root = [] Output: []","title":"Problem Statement"},{"location":"binary_tree_level_order_traversal/#solution","text":"from collections import deque # Definition for a binary tree node. class TreeNode : def __init__ ( self , val = 0 , left = None , right = None ): self . val = val self . left = left self . right = right class Solution : def levelOrder ( self , root : TreeNode ) -> list [ list [ int ]]: result = [] if not root : return result queue = deque ([ root ]) while queue : level_size = len ( queue ) current_level_nodes = [] for _ in range ( level_size ): node = queue . popleft () current_level_nodes . append ( node . val ) if node . left : queue . append ( node . left ) if node . right : queue . append ( node . right ) result . append ( current_level_nodes ) return result","title":"Solution"},{"location":"binary_tree_level_order_traversal/#explanation","text":"This problem is a classic application of Breadth-First Search (BFS). Core Idea: BFS explores a tree level by level. We use a queue to keep track of the nodes to visit. Initialization: Create an empty list result to store the level order traversal. If the root is None , return an empty result . Initialize a deque (double-ended queue) and add the root to it. Level-by-Level Traversal: The while queue: loop continues as long as there are nodes to visit. Inside the loop, we first get the level_size (the number of nodes currently in the queue). This is crucial because it tells us how many nodes belong to the current level. Create an empty list current_level_nodes to store the values of nodes at the current level. Iterate level_size times: Dequeue a node from the front of the queue . Append node.val to current_level_nodes . If the node has a left child, enqueue it. If the node has a right child, enqueue it. After processing all nodes at the current level, append current_level_nodes to the result . Return Result: Once the queue is empty, all nodes have been visited, and result contains the level order traversal. Time and Space Complexity: Time Complexity: O(N), where N is the number of nodes in the binary tree. Each node is visited and processed exactly once. Space Complexity: O(W) in the worst case, where W is the maximum width of the tree (the maximum number of nodes at any single level). In a complete binary tree, W can be N/2, so O(N). In a skewed tree, W is 1, so O(1).","title":"Explanation"},{"location":"binary_tree_right_side_view/","text":"66. Binary Tree Right Side View Problem Statement Given the root of a binary tree, imagine yourself standing on the right side of it, return the values of the nodes you can see ordered from top to bottom . Example 1: Input: root = [1,2,3,null,5,null,4] Output: [1,3,4] Example 2: Input: root = [1,null,3] Output: [1,3] Example 3: Input: root = [] Output: [] Solution from collections import deque # Definition for a binary tree node. class TreeNode : def __init__ ( self , val = 0 , left = None , right = None ): self . val = val self . left = left self . right = right class Solution : def rightSideView ( self , root : TreeNode ) -> list [ int ]: result = [] if not root : return result queue = deque ([ root ]) while queue : level_size = len ( queue ) # The last node in the current level is the rightmost node rightmost_node_val = None for i in range ( level_size ): node = queue . popleft () rightmost_node_val = node . val # Update with current node's value if node . left : queue . append ( node . left ) if node . right : queue . append ( node . right ) result . append ( rightmost_node_val ) return result Explanation This problem can be solved using a Level Order Traversal (BFS). The key insight is that for each level of the tree, the rightmost node is the last node processed in that level during a BFS traversal. Initialization: Create an empty list result to store the right side view. If the root is None , return an empty result . Initialize a deque (double-ended queue) and add the root to it. Level-by-Level Traversal (BFS): The while queue: loop continues as long as there are nodes to visit. Inside the loop, we first get the level_size (the number of nodes currently in the queue). This tells us how many nodes belong to the current level. We initialize rightmost_node_val to None for each level. Iterate level_size times: Dequeue a node from the front of the queue . Update rightmost_node_val with the node.val . Since we are processing nodes from left to right within a level, the last node processed will be the rightmost one. If the node has a left child, enqueue it. If the node has a right child, enqueue it. After processing all nodes at the current level, append the rightmost_node_val to the result . Return Result: Once the queue is empty, all nodes have been visited, and result contains the right side view. Time and Space Complexity: Time Complexity: O(N), where N is the number of nodes in the binary tree. Each node is visited and processed exactly once. Space Complexity: O(W) in the worst case, where W is the maximum width of the tree (the maximum number of nodes at any single level). In a complete binary tree, W can be N/2, so O(N). In a skewed tree, W is 1, so O(1).","title":"Binary Tree Right Side View"},{"location":"binary_tree_right_side_view/#66-binary-tree-right-side-view","text":"","title":"66. Binary Tree Right Side View"},{"location":"binary_tree_right_side_view/#problem-statement","text":"Given the root of a binary tree, imagine yourself standing on the right side of it, return the values of the nodes you can see ordered from top to bottom . Example 1: Input: root = [1,2,3,null,5,null,4] Output: [1,3,4] Example 2: Input: root = [1,null,3] Output: [1,3] Example 3: Input: root = [] Output: []","title":"Problem Statement"},{"location":"binary_tree_right_side_view/#solution","text":"from collections import deque # Definition for a binary tree node. class TreeNode : def __init__ ( self , val = 0 , left = None , right = None ): self . val = val self . left = left self . right = right class Solution : def rightSideView ( self , root : TreeNode ) -> list [ int ]: result = [] if not root : return result queue = deque ([ root ]) while queue : level_size = len ( queue ) # The last node in the current level is the rightmost node rightmost_node_val = None for i in range ( level_size ): node = queue . popleft () rightmost_node_val = node . val # Update with current node's value if node . left : queue . append ( node . left ) if node . right : queue . append ( node . right ) result . append ( rightmost_node_val ) return result","title":"Solution"},{"location":"binary_tree_right_side_view/#explanation","text":"This problem can be solved using a Level Order Traversal (BFS). The key insight is that for each level of the tree, the rightmost node is the last node processed in that level during a BFS traversal. Initialization: Create an empty list result to store the right side view. If the root is None , return an empty result . Initialize a deque (double-ended queue) and add the root to it. Level-by-Level Traversal (BFS): The while queue: loop continues as long as there are nodes to visit. Inside the loop, we first get the level_size (the number of nodes currently in the queue). This tells us how many nodes belong to the current level. We initialize rightmost_node_val to None for each level. Iterate level_size times: Dequeue a node from the front of the queue . Update rightmost_node_val with the node.val . Since we are processing nodes from left to right within a level, the last node processed will be the rightmost one. If the node has a left child, enqueue it. If the node has a right child, enqueue it. After processing all nodes at the current level, append the rightmost_node_val to the result . Return Result: Once the queue is empty, all nodes have been visited, and result contains the right side view. Time and Space Complexity: Time Complexity: O(N), where N is the number of nodes in the binary tree. Each node is visited and processed exactly once. Space Complexity: O(W) in the worst case, where W is the maximum width of the tree (the maximum number of nodes at any single level). In a complete binary tree, W can be N/2, so O(N). In a skewed tree, W is 1, so O(1).","title":"Explanation"},{"location":"climbing_stairs/","text":"16. Climbing Stairs Problem Statement You are climbing a staircase. It takes n steps to reach the top. Each time you can either climb 1 or 2 steps. In how many distinct ways can you climb to the top? Example 1: Input: n = 2 Output: 2 Explanation: There are two ways to climb to the top. 1. 1 step + 1 step 2. 2 steps Example 2: Input: n = 3 Output: 3 Explanation: There are three ways to climb to the top. 1. 1 step + 1 step + 1 step 2. 1 step + 2 steps 3. 2 steps + 1 step Solution class Solution : def climbStairs ( self , n : int ) -> int : if n <= 2 : return n # We only need to store the last two values one_step_before = 2 two_steps_before = 1 all_ways = 0 for _ in range ( 2 , n ): all_ways = one_step_before + two_steps_before two_steps_before = one_step_before one_step_before = all_ways return all_ways Explanation This is a classic dynamic programming problem that turns out to be the Fibonacci sequence. Let dp[i] be the number of ways to reach the i -th step. To reach step i , you could have come from step i-1 (by taking one step) or from step i-2 (by taking two steps). Therefore, the total number of ways to reach step i is the sum of the ways to reach step i-1 and the ways to reach step i-2 . This gives us the recurrence relation: dp[i] = dp[i-1] + dp[i-2] . This is the same as the Fibonacci sequence. dp[1] = 1 (1 way to reach the first step) dp[2] = 2 (2 ways: 1+1 or 2) dp[3] = dp[2] + dp[1] = 2 + 1 = 3 The provided solution is an optimized version of this. Instead of storing the entire dp array, we only need to keep track of the last two values ( one_step_before and two_steps_before ), which correspond to dp[i-1] and dp[i-2] . This reduces the space complexity to O(1) while maintaining an O(n) time complexity.","title":"Climbing Stairs"},{"location":"climbing_stairs/#16-climbing-stairs","text":"","title":"16. Climbing Stairs"},{"location":"climbing_stairs/#problem-statement","text":"You are climbing a staircase. It takes n steps to reach the top. Each time you can either climb 1 or 2 steps. In how many distinct ways can you climb to the top? Example 1: Input: n = 2 Output: 2 Explanation: There are two ways to climb to the top. 1. 1 step + 1 step 2. 2 steps Example 2: Input: n = 3 Output: 3 Explanation: There are three ways to climb to the top. 1. 1 step + 1 step + 1 step 2. 1 step + 2 steps 3. 2 steps + 1 step","title":"Problem Statement"},{"location":"climbing_stairs/#solution","text":"class Solution : def climbStairs ( self , n : int ) -> int : if n <= 2 : return n # We only need to store the last two values one_step_before = 2 two_steps_before = 1 all_ways = 0 for _ in range ( 2 , n ): all_ways = one_step_before + two_steps_before two_steps_before = one_step_before one_step_before = all_ways return all_ways","title":"Solution"},{"location":"climbing_stairs/#explanation","text":"This is a classic dynamic programming problem that turns out to be the Fibonacci sequence. Let dp[i] be the number of ways to reach the i -th step. To reach step i , you could have come from step i-1 (by taking one step) or from step i-2 (by taking two steps). Therefore, the total number of ways to reach step i is the sum of the ways to reach step i-1 and the ways to reach step i-2 . This gives us the recurrence relation: dp[i] = dp[i-1] + dp[i-2] . This is the same as the Fibonacci sequence. dp[1] = 1 (1 way to reach the first step) dp[2] = 2 (2 ways: 1+1 or 2) dp[3] = dp[2] + dp[1] = 2 + 1 = 3 The provided solution is an optimized version of this. Instead of storing the entire dp array, we only need to keep track of the last two values ( one_step_before and two_steps_before ), which correspond to dp[i-1] and dp[i-2] . This reduces the space complexity to O(1) while maintaining an O(n) time complexity.","title":"Explanation"},{"location":"clone_graph/","text":"27. Clone Graph Problem Statement Given a reference of a node in a connected undirected graph. Return a deep copy (clone) of the graph. Each node in the graph contains a value ( int ) and a list ( List[Node] ) of its neighbors. class Node { public int val; public List<Node> neighbors; } Test case format: For simplicity, each node's value is the same as the node's index (1-indexed). For example, the first node with val == 1 , the second node with val == 2 , and so on. The graph is represented in the test case using an adjacency list. Adjacency list is a collection of unordered lists used to represent a finite graph. Each list describes the set of neighbors of a node in the graph. The given node will always be the first node with val = 1 . You must return the copy of the given node as a reference to the cloned graph. Example 1: Input: adjList = [[2,4],[1,3],[2,4],[1,3]] Output: [[2,4],[1,3],[2,4],[1,3]] Explanation: The original graph and its clone have the same adjacency list. Example 2: Input: adjList = [[]] Output: [[]] Explanation: Note that the input contains one empty list. The graph consists of only one node with val = 1 and it does not have any neighbors. Example 3: Input: adjList = [] Output: [] Explanation: This represents an empty graph. There are no nodes in this graph. Solution \"\"\" # Definition for a Node. class Node: def __init__(self, val = 0, neighbors = None): self.val = val self.neighbors = neighbors if neighbors is not None else [] \"\"\" class Solution : def cloneGraph ( self , node : 'Node' ) -> 'Node' : if not node : return None # A hash map to store the mapping from original nodes to their copies old_to_new = {} def dfs ( original_node ): # If we have already cloned this node, return the clone if original_node in old_to_new : return old_to_new [ original_node ] # Create a new node (the copy) copy_node = Node ( original_node . val ) old_to_new [ original_node ] = copy_node # Recursively clone all the neighbors for neighbor in original_node . neighbors : copy_node . neighbors . append ( dfs ( neighbor )) return copy_node return dfs ( node ) Explanation To create a deep copy of a graph, we need to traverse the entire graph and create a new copy for each node and each edge. A simple traversal (like DFS or BFS) is not enough, as we might get stuck in cycles or re-process nodes. The key is to use a hash map (dictionary) to keep track of the nodes that have already been copied. This map, old_to_new , will store the mapping from an original node to its corresponding new, cloned node. The algorithm works as follows (using Depth-First Search - DFS): Base Case: If the input node is None , we return None . old_to_new Map: This map is the core of the solution. Before cloning a node, we check if it's already in our map. DFS Traversal: The dfs function takes an original node as input. Check the map: If the original node is already in old_to_new , it means we've already created its copy. We simply return the copy from the map. This prevents infinite loops in graphs with cycles. Create a copy: If the node is not in the map, we create a new Node with the same value. Update the map: We immediately add the mapping from the original node to our new copy in the old_to_new map. This is crucial to do before traversing its neighbors. Clone neighbors: We then iterate through all the neighbors of the original node. For each neighbor, we make a recursive call to dfs . The return value of this call (which is the cloned neighbor) is appended to the neighbors list of our copy_node . Return: The initial call to dfs(node) starts the process, and it will eventually return the head of the new, cloned graph. This approach ensures that each node is copied exactly once. The time complexity is O(N + E), where N is the number of nodes and E is the number of edges, as we visit each node and edge once. The space complexity is O(N) for the old_to_new map and the recursion stack.","title":"Clone Graph"},{"location":"clone_graph/#27-clone-graph","text":"","title":"27. Clone Graph"},{"location":"clone_graph/#problem-statement","text":"Given a reference of a node in a connected undirected graph. Return a deep copy (clone) of the graph. Each node in the graph contains a value ( int ) and a list ( List[Node] ) of its neighbors. class Node { public int val; public List<Node> neighbors; } Test case format: For simplicity, each node's value is the same as the node's index (1-indexed). For example, the first node with val == 1 , the second node with val == 2 , and so on. The graph is represented in the test case using an adjacency list. Adjacency list is a collection of unordered lists used to represent a finite graph. Each list describes the set of neighbors of a node in the graph. The given node will always be the first node with val = 1 . You must return the copy of the given node as a reference to the cloned graph. Example 1: Input: adjList = [[2,4],[1,3],[2,4],[1,3]] Output: [[2,4],[1,3],[2,4],[1,3]] Explanation: The original graph and its clone have the same adjacency list. Example 2: Input: adjList = [[]] Output: [[]] Explanation: Note that the input contains one empty list. The graph consists of only one node with val = 1 and it does not have any neighbors. Example 3: Input: adjList = [] Output: [] Explanation: This represents an empty graph. There are no nodes in this graph.","title":"Problem Statement"},{"location":"clone_graph/#solution","text":"\"\"\" # Definition for a Node. class Node: def __init__(self, val = 0, neighbors = None): self.val = val self.neighbors = neighbors if neighbors is not None else [] \"\"\" class Solution : def cloneGraph ( self , node : 'Node' ) -> 'Node' : if not node : return None # A hash map to store the mapping from original nodes to their copies old_to_new = {} def dfs ( original_node ): # If we have already cloned this node, return the clone if original_node in old_to_new : return old_to_new [ original_node ] # Create a new node (the copy) copy_node = Node ( original_node . val ) old_to_new [ original_node ] = copy_node # Recursively clone all the neighbors for neighbor in original_node . neighbors : copy_node . neighbors . append ( dfs ( neighbor )) return copy_node return dfs ( node )","title":"Solution"},{"location":"clone_graph/#explanation","text":"To create a deep copy of a graph, we need to traverse the entire graph and create a new copy for each node and each edge. A simple traversal (like DFS or BFS) is not enough, as we might get stuck in cycles or re-process nodes. The key is to use a hash map (dictionary) to keep track of the nodes that have already been copied. This map, old_to_new , will store the mapping from an original node to its corresponding new, cloned node. The algorithm works as follows (using Depth-First Search - DFS): Base Case: If the input node is None , we return None . old_to_new Map: This map is the core of the solution. Before cloning a node, we check if it's already in our map. DFS Traversal: The dfs function takes an original node as input. Check the map: If the original node is already in old_to_new , it means we've already created its copy. We simply return the copy from the map. This prevents infinite loops in graphs with cycles. Create a copy: If the node is not in the map, we create a new Node with the same value. Update the map: We immediately add the mapping from the original node to our new copy in the old_to_new map. This is crucial to do before traversing its neighbors. Clone neighbors: We then iterate through all the neighbors of the original node. For each neighbor, we make a recursive call to dfs . The return value of this call (which is the cloned neighbor) is appended to the neighbors list of our copy_node . Return: The initial call to dfs(node) starts the process, and it will eventually return the head of the new, cloned graph. This approach ensures that each node is copied exactly once. The time complexity is O(N + E), where N is the number of nodes and E is the number of edges, as we visit each node and edge once. The space complexity is O(N) for the old_to_new map and the recursion stack.","title":"Explanation"},{"location":"coin_change/","text":"17. Coin Change Problem Statement You are given an integer array coins representing coins of different denominations and an integer amount representing a total amount of money. Return the fewest number of coins that you need to make up that amount . If that amount of money cannot be made up by any combination of the coins, return -1 . You may assume that you have an infinite number of each kind of coin. Example 1: Input: coins = [1,2,5], amount = 11 Output: 3 Explanation: 11 = 5 + 5 + 1 Example 2: Input: coins = [2], amount = 3 Output: -1 Example 3: Input: coins = [1], amount = 0 Output: 0 Solution class Solution : def coinChange ( self , coins : list [ int ], amount : int ) -> int : # Create a DP array to store the minimum coins for each amount # Initialize with a value larger than any possible number of coins dp = [ float ( 'inf' )] * ( amount + 1 ) dp [ 0 ] = 0 for i in range ( 1 , amount + 1 ): for coin in coins : if i - coin >= 0 : dp [ i ] = min ( dp [ i ], dp [ i - coin ] + 1 ) return dp [ amount ] if dp [ amount ] != float ( 'inf' ) else - 1 Explanation This is a classic dynamic programming problem. We create a dp array where dp[i] will store the minimum number of coins required to make the amount i . Initialization: We initialize the dp array with a large value (infinity) to represent that the amounts are not yet reachable. dp[0] is set to 0 because it takes 0 coins to make an amount of 0. Bottom-Up Calculation: We iterate from amount 1 up to the target amount . For each amount i , we iterate through our available coins . DP Relation: If a coin is less than or equal to the current amount i , we can potentially use this coin. The number of coins to make i would be dp[i - coin] + 1 . We take the minimum of this value and the current dp[i] . dp[i] = min(dp[i], dp[i - coin] + 1) Final Result: After filling the dp array, dp[amount] will hold the minimum number of coins for the target amount. If it's still infinity, it means the amount is unreachable, so we return -1. The time complexity is O(amount * n), where n is the number of coins, because of the nested loops. The space complexity is O(amount) for the dp array.","title":"Coin Change"},{"location":"coin_change/#17-coin-change","text":"","title":"17. Coin Change"},{"location":"coin_change/#problem-statement","text":"You are given an integer array coins representing coins of different denominations and an integer amount representing a total amount of money. Return the fewest number of coins that you need to make up that amount . If that amount of money cannot be made up by any combination of the coins, return -1 . You may assume that you have an infinite number of each kind of coin. Example 1: Input: coins = [1,2,5], amount = 11 Output: 3 Explanation: 11 = 5 + 5 + 1 Example 2: Input: coins = [2], amount = 3 Output: -1 Example 3: Input: coins = [1], amount = 0 Output: 0","title":"Problem Statement"},{"location":"coin_change/#solution","text":"class Solution : def coinChange ( self , coins : list [ int ], amount : int ) -> int : # Create a DP array to store the minimum coins for each amount # Initialize with a value larger than any possible number of coins dp = [ float ( 'inf' )] * ( amount + 1 ) dp [ 0 ] = 0 for i in range ( 1 , amount + 1 ): for coin in coins : if i - coin >= 0 : dp [ i ] = min ( dp [ i ], dp [ i - coin ] + 1 ) return dp [ amount ] if dp [ amount ] != float ( 'inf' ) else - 1","title":"Solution"},{"location":"coin_change/#explanation","text":"This is a classic dynamic programming problem. We create a dp array where dp[i] will store the minimum number of coins required to make the amount i . Initialization: We initialize the dp array with a large value (infinity) to represent that the amounts are not yet reachable. dp[0] is set to 0 because it takes 0 coins to make an amount of 0. Bottom-Up Calculation: We iterate from amount 1 up to the target amount . For each amount i , we iterate through our available coins . DP Relation: If a coin is less than or equal to the current amount i , we can potentially use this coin. The number of coins to make i would be dp[i - coin] + 1 . We take the minimum of this value and the current dp[i] . dp[i] = min(dp[i], dp[i - coin] + 1) Final Result: After filling the dp array, dp[amount] will hold the minimum number of coins for the target amount. If it's still infinity, it means the amount is unreachable, so we return -1. The time complexity is O(amount * n), where n is the number of coins, because of the nested loops. The space complexity is O(amount) for the dp array.","title":"Explanation"},{"location":"combination_sum/","text":"21. Combination Sum Problem Statement Given an array of distinct integers candidates and a target integer target , return a list of all unique combinations of candidates where the chosen numbers sum to target . You may return the combinations in any order . The same number may be chosen from candidates an unlimited number of times . Two combinations are unique if the frequency of at least one of the chosen numbers is different. The test cases are generated such that the number of unique combinations that sum up to target is less than 150 combinations for the given input. Example 1: Input: candidates = [2,3,6,7], target = 7 Output: [[2,2,3],[7]] Explanation: 2 and 3 are candidates, and 2 + 2 + 3 = 7. Note that 2 can be used multiple times. 7 is a candidate, and 7 = 7. These are the only two combinations. Example 2: Input: candidates = [2,3,5], target = 8 Output: [[2,2,2,2],[2,3,3],[3,5]] Example 3: Input: candidates = [2], target = 1 Output: [] Solution class Solution : def combinationSum ( self , candidates : list [ int ], target : int ) -> list [ list [ int ]]: result = [] def backtrack ( remaining , combination , start ): if remaining == 0 : # Found a valid combination result . append ( list ( combination )) return if remaining < 0 : # Exceeded the target return for i in range ( start , len ( candidates )): # Add the number to the current combination combination . append ( candidates [ i ]) # Continue exploring with the same number (since we can reuse it) backtrack ( remaining - candidates [ i ], combination , i ) # Backtrack: remove the number to explore other possibilities combination . pop () backtrack ( target , [], 0 ) return result Explanation This problem is a classic backtracking problem. The backtrack function explores all possible combinations recursively. Base Cases: If remaining (the target sum we still need to reach) is 0, it means we have found a valid combination. We add a copy of the current combination to our result . If remaining is less than 0, it means the current path is invalid, so we stop exploring it. Recursive Step: We iterate through the candidates starting from the start index. The start index is used to ensure that we don't generate duplicate combinations (e.g., [2,3] and [3,2] if we always started from index 0). For each candidate, we add it to our current combination . We then make a recursive call to backtrack , reducing the remaining sum and passing the same start index ( i ) because we are allowed to reuse the same element. After the recursive call returns, we backtrack by removing the last added element ( combination.pop() ). This allows us to explore other branches of the decision tree. The time complexity is hard to define precisely but is exponential, roughly O(N^(T/M + 1)), where N is the number of candidates, T is the target, and M is the minimum candidate value. The space complexity is O(T/M) for the recursion depth.","title":"Combination Sum"},{"location":"combination_sum/#21-combination-sum","text":"","title":"21. Combination Sum"},{"location":"combination_sum/#problem-statement","text":"Given an array of distinct integers candidates and a target integer target , return a list of all unique combinations of candidates where the chosen numbers sum to target . You may return the combinations in any order . The same number may be chosen from candidates an unlimited number of times . Two combinations are unique if the frequency of at least one of the chosen numbers is different. The test cases are generated such that the number of unique combinations that sum up to target is less than 150 combinations for the given input. Example 1: Input: candidates = [2,3,6,7], target = 7 Output: [[2,2,3],[7]] Explanation: 2 and 3 are candidates, and 2 + 2 + 3 = 7. Note that 2 can be used multiple times. 7 is a candidate, and 7 = 7. These are the only two combinations. Example 2: Input: candidates = [2,3,5], target = 8 Output: [[2,2,2,2],[2,3,3],[3,5]] Example 3: Input: candidates = [2], target = 1 Output: []","title":"Problem Statement"},{"location":"combination_sum/#solution","text":"class Solution : def combinationSum ( self , candidates : list [ int ], target : int ) -> list [ list [ int ]]: result = [] def backtrack ( remaining , combination , start ): if remaining == 0 : # Found a valid combination result . append ( list ( combination )) return if remaining < 0 : # Exceeded the target return for i in range ( start , len ( candidates )): # Add the number to the current combination combination . append ( candidates [ i ]) # Continue exploring with the same number (since we can reuse it) backtrack ( remaining - candidates [ i ], combination , i ) # Backtrack: remove the number to explore other possibilities combination . pop () backtrack ( target , [], 0 ) return result","title":"Solution"},{"location":"combination_sum/#explanation","text":"This problem is a classic backtracking problem. The backtrack function explores all possible combinations recursively. Base Cases: If remaining (the target sum we still need to reach) is 0, it means we have found a valid combination. We add a copy of the current combination to our result . If remaining is less than 0, it means the current path is invalid, so we stop exploring it. Recursive Step: We iterate through the candidates starting from the start index. The start index is used to ensure that we don't generate duplicate combinations (e.g., [2,3] and [3,2] if we always started from index 0). For each candidate, we add it to our current combination . We then make a recursive call to backtrack , reducing the remaining sum and passing the same start index ( i ) because we are allowed to reuse the same element. After the recursive call returns, we backtrack by removing the last added element ( combination.pop() ). This allows us to explore other branches of the decision tree. The time complexity is hard to define precisely but is exponential, roughly O(N^(T/M + 1)), where N is the number of candidates, T is the target, and M is the minimum candidate value. The space complexity is O(T/M) for the recursion depth.","title":"Explanation"},{"location":"construct_binary_tree_from_preorder_and_inorder_traversal/","text":"65. Construct Binary Tree from Preorder and Inorder Traversal Problem Statement Given two integer arrays preorder and inorder where preorder is the preorder traversal of a binary tree and inorder is the inorder traversal of the same tree, construct and return the binary tree . Example 1: Input: preorder = [3,9,20,15,7], inorder = [9,3,15,20,7] Output: [3,9,20,null,null,15,7] Example 2: Input: preorder = [-1], inorder = [-1] Output: [-1] Solution # Definition for a binary tree node. class TreeNode : def __init__ ( self , val = 0 , left = None , right = None ): self . val = val self . left = left self . right = right class Solution : def buildTree ( self , preorder : list [ int ], inorder : list [ int ]) -> TreeNode : # Create a hash map for quick lookup of values in inorder traversal inorder_map = { val : idx for idx , val in enumerate ( inorder )} def build ( preorder_start , preorder_end , inorder_start , inorder_end ): # Base case: if the range is invalid, return None if preorder_start > preorder_end or inorder_start > inorder_end : return None # The first element in preorder is always the root of the current subtree root_val = preorder [ preorder_start ] root = TreeNode ( root_val ) # Find the root_val in inorder traversal to determine left and right subtree boundaries inorder_root_idx = inorder_map [ root_val ] # Calculate the size of the left subtree left_subtree_size = inorder_root_idx - inorder_start # Recursively build the left subtree root . left = build ( preorder_start + 1 , # Next element in preorder is left child preorder_start + left_subtree_size , # End of left subtree in preorder inorder_start , # Start of left subtree in inorder inorder_root_idx - 1 # End of left subtree in inorder ) # Recursively build the right subtree root . right = build ( preorder_start + left_subtree_size + 1 , # Start of right subtree in preorder preorder_end , # End of right subtree in preorder inorder_root_idx + 1 , # Start of right subtree in inorder inorder_end # End of right subtree in inorder ) return root # Initial call to build the tree return build ( 0 , len ( preorder ) - 1 , 0 , len ( inorder ) - 1 ) Explanation This is a classic tree construction problem that can be solved recursively. The key properties of preorder and inorder traversals are crucial here: Preorder Traversal: [Root, Left Subtree, Right Subtree] Inorder Traversal: [Left Subtree, Root, Right Subtree] Core Idea: The first element in the preorder traversal is always the root of the current subtree. Once we identify the root from preorder , we can find its position in the inorder traversal. This position divides the inorder array into two parts: the left part represents the left subtree, and the right part represents the right subtree. The sizes of these left and right parts in inorder tell us the sizes of the left and right subtrees. We can then use these sizes to determine the corresponding ranges in the preorder array for the left and right subtrees. Recursive build Function: The build function takes the start and end indices for both preorder and inorder arrays, defining the current segment of the tree we are trying to build. Base Case: If preorder_start > preorder_end or inorder_start > inorder_end , it means we have an empty subtree, so return None . Create Root: The root_val is preorder[preorder_start] . Create a TreeNode with this value. Find Root in Inorder: Use a hash map ( inorder_map ) to quickly find the index of root_val in the inorder array. This inorder_root_idx is critical. Calculate Subtree Sizes: The number of elements in the left subtree is left_subtree_size = inorder_root_idx - inorder_start . Recursive Calls: Left Subtree: Recursively call build for the left subtree. The preorder range will be [preorder_start + 1, preorder_start + left_subtree_size] . The inorder range will be [inorder_start, inorder_root_idx - 1] . Right Subtree: Recursively call build for the right subtree. The preorder range will be [preorder_start + left_subtree_size + 1, preorder_end] . The inorder range will be [inorder_root_idx + 1, inorder_end] . Return Root: Return the constructed root node. Optimization: Using a hash map for inorder_map allows for O(1) lookup of the root's index, which is crucial for performance. Time and Space Complexity: Time Complexity: O(N), where N is the number of nodes in the tree. Each node is processed once, and the hash map lookup is O(1). Space Complexity: O(N) for the inorder_map and O(H) for the recursion stack (where H is the height of the tree, which can be N in the worst case).","title":"Construct Binary Tree from Preorder and Inorder Traversal"},{"location":"construct_binary_tree_from_preorder_and_inorder_traversal/#65-construct-binary-tree-from-preorder-and-inorder-traversal","text":"","title":"65. Construct Binary Tree from Preorder and Inorder Traversal"},{"location":"construct_binary_tree_from_preorder_and_inorder_traversal/#problem-statement","text":"Given two integer arrays preorder and inorder where preorder is the preorder traversal of a binary tree and inorder is the inorder traversal of the same tree, construct and return the binary tree . Example 1: Input: preorder = [3,9,20,15,7], inorder = [9,3,15,20,7] Output: [3,9,20,null,null,15,7] Example 2: Input: preorder = [-1], inorder = [-1] Output: [-1]","title":"Problem Statement"},{"location":"construct_binary_tree_from_preorder_and_inorder_traversal/#solution","text":"# Definition for a binary tree node. class TreeNode : def __init__ ( self , val = 0 , left = None , right = None ): self . val = val self . left = left self . right = right class Solution : def buildTree ( self , preorder : list [ int ], inorder : list [ int ]) -> TreeNode : # Create a hash map for quick lookup of values in inorder traversal inorder_map = { val : idx for idx , val in enumerate ( inorder )} def build ( preorder_start , preorder_end , inorder_start , inorder_end ): # Base case: if the range is invalid, return None if preorder_start > preorder_end or inorder_start > inorder_end : return None # The first element in preorder is always the root of the current subtree root_val = preorder [ preorder_start ] root = TreeNode ( root_val ) # Find the root_val in inorder traversal to determine left and right subtree boundaries inorder_root_idx = inorder_map [ root_val ] # Calculate the size of the left subtree left_subtree_size = inorder_root_idx - inorder_start # Recursively build the left subtree root . left = build ( preorder_start + 1 , # Next element in preorder is left child preorder_start + left_subtree_size , # End of left subtree in preorder inorder_start , # Start of left subtree in inorder inorder_root_idx - 1 # End of left subtree in inorder ) # Recursively build the right subtree root . right = build ( preorder_start + left_subtree_size + 1 , # Start of right subtree in preorder preorder_end , # End of right subtree in preorder inorder_root_idx + 1 , # Start of right subtree in inorder inorder_end # End of right subtree in inorder ) return root # Initial call to build the tree return build ( 0 , len ( preorder ) - 1 , 0 , len ( inorder ) - 1 )","title":"Solution"},{"location":"construct_binary_tree_from_preorder_and_inorder_traversal/#explanation","text":"This is a classic tree construction problem that can be solved recursively. The key properties of preorder and inorder traversals are crucial here: Preorder Traversal: [Root, Left Subtree, Right Subtree] Inorder Traversal: [Left Subtree, Root, Right Subtree] Core Idea: The first element in the preorder traversal is always the root of the current subtree. Once we identify the root from preorder , we can find its position in the inorder traversal. This position divides the inorder array into two parts: the left part represents the left subtree, and the right part represents the right subtree. The sizes of these left and right parts in inorder tell us the sizes of the left and right subtrees. We can then use these sizes to determine the corresponding ranges in the preorder array for the left and right subtrees. Recursive build Function: The build function takes the start and end indices for both preorder and inorder arrays, defining the current segment of the tree we are trying to build. Base Case: If preorder_start > preorder_end or inorder_start > inorder_end , it means we have an empty subtree, so return None . Create Root: The root_val is preorder[preorder_start] . Create a TreeNode with this value. Find Root in Inorder: Use a hash map ( inorder_map ) to quickly find the index of root_val in the inorder array. This inorder_root_idx is critical. Calculate Subtree Sizes: The number of elements in the left subtree is left_subtree_size = inorder_root_idx - inorder_start . Recursive Calls: Left Subtree: Recursively call build for the left subtree. The preorder range will be [preorder_start + 1, preorder_start + left_subtree_size] . The inorder range will be [inorder_start, inorder_root_idx - 1] . Right Subtree: Recursively call build for the right subtree. The preorder range will be [preorder_start + left_subtree_size + 1, preorder_end] . The inorder range will be [inorder_root_idx + 1, inorder_end] . Return Root: Return the constructed root node. Optimization: Using a hash map for inorder_map allows for O(1) lookup of the root's index, which is crucial for performance. Time and Space Complexity: Time Complexity: O(N), where N is the number of nodes in the tree. Each node is processed once, and the hash map lookup is O(1). Space Complexity: O(N) for the inorder_map and O(H) for the recursion stack (where H is the height of the tree, which can be N in the worst case).","title":"Explanation"},{"location":"container_with_most_water/","text":"10. Container With Most Water Problem Statement You are given an integer array height of length n . There are n vertical lines drawn such that the two endpoints of the i th line are (i, 0) and (i, height[i]) . Find two lines that together with the x-axis form a container, such that the container contains the most water. Return the maximum amount of water a container can store . Notice that you may not slant the container. Example 1: Input: height = [1,8,6,2,5,4,8,3,7] Output: 49 Explanation: The above vertical lines are represented by array [1,8,6,2,5,4,8,3,7]. In this case, the max area of water (blue section) the container can contain is 49. Example 2: Input: height = [1,1] Output: 1 Solution class Solution : def maxArea ( self , height : list [ int ]) -> int : left , right = 0 , len ( height ) - 1 max_area = 0 while left < right : # Calculate the area h = min ( height [ left ], height [ right ]) w = right - left area = h * w max_area = max ( max_area , area ) # Move the pointer pointing to the shorter line if height [ left ] < height [ right ]: left += 1 else : right -= 1 return max_area Explanation This problem can be solved efficiently using a two-pointer approach. We initialize two pointers, left at the beginning of the array and right at the end. The area of the container formed by these two lines is determined by the shorter of the two heights (as that's the water level) and the distance between the lines. In each step, we calculate the area and update our max_area . Then, we need to decide which pointer to move. To maximize the area, we should try to increase the shorter height. Therefore, we move the pointer that points to the shorter of the two lines inward. This process continues until the pointers meet. The time complexity is O(n) because we traverse the array once. The space complexity is O(1).","title":"Container With Most Water"},{"location":"container_with_most_water/#10-container-with-most-water","text":"","title":"10. Container With Most Water"},{"location":"container_with_most_water/#problem-statement","text":"You are given an integer array height of length n . There are n vertical lines drawn such that the two endpoints of the i th line are (i, 0) and (i, height[i]) . Find two lines that together with the x-axis form a container, such that the container contains the most water. Return the maximum amount of water a container can store . Notice that you may not slant the container. Example 1: Input: height = [1,8,6,2,5,4,8,3,7] Output: 49 Explanation: The above vertical lines are represented by array [1,8,6,2,5,4,8,3,7]. In this case, the max area of water (blue section) the container can contain is 49. Example 2: Input: height = [1,1] Output: 1","title":"Problem Statement"},{"location":"container_with_most_water/#solution","text":"class Solution : def maxArea ( self , height : list [ int ]) -> int : left , right = 0 , len ( height ) - 1 max_area = 0 while left < right : # Calculate the area h = min ( height [ left ], height [ right ]) w = right - left area = h * w max_area = max ( max_area , area ) # Move the pointer pointing to the shorter line if height [ left ] < height [ right ]: left += 1 else : right -= 1 return max_area","title":"Solution"},{"location":"container_with_most_water/#explanation","text":"This problem can be solved efficiently using a two-pointer approach. We initialize two pointers, left at the beginning of the array and right at the end. The area of the container formed by these two lines is determined by the shorter of the two heights (as that's the water level) and the distance between the lines. In each step, we calculate the area and update our max_area . Then, we need to decide which pointer to move. To maximize the area, we should try to increase the shorter height. Therefore, we move the pointer that points to the shorter of the two lines inward. This process continues until the pointers meet. The time complexity is O(n) because we traverse the array once. The space complexity is O(1).","title":"Explanation"},{"location":"contains_duplicate/","text":"3. Contains Duplicate Problem Statement Given an integer array nums , return true if any value appears at least twice in the array, and return false if every element is distinct. Example 1: Input: nums = [1,2,3,1] Output: true Example 2: Input: nums = [1,2,3,4] Output: false Example 3: Input: nums = [1,1,1,3,3,4,3,2,4,2] Output: true Solution class Solution : def containsDuplicate ( self , nums : list [ int ]) -> bool : seen = set () for num in nums : if num in seen : return True seen . add ( num ) return False Explanation This solution uses a hash set ( seen ) to efficiently check for duplicates. We iterate through the input array nums . For each number, we check if it's already present in our seen set. If the number is in the set, we have found a duplicate and immediately return True . If the number is not in the set, we add it to the set and continue to the next element. If we finish iterating through the entire array without finding any duplicates, it means all elements are distinct, and we return False . This approach has a time complexity of O(n) because we iterate through the array once, and set lookups/insertions are O(1) on average. The space complexity is O(n) in the worst case, where all elements are unique and stored in the set.","title":"Contains Duplicate"},{"location":"contains_duplicate/#3-contains-duplicate","text":"","title":"3. Contains Duplicate"},{"location":"contains_duplicate/#problem-statement","text":"Given an integer array nums , return true if any value appears at least twice in the array, and return false if every element is distinct. Example 1: Input: nums = [1,2,3,1] Output: true Example 2: Input: nums = [1,2,3,4] Output: false Example 3: Input: nums = [1,1,1,3,3,4,3,2,4,2] Output: true","title":"Problem Statement"},{"location":"contains_duplicate/#solution","text":"class Solution : def containsDuplicate ( self , nums : list [ int ]) -> bool : seen = set () for num in nums : if num in seen : return True seen . add ( num ) return False","title":"Solution"},{"location":"contains_duplicate/#explanation","text":"This solution uses a hash set ( seen ) to efficiently check for duplicates. We iterate through the input array nums . For each number, we check if it's already present in our seen set. If the number is in the set, we have found a duplicate and immediately return True . If the number is not in the set, we add it to the set and continue to the next element. If we finish iterating through the entire array without finding any duplicates, it means all elements are distinct, and we return False . This approach has a time complexity of O(n) because we iterate through the array once, and set lookups/insertions are O(1) on average. The space complexity is O(n) in the worst case, where all elements are unique and stored in the set.","title":"Explanation"},{"location":"count_good_nodes_in_binary_tree/","text":"67. Count Good Nodes in Binary Tree Problem Statement Given a binary tree root , a node X in the tree is named good if in the path from the root to X there are no nodes with a value greater than X . Return the number of good nodes in the binary tree . Example 1: Input: root = [3,1,4,3,null,1,5] Output: 4 Explanation: Nodes in the tree are: - Node 3 (root) is always a good node. - Node 1 -> not good, because path from root is [3,1], and 3 > 1. - Node 4 -> good, because path from root is [3,4], and 3 < 4. - Node 3 (left child of 1) -> not good, because path from root is [3,1,3], and 3 > 1. - Node 1 (left child of 4) -> not good, because path from root is [3,4,1], and 4 > 1. - Node 5 (right child of 4) -> good, because path from root is [3,4,5], and 3 < 5, 4 < 5. Total good nodes: 4. Example 2: Input: root = [3,3,null,4,2] Output: 3 Explanation: Node 3 (root) is good. Node 3 (left child of 3) is good because path is [3,3]. Node 4 (left child of 3) is good because path is [3,3,4]. Node 2 (right child of 4) is not good because path is [3,3,4,2], and 4 > 2. Example 3: Input: root = [1] Output: 1 Solution # Definition for a binary tree node. class TreeNode : def __init__ ( self , val = 0 , left = None , right = None ): self . val = val self . left = left self . right = right class Solution : def goodNodes ( self , root : TreeNode ) -> int : def dfs ( node , max_so_far ): if not node : return 0 count = 0 if node . val >= max_so_far : count = 1 max_so_far = node . val # Update max_so_far for children count += dfs ( node . left , max_so_far ) count += dfs ( node . right , max_so_far ) return count # Start DFS from root with initial max_so_far as negative infinity return dfs ( root , float ( '-inf' )) Explanation This problem can be solved using a Depth-First Search (DFS) approach. The key is to pass the maximum value encountered so far along the path from the root to the current node. Core Idea: A node is \"good\" if its value is greater than or equal to the maximum value on the path from the root to its parent. Recursive dfs Function: The dfs function takes two arguments: the node currently being visited and max_so_far , which is the maximum value encountered on the path from the root to the parent of the current node . Base Case: If node is None , there are no good nodes in this empty subtree, so return 0. Check Good Node: Initialize count for the current node to 0. If node.val >= max_so_far , it means the current node is a \"good\" node. Increment count to 1. Crucially, update max_so_far to node.val if the current node is greater. This new max_so_far will be passed down to its children. Recurse on Children: Recursively call dfs on node.left and node.right , passing the (potentially updated) max_so_far . Add the counts returned from the recursive calls to the current count . Return Count: Return the total count of good nodes in the subtree rooted at node . Initial Call: We start the DFS from the root with max_so_far initialized to negative infinity ( float('-inf') ) to ensure the root node is always considered a good node. Time and Space Complexity: Time Complexity: O(N), where N is the number of nodes in the binary tree. Each node is visited exactly once. Space Complexity: O(H) in the worst case, where H is the height of the tree, due to the recursion stack. In a skewed tree, H can be N (O(N)), and in a balanced tree, H is log N (O(log N)).","title":"Count Good Nodes in Binary Tree"},{"location":"count_good_nodes_in_binary_tree/#67-count-good-nodes-in-binary-tree","text":"","title":"67. Count Good Nodes in Binary Tree"},{"location":"count_good_nodes_in_binary_tree/#problem-statement","text":"Given a binary tree root , a node X in the tree is named good if in the path from the root to X there are no nodes with a value greater than X . Return the number of good nodes in the binary tree . Example 1: Input: root = [3,1,4,3,null,1,5] Output: 4 Explanation: Nodes in the tree are: - Node 3 (root) is always a good node. - Node 1 -> not good, because path from root is [3,1], and 3 > 1. - Node 4 -> good, because path from root is [3,4], and 3 < 4. - Node 3 (left child of 1) -> not good, because path from root is [3,1,3], and 3 > 1. - Node 1 (left child of 4) -> not good, because path from root is [3,4,1], and 4 > 1. - Node 5 (right child of 4) -> good, because path from root is [3,4,5], and 3 < 5, 4 < 5. Total good nodes: 4. Example 2: Input: root = [3,3,null,4,2] Output: 3 Explanation: Node 3 (root) is good. Node 3 (left child of 3) is good because path is [3,3]. Node 4 (left child of 3) is good because path is [3,3,4]. Node 2 (right child of 4) is not good because path is [3,3,4,2], and 4 > 2. Example 3: Input: root = [1] Output: 1","title":"Problem Statement"},{"location":"count_good_nodes_in_binary_tree/#solution","text":"# Definition for a binary tree node. class TreeNode : def __init__ ( self , val = 0 , left = None , right = None ): self . val = val self . left = left self . right = right class Solution : def goodNodes ( self , root : TreeNode ) -> int : def dfs ( node , max_so_far ): if not node : return 0 count = 0 if node . val >= max_so_far : count = 1 max_so_far = node . val # Update max_so_far for children count += dfs ( node . left , max_so_far ) count += dfs ( node . right , max_so_far ) return count # Start DFS from root with initial max_so_far as negative infinity return dfs ( root , float ( '-inf' ))","title":"Solution"},{"location":"count_good_nodes_in_binary_tree/#explanation","text":"This problem can be solved using a Depth-First Search (DFS) approach. The key is to pass the maximum value encountered so far along the path from the root to the current node. Core Idea: A node is \"good\" if its value is greater than or equal to the maximum value on the path from the root to its parent. Recursive dfs Function: The dfs function takes two arguments: the node currently being visited and max_so_far , which is the maximum value encountered on the path from the root to the parent of the current node . Base Case: If node is None , there are no good nodes in this empty subtree, so return 0. Check Good Node: Initialize count for the current node to 0. If node.val >= max_so_far , it means the current node is a \"good\" node. Increment count to 1. Crucially, update max_so_far to node.val if the current node is greater. This new max_so_far will be passed down to its children. Recurse on Children: Recursively call dfs on node.left and node.right , passing the (potentially updated) max_so_far . Add the counts returned from the recursive calls to the current count . Return Count: Return the total count of good nodes in the subtree rooted at node . Initial Call: We start the DFS from the root with max_so_far initialized to negative infinity ( float('-inf') ) to ensure the root node is always considered a good node. Time and Space Complexity: Time Complexity: O(N), where N is the number of nodes in the binary tree. Each node is visited exactly once. Space Complexity: O(H) in the worst case, where H is the height of the tree, due to the recursion stack. In a skewed tree, H can be N (O(N)), and in a balanced tree, H is log N (O(log N)).","title":"Explanation"},{"location":"counting_bits/","text":"13. Counting Bits Problem Statement Given an integer n , return an array ans of length n + 1 such that for each i ( 0 <= i <= n ), ans[i] is the number of 1's in the binary representation of i . Example 1: Input: n = 2 Output: [0,1,1] Explanation: 0 --> 0 1 --> 1 2 --> 10 Example 2: Input: n = 5 Output: [0,1,1,2,1,2] Explanation: 0 --> 0 1 --> 1 2 --> 10 3 --> 11 4 --> 100 5 --> 101 Solution class Solution : def countBits ( self , n : int ) -> list [ int ]: # Initialize an array to store the results ans = [ 0 ] * ( n + 1 ) # Iterate from 1 to n for i in range ( 1 , n + 1 ): # The number of 1s in i is the number of 1s in i // 2 (i >> 1) # plus 1 if i is odd. ans [ i ] = ans [ i >> 1 ] + ( i & 1 ) return ans Explanation This problem can be solved using dynamic programming by observing a pattern in the number of set bits. The number of '1's in the binary representation of an integer i can be derived from a previously computed value. Let ans[i] be the number of set bits in i . Right shifting i by 1 ( i >> 1 ) is equivalent to integer division by 2. This effectively removes the least significant bit. Checking i & 1 tells us if i is odd or even. If i is odd, its least significant bit is 1. If i is even, it's 0. Therefore, the number of set bits in i is the same as the number of set bits in i // 2 , plus an additional 1 if i is odd. This leads to the recurrence relation: ans[i] = ans[i >> 1] + (i & 1) . We can build up the ans array from 0 to n using this relation, resulting in an O(n) time complexity and O(n) space complexity for the output array.","title":"Counting Bits"},{"location":"counting_bits/#13-counting-bits","text":"","title":"13. Counting Bits"},{"location":"counting_bits/#problem-statement","text":"Given an integer n , return an array ans of length n + 1 such that for each i ( 0 <= i <= n ), ans[i] is the number of 1's in the binary representation of i . Example 1: Input: n = 2 Output: [0,1,1] Explanation: 0 --> 0 1 --> 1 2 --> 10 Example 2: Input: n = 5 Output: [0,1,1,2,1,2] Explanation: 0 --> 0 1 --> 1 2 --> 10 3 --> 11 4 --> 100 5 --> 101","title":"Problem Statement"},{"location":"counting_bits/#solution","text":"class Solution : def countBits ( self , n : int ) -> list [ int ]: # Initialize an array to store the results ans = [ 0 ] * ( n + 1 ) # Iterate from 1 to n for i in range ( 1 , n + 1 ): # The number of 1s in i is the number of 1s in i // 2 (i >> 1) # plus 1 if i is odd. ans [ i ] = ans [ i >> 1 ] + ( i & 1 ) return ans","title":"Solution"},{"location":"counting_bits/#explanation","text":"This problem can be solved using dynamic programming by observing a pattern in the number of set bits. The number of '1's in the binary representation of an integer i can be derived from a previously computed value. Let ans[i] be the number of set bits in i . Right shifting i by 1 ( i >> 1 ) is equivalent to integer division by 2. This effectively removes the least significant bit. Checking i & 1 tells us if i is odd or even. If i is odd, its least significant bit is 1. If i is even, it's 0. Therefore, the number of set bits in i is the same as the number of set bits in i // 2 , plus an additional 1 if i is odd. This leads to the recurrence relation: ans[i] = ans[i >> 1] + (i & 1) . We can build up the ans array from 0 to n using this relation, resulting in an O(n) time complexity and O(n) space complexity for the output array.","title":"Explanation"},{"location":"course_schedule/","text":"28. Course Schedule Problem Statement There are a total of numCourses courses you have to take, labeled from 0 to numCourses - 1 . You are given an array prerequisites where prerequisites[i] = [ai, bi] indicates that you must take course bi first if you want to take course ai . For example, the pair [0, 1] , indicates that to take course 0 you have to first take course 1 . Return true if you can finish all courses. Otherwise, return false . Example 1: Input: numCourses = 2, prerequisites = [[1,0]] Output: true Explanation: There are a total of 2 courses to take. To take course 1 you should have finished course 0. So it is possible. Example 2: Input: numCourses = 2, prerequisites = [[1,0],[0,1]] Output: false Explanation: There are a total of 2 courses to take. To take course 1 you should have finished course 0, and to take course 0 you should also have finished course 1. So it is impossible. Solution class Solution : def canFinish ( self , numCourses : int , prerequisites : list [ list [ int ]]) -> bool : # Build adjacency list adj = { i : [] for i in range ( numCourses )} for course , prereq in prerequisites : adj [ course ] . append ( prereq ) # A set to keep track of nodes in the current recursion stack (visiting) visiting = set () # A set to keep track of nodes that have been fully processed visited = set () def has_cycle ( course ): visiting . add ( course ) for prereq in adj [ course ]: if prereq in visiting : # Cycle detected return True if prereq not in visited : if has_cycle ( prereq ): return True # No cycle found from this node, move it from visiting to visited visiting . remove ( course ) visited . add ( course ) return False # Check for cycles from every course for course in range ( numCourses ): if course not in visited : if has_cycle ( course ): return False return True Explanation This problem is equivalent to detecting a cycle in a directed graph. The courses are the nodes, and the prerequisites are the directed edges. If there is a cycle in the graph (e.g., Course A depends on B, B depends on C, and C depends on A), then it's impossible to finish all courses. If there are no cycles, it's always possible. We can solve this using Depth-First Search (DFS). Build Adjacency List: First, we represent the graph using an adjacency list, where adj[course] contains a list of its prerequisites. Track Visited States: We need to keep track of the state of each node during the DFS traversal. We use two sets: visiting : Stores nodes that are currently in the recursion stack for the active DFS path. If we encounter a node that is already in visiting , we have found a back edge, which means there is a cycle. visited : Stores nodes that have been completely explored (i.e., all their neighbors have been visited) and are known to not be part of a cycle. DFS with Cycle Detection: The has_cycle function performs the DFS. When we visit a course , we add it to visiting . We then recursively call has_cycle for all its prereq s. If any prereq is already in visiting , we've found a cycle, and we return True . After visiting all neighbors of a course without finding a cycle, we remove it from visiting and add it to visited . This is an important optimization; it means we don't have to re-explore this node if we encounter it again from a different path. Main Loop: We iterate through all courses from 0 to numCourses - 1 . We start a DFS from each course that hasn't been visited yet to ensure we cover all components of the graph. The time complexity is O(V + E), where V is the number of courses (vertices) and E is the number of prerequisites (edges), because we visit each vertex and edge once. The space complexity is O(V + E) for the adjacency list and the visited sets.","title":"Course Schedule"},{"location":"course_schedule/#28-course-schedule","text":"","title":"28. Course Schedule"},{"location":"course_schedule/#problem-statement","text":"There are a total of numCourses courses you have to take, labeled from 0 to numCourses - 1 . You are given an array prerequisites where prerequisites[i] = [ai, bi] indicates that you must take course bi first if you want to take course ai . For example, the pair [0, 1] , indicates that to take course 0 you have to first take course 1 . Return true if you can finish all courses. Otherwise, return false . Example 1: Input: numCourses = 2, prerequisites = [[1,0]] Output: true Explanation: There are a total of 2 courses to take. To take course 1 you should have finished course 0. So it is possible. Example 2: Input: numCourses = 2, prerequisites = [[1,0],[0,1]] Output: false Explanation: There are a total of 2 courses to take. To take course 1 you should have finished course 0, and to take course 0 you should also have finished course 1. So it is impossible.","title":"Problem Statement"},{"location":"course_schedule/#solution","text":"class Solution : def canFinish ( self , numCourses : int , prerequisites : list [ list [ int ]]) -> bool : # Build adjacency list adj = { i : [] for i in range ( numCourses )} for course , prereq in prerequisites : adj [ course ] . append ( prereq ) # A set to keep track of nodes in the current recursion stack (visiting) visiting = set () # A set to keep track of nodes that have been fully processed visited = set () def has_cycle ( course ): visiting . add ( course ) for prereq in adj [ course ]: if prereq in visiting : # Cycle detected return True if prereq not in visited : if has_cycle ( prereq ): return True # No cycle found from this node, move it from visiting to visited visiting . remove ( course ) visited . add ( course ) return False # Check for cycles from every course for course in range ( numCourses ): if course not in visited : if has_cycle ( course ): return False return True","title":"Solution"},{"location":"course_schedule/#explanation","text":"This problem is equivalent to detecting a cycle in a directed graph. The courses are the nodes, and the prerequisites are the directed edges. If there is a cycle in the graph (e.g., Course A depends on B, B depends on C, and C depends on A), then it's impossible to finish all courses. If there are no cycles, it's always possible. We can solve this using Depth-First Search (DFS). Build Adjacency List: First, we represent the graph using an adjacency list, where adj[course] contains a list of its prerequisites. Track Visited States: We need to keep track of the state of each node during the DFS traversal. We use two sets: visiting : Stores nodes that are currently in the recursion stack for the active DFS path. If we encounter a node that is already in visiting , we have found a back edge, which means there is a cycle. visited : Stores nodes that have been completely explored (i.e., all their neighbors have been visited) and are known to not be part of a cycle. DFS with Cycle Detection: The has_cycle function performs the DFS. When we visit a course , we add it to visiting . We then recursively call has_cycle for all its prereq s. If any prereq is already in visiting , we've found a cycle, and we return True . After visiting all neighbors of a course without finding a cycle, we remove it from visiting and add it to visited . This is an important optimization; it means we don't have to re-explore this node if we encounter it again from a different path. Main Loop: We iterate through all courses from 0 to numCourses - 1 . We start a DFS from each course that hasn't been visited yet to ensure we cover all components of the graph. The time complexity is O(V + E), where V is the number of courses (vertices) and E is the number of prerequisites (edges), because we visit each vertex and edge once. The space complexity is O(V + E) for the adjacency list and the visited sets.","title":"Explanation"},{"location":"decode_ways/","text":"24. Decode Ways Problem Statement A message containing letters from A-Z can be encoded into numbers using the following mapping: 'A' -> \"1\" 'B' -> \"2\" ... 'Z' -> \"26\" To decode an encoded message, all the digits must be grouped then mapped back into letters using the reverse of the mapping above (there may be multiple ways). For example, \"11106\" can be mapped into: \"AAJF\" with the grouping (1 1 10 6) \"KJF\" with the grouping (11 10 6) Note that the grouping (1 11 06) is invalid because \"06\" cannot be mapped into 'F' since \"6\" is different from \"06\" . Given a string s containing only digits, return the number of ways to decode it . The test cases are generated so that the answer fits in a 32-bit integer. Example 1: Input: s = \"12\" Output: 2 Explanation: \"12\" could be decoded as \"AB\" (1 2) or \"L\" (12). Example 2: Input: s = \"226\" Output: 3 Explanation: \"226\" could be decoded as \"BZ\" (2 26), \"VF\" (22 6), or \"BBF\" (2 2 6). Example 3: Input: s = \"06\" Output: 0 Explanation: \"06\" cannot be mapped to \"F\" because of the leading zero (\"6\" is different from \"06\"). Solution class Solution : def numDecodings ( self , s : str ) -> int : if not s or s [ 0 ] == '0' : return 0 # dp[i] = number of ways to decode s[:i] dp = [ 0 ] * ( len ( s ) + 1 ) dp [ 0 ] = 1 # Base case: empty string has one decoding dp [ 1 ] = 1 # s[0] is not '0', so one way to decode for i in range ( 2 , len ( s ) + 1 ): # One-digit decode if s [ i - 1 ] != '0' : dp [ i ] += dp [ i - 1 ] # Two-digit decode two_digit = int ( s [ i - 2 : i ]) if 10 <= two_digit <= 26 : dp [ i ] += dp [ i - 2 ] return dp [ - 1 ] Explanation This problem can be solved using dynamic programming. Let dp[i] be the number of ways to decode the prefix of the string s of length i ( s[:i] ). Initialization: dp[0] = 1 : There is one way to decode an empty string (the empty decoding). dp[1] = 1 : If the first character s[0] is not '0', there is one way to decode it. DP Relation: We iterate from i = 2 to len(s) . For each i , we consider the last one or two digits: One-Digit Decode: We look at the last digit s[i-1] . If it's not '0', it can be decoded as a single letter. The number of ways to do this is the same as the number of ways to decode the string up to the previous character, so we add dp[i-1] to dp[i] . Two-Digit Decode: We look at the last two digits s[i-2:i] . If this two-digit number is between 10 and 26 (inclusive), it can be decoded as a single letter. The number of ways to do this is the same as the number of ways to decode the string up to two characters before, so we add dp[i-2] to dp[i] . Final Result: dp[len(s)] will contain the total number of ways to decode the entire string. The time complexity is O(n) because we iterate through the string once. The space complexity is O(n) for the dp array. This can be optimized to O(1) space by only storing the last two dp values.","title":"Decode Ways"},{"location":"decode_ways/#24-decode-ways","text":"","title":"24. Decode Ways"},{"location":"decode_ways/#problem-statement","text":"A message containing letters from A-Z can be encoded into numbers using the following mapping: 'A' -> \"1\" 'B' -> \"2\" ... 'Z' -> \"26\" To decode an encoded message, all the digits must be grouped then mapped back into letters using the reverse of the mapping above (there may be multiple ways). For example, \"11106\" can be mapped into: \"AAJF\" with the grouping (1 1 10 6) \"KJF\" with the grouping (11 10 6) Note that the grouping (1 11 06) is invalid because \"06\" cannot be mapped into 'F' since \"6\" is different from \"06\" . Given a string s containing only digits, return the number of ways to decode it . The test cases are generated so that the answer fits in a 32-bit integer. Example 1: Input: s = \"12\" Output: 2 Explanation: \"12\" could be decoded as \"AB\" (1 2) or \"L\" (12). Example 2: Input: s = \"226\" Output: 3 Explanation: \"226\" could be decoded as \"BZ\" (2 26), \"VF\" (22 6), or \"BBF\" (2 2 6). Example 3: Input: s = \"06\" Output: 0 Explanation: \"06\" cannot be mapped to \"F\" because of the leading zero (\"6\" is different from \"06\").","title":"Problem Statement"},{"location":"decode_ways/#solution","text":"class Solution : def numDecodings ( self , s : str ) -> int : if not s or s [ 0 ] == '0' : return 0 # dp[i] = number of ways to decode s[:i] dp = [ 0 ] * ( len ( s ) + 1 ) dp [ 0 ] = 1 # Base case: empty string has one decoding dp [ 1 ] = 1 # s[0] is not '0', so one way to decode for i in range ( 2 , len ( s ) + 1 ): # One-digit decode if s [ i - 1 ] != '0' : dp [ i ] += dp [ i - 1 ] # Two-digit decode two_digit = int ( s [ i - 2 : i ]) if 10 <= two_digit <= 26 : dp [ i ] += dp [ i - 2 ] return dp [ - 1 ]","title":"Solution"},{"location":"decode_ways/#explanation","text":"This problem can be solved using dynamic programming. Let dp[i] be the number of ways to decode the prefix of the string s of length i ( s[:i] ). Initialization: dp[0] = 1 : There is one way to decode an empty string (the empty decoding). dp[1] = 1 : If the first character s[0] is not '0', there is one way to decode it. DP Relation: We iterate from i = 2 to len(s) . For each i , we consider the last one or two digits: One-Digit Decode: We look at the last digit s[i-1] . If it's not '0', it can be decoded as a single letter. The number of ways to do this is the same as the number of ways to decode the string up to the previous character, so we add dp[i-1] to dp[i] . Two-Digit Decode: We look at the last two digits s[i-2:i] . If this two-digit number is between 10 and 26 (inclusive), it can be decoded as a single letter. The number of ways to do this is the same as the number of ways to decode the string up to two characters before, so we add dp[i-2] to dp[i] . Final Result: dp[len(s)] will contain the total number of ways to decode the entire string. The time complexity is O(n) because we iterate through the string once. The space complexity is O(n) for the dp array. This can be optimized to O(1) space by only storing the last two dp values.","title":"Explanation"},{"location":"design_add_and_search_words_data_structure/","text":"70. Design Add and Search Words Data Structure Problem Statement Design a data structure that supports adding new words and finding if a string matches any previously added string. Implement the WordDictionary class: WordDictionary() Initializes the object. void addWord(word) Adds word to the data structure, it can be matched later. boolean search(word) Returns true if word is in the data structure, otherwise false . word may contain dots . where dots can be matched with any letter. Example: Input: [\"WordDictionary\",\"addWord\",\"addWord\",\"addWord\",\"search\",\"search\",\"search\",\"search\"] [[],[\"bad\"],[\"dad\"],[\"mad\"],[\"pad\"],[\"bad\"],[\".ad\"],[\"b..d\"]] Output: [null,null,null,null,false,true,true,true] Explanation: WordDictionary wordDictionary = new WordDictionary(); wordDictionary.addWord(\"bad\"); wordDictionary.addWord(\"dad\"); wordDictionary.addWord(\"mad\"); wordDictionary.search(\"pad\"); // return False wordDictionary.search(\"bad\"); // return True wordDictionary.search(\".ad\"); // return True wordDictionary.search(\"b..\"); // return True Solution class TrieNode : def __init__ ( self ): self . children = {} self . is_end_of_word = False class WordDictionary : def __init__ ( self ): self . root = TrieNode () def addWord ( self , word : str ) -> None : curr = self . root for char in word : if char not in curr . children : curr . children [ char ] = TrieNode () curr = curr . children [ char ] curr . is_end_of_word = True def search ( self , word : str ) -> bool : def dfs ( j , node ): curr = node for i in range ( j , len ( word )): char = word [ i ] if char == '.' : # If it's a dot, try all possible children for child in curr . children . values (): if dfs ( i + 1 , child ): return True return False # No child path led to a match else : # If it's a regular character, proceed normally if char not in curr . children : return False curr = curr . children [ char ] return curr . is_end_of_word return dfs ( 0 , self . root ) Explanation This problem extends the basic Trie (prefix tree) data structure to support searching with wildcard characters ( . ). TrieNode Class: (Same as in \"Implement Trie\") children : A dictionary mapping characters to child TrieNode s. is_end_of_word : A boolean indicating if a word ends at this node. WordDictionary Class Methods: __init__(self) : Initializes the trie with a root node. addWord(self, word) : (Same as insert in \"Implement Trie\") Traverses the trie, creating new nodes as needed for characters in the word . Marks the last node as is_end_of_word = True . search(self, word) : This is where the main difference lies. It uses a recursive Depth-First Search (DFS) to handle the wildcard character . . dfs(j, node) Function: j : The current index in the word we are trying to match. node : The current TrieNode we are at in the trie. Iteration: The dfs function iterates from index j to the end of the word . Handling . (Wildcard): If char == '.' : This means the dot can match any character. So, we need to recursively call dfs for all children of the current node . If any of these recursive calls return True (meaning a match was found down that path), then we return True immediately. If none of the children paths lead to a match, we return False . Handling Regular Characters: If char is a regular letter: Check if char exists as a child of the current node . If not, no match is possible, return False . Move curr to the corresponding child node. Base Case for dfs : After the loop finishes (meaning we have processed all characters in the word from index j onwards), we return curr.is_end_of_word . This ensures that we only consider a match if a complete word ends at the current trie node. The initial call to search starts the DFS from index 0 and the root node. Time and Space Complexity: addWord : O(L), where L is the length of the word. search : In the worst case (e.g., a word like ... where all characters are wildcards), the search can visit many paths. The time complexity can be roughly O(26^L) in the worst case, but on average, it's much faster. More precisely, it's O(L * 26) in the worst case for a single search, where L is the length of the word. The total time complexity depends on the number of words and search queries. Space Complexity: O(Total Characters), similar to a regular Trie.","title":"Design Add and Search Words Data Structure"},{"location":"design_add_and_search_words_data_structure/#70-design-add-and-search-words-data-structure","text":"","title":"70. Design Add and Search Words Data Structure"},{"location":"design_add_and_search_words_data_structure/#problem-statement","text":"Design a data structure that supports adding new words and finding if a string matches any previously added string. Implement the WordDictionary class: WordDictionary() Initializes the object. void addWord(word) Adds word to the data structure, it can be matched later. boolean search(word) Returns true if word is in the data structure, otherwise false . word may contain dots . where dots can be matched with any letter. Example: Input: [\"WordDictionary\",\"addWord\",\"addWord\",\"addWord\",\"search\",\"search\",\"search\",\"search\"] [[],[\"bad\"],[\"dad\"],[\"mad\"],[\"pad\"],[\"bad\"],[\".ad\"],[\"b..d\"]] Output: [null,null,null,null,false,true,true,true] Explanation: WordDictionary wordDictionary = new WordDictionary(); wordDictionary.addWord(\"bad\"); wordDictionary.addWord(\"dad\"); wordDictionary.addWord(\"mad\"); wordDictionary.search(\"pad\"); // return False wordDictionary.search(\"bad\"); // return True wordDictionary.search(\".ad\"); // return True wordDictionary.search(\"b..\"); // return True","title":"Problem Statement"},{"location":"design_add_and_search_words_data_structure/#solution","text":"class TrieNode : def __init__ ( self ): self . children = {} self . is_end_of_word = False class WordDictionary : def __init__ ( self ): self . root = TrieNode () def addWord ( self , word : str ) -> None : curr = self . root for char in word : if char not in curr . children : curr . children [ char ] = TrieNode () curr = curr . children [ char ] curr . is_end_of_word = True def search ( self , word : str ) -> bool : def dfs ( j , node ): curr = node for i in range ( j , len ( word )): char = word [ i ] if char == '.' : # If it's a dot, try all possible children for child in curr . children . values (): if dfs ( i + 1 , child ): return True return False # No child path led to a match else : # If it's a regular character, proceed normally if char not in curr . children : return False curr = curr . children [ char ] return curr . is_end_of_word return dfs ( 0 , self . root )","title":"Solution"},{"location":"design_add_and_search_words_data_structure/#explanation","text":"This problem extends the basic Trie (prefix tree) data structure to support searching with wildcard characters ( . ). TrieNode Class: (Same as in \"Implement Trie\") children : A dictionary mapping characters to child TrieNode s. is_end_of_word : A boolean indicating if a word ends at this node. WordDictionary Class Methods: __init__(self) : Initializes the trie with a root node. addWord(self, word) : (Same as insert in \"Implement Trie\") Traverses the trie, creating new nodes as needed for characters in the word . Marks the last node as is_end_of_word = True . search(self, word) : This is where the main difference lies. It uses a recursive Depth-First Search (DFS) to handle the wildcard character . . dfs(j, node) Function: j : The current index in the word we are trying to match. node : The current TrieNode we are at in the trie. Iteration: The dfs function iterates from index j to the end of the word . Handling . (Wildcard): If char == '.' : This means the dot can match any character. So, we need to recursively call dfs for all children of the current node . If any of these recursive calls return True (meaning a match was found down that path), then we return True immediately. If none of the children paths lead to a match, we return False . Handling Regular Characters: If char is a regular letter: Check if char exists as a child of the current node . If not, no match is possible, return False . Move curr to the corresponding child node. Base Case for dfs : After the loop finishes (meaning we have processed all characters in the word from index j onwards), we return curr.is_end_of_word . This ensures that we only consider a match if a complete word ends at the current trie node. The initial call to search starts the DFS from index 0 and the root node. Time and Space Complexity: addWord : O(L), where L is the length of the word. search : In the worst case (e.g., a word like ... where all characters are wildcards), the search can visit many paths. The time complexity can be roughly O(26^L) in the worst case, but on average, it's much faster. More precisely, it's O(L * 26) in the worst case for a single search, where L is the length of the word. The total time complexity depends on the number of words and search queries. Space Complexity: O(Total Characters), similar to a regular Trie.","title":"Explanation"},{"location":"find_minimum_in_rotated_sorted_array/","text":"7. Find Minimum in Rotated Sorted Array Problem Statement Suppose an array of length n sorted in ascending order is rotated between 1 and n times. For example, the array nums = [0,1,2,4,5,6,7] might become: [4,5,6,7,0,1,2] if it was rotated 4 times. [0,1,2,4,5,6,7] if it was rotated 7 times. Notice that rotating an array [a[0], a[1], a[2], ..., a[n-1]] 1 time results in the array [a[n-1], a[0], a[1], a[2], ..., a[n-2]] . Given the sorted rotated array nums of unique elements, return the minimum element of this array . You must write an algorithm that runs in O(log n) time. Example 1: Input: nums = [3,4,5,1,2] Output: 1 Explanation: The original array was [1,2,3,4,5] rotated 3 times. Example 2: Input: nums = [4,5,6,7,0,1,2] Output: 0 Explanation: The original array was [0,1,2,4,5,6,7] and it was rotated 4 times. Example 3: Input: nums = [11,13,15,17] Output: 11 Explanation: The original array was [11,13,15,17] and it was rotated 4 times. Solution class Solution : def findMin ( self , nums : list [ int ]) -> int : left , right = 0 , len ( nums ) - 1 while left < right : mid = ( left + right ) // 2 if nums [ mid ] > nums [ right ]: # The pivot (minimum element) is in the right half left = mid + 1 else : # The pivot is in the left half or is the mid element right = mid return nums [ left ] Explanation This problem can be solved efficiently using a modified binary search. The key insight is to compare the middle element with the rightmost element to determine which half of the array contains the minimum element (the pivot point). If nums[mid] > nums[right] , it means the rotation pivot must be in the right half of the array (from mid + 1 to right ). The left part is sorted correctly. If nums[mid] <= nums[right] , the pivot is either the middle element itself or in the left half. So, we search in the left half, including the middle element. We continue narrowing down the search space until left and right converge. The element at this final index is the minimum element of the rotated array. This binary search approach guarantees an O(log n) time complexity with O(1) space complexity.","title":"Find Minimum in Rotated Sorted Array"},{"location":"find_minimum_in_rotated_sorted_array/#7-find-minimum-in-rotated-sorted-array","text":"","title":"7. Find Minimum in Rotated Sorted Array"},{"location":"find_minimum_in_rotated_sorted_array/#problem-statement","text":"Suppose an array of length n sorted in ascending order is rotated between 1 and n times. For example, the array nums = [0,1,2,4,5,6,7] might become: [4,5,6,7,0,1,2] if it was rotated 4 times. [0,1,2,4,5,6,7] if it was rotated 7 times. Notice that rotating an array [a[0], a[1], a[2], ..., a[n-1]] 1 time results in the array [a[n-1], a[0], a[1], a[2], ..., a[n-2]] . Given the sorted rotated array nums of unique elements, return the minimum element of this array . You must write an algorithm that runs in O(log n) time. Example 1: Input: nums = [3,4,5,1,2] Output: 1 Explanation: The original array was [1,2,3,4,5] rotated 3 times. Example 2: Input: nums = [4,5,6,7,0,1,2] Output: 0 Explanation: The original array was [0,1,2,4,5,6,7] and it was rotated 4 times. Example 3: Input: nums = [11,13,15,17] Output: 11 Explanation: The original array was [11,13,15,17] and it was rotated 4 times.","title":"Problem Statement"},{"location":"find_minimum_in_rotated_sorted_array/#solution","text":"class Solution : def findMin ( self , nums : list [ int ]) -> int : left , right = 0 , len ( nums ) - 1 while left < right : mid = ( left + right ) // 2 if nums [ mid ] > nums [ right ]: # The pivot (minimum element) is in the right half left = mid + 1 else : # The pivot is in the left half or is the mid element right = mid return nums [ left ]","title":"Solution"},{"location":"find_minimum_in_rotated_sorted_array/#explanation","text":"This problem can be solved efficiently using a modified binary search. The key insight is to compare the middle element with the rightmost element to determine which half of the array contains the minimum element (the pivot point). If nums[mid] > nums[right] , it means the rotation pivot must be in the right half of the array (from mid + 1 to right ). The left part is sorted correctly. If nums[mid] <= nums[right] , the pivot is either the middle element itself or in the left half. So, we search in the left half, including the middle element. We continue narrowing down the search space until left and right converge. The element at this final index is the minimum element of the rotated array. This binary search approach guarantees an O(log n) time complexity with O(1) space complexity.","title":"Explanation"},{"location":"find_the_duplicate_number/","text":"51. Find the Duplicate Number Problem Statement Given an array of integers nums containing n + 1 integers where each integer is in the range [1, n] inclusive. There is only one repeated number in nums , return this repeated number . You must solve the problem without modifying the array nums and uses only constant extra space. Example 1: Input: nums = [1,3,4,2,2] Output: 2 Example 2: Input: nums = [3,1,3,4,2] Output: 3 Example 3: Input: nums = [3,3,3,3,3] Output: 3 Solution class Solution : def findDuplicate ( self , nums : list [ int ]) -> int : # Phase 1: Find the intersection point of the two runners. # This is similar to detecting a cycle in a linked list. slow = nums [ 0 ] fast = nums [ 0 ] while True : slow = nums [ slow ] fast = nums [ nums [ fast ]] if slow == fast : break # Phase 2: Find the \"entrance\" to the cycle. # Move one pointer to the start (nums[0]) and keep the other at the meeting point. # They will meet at the start of the cycle, which is the duplicate number. ptr1 = nums [ 0 ] ptr2 = slow while ptr1 != ptr2 : ptr1 = nums [ ptr1 ] ptr2 = nums [ ptr2 ] return ptr1 Explanation This problem can be cleverly solved using Floyd's Tortoise and Hare (Cycle Detection) Algorithm , which is typically used for linked lists. The key insight is to view the array as a linked list where nums[i] is the next node after i . Since there are n+1 numbers in the range [1, n] , and exactly one number is duplicated, this creates a cycle in our conceptual linked list. For example, if nums = [1,3,4,2,2] , the sequence of next pointers would be: 0 -> 1 -> 3 -> 2 -> 2 (a cycle at 2) Phase 1: Detect the Cycle Initialize slow and fast pointers, both starting at nums[0] . In each step, slow moves one step ( slow = nums[slow] ), and fast moves two steps ( fast = nums[nums[fast]] ). If there's a duplicate, slow and fast will eventually meet inside the cycle. When they meet, we break the loop. Phase 2: Find the Start of the Cycle (the Duplicate Number) Reset one pointer ( ptr1 ) back to nums[0] . Keep the other pointer ( ptr2 , which is slow from Phase 1) at the meeting point. Move both ptr1 and ptr2 one step at a time ( ptr1 = nums[ptr1] , ptr2 = nums[ptr2] ). The point where they meet again is the entry point of the cycle, which is the duplicate number. Why this works: The mathematical proof for Floyd's algorithm shows that if a cycle exists, the distance from the start of the list to the cycle entry point is equal to the distance from the meeting point to the cycle entry point. Therefore, by moving one pointer from the start and the other from the meeting point, they will converge at the cycle entry. Time and Space Complexity: Time Complexity: O(n), as both pointers traverse the array at most a constant number of times. Space Complexity: O(1), as we only use a few extra pointers and do not modify the input array.","title":"Find the Duplicate Number"},{"location":"find_the_duplicate_number/#51-find-the-duplicate-number","text":"","title":"51. Find the Duplicate Number"},{"location":"find_the_duplicate_number/#problem-statement","text":"Given an array of integers nums containing n + 1 integers where each integer is in the range [1, n] inclusive. There is only one repeated number in nums , return this repeated number . You must solve the problem without modifying the array nums and uses only constant extra space. Example 1: Input: nums = [1,3,4,2,2] Output: 2 Example 2: Input: nums = [3,1,3,4,2] Output: 3 Example 3: Input: nums = [3,3,3,3,3] Output: 3","title":"Problem Statement"},{"location":"find_the_duplicate_number/#solution","text":"class Solution : def findDuplicate ( self , nums : list [ int ]) -> int : # Phase 1: Find the intersection point of the two runners. # This is similar to detecting a cycle in a linked list. slow = nums [ 0 ] fast = nums [ 0 ] while True : slow = nums [ slow ] fast = nums [ nums [ fast ]] if slow == fast : break # Phase 2: Find the \"entrance\" to the cycle. # Move one pointer to the start (nums[0]) and keep the other at the meeting point. # They will meet at the start of the cycle, which is the duplicate number. ptr1 = nums [ 0 ] ptr2 = slow while ptr1 != ptr2 : ptr1 = nums [ ptr1 ] ptr2 = nums [ ptr2 ] return ptr1","title":"Solution"},{"location":"find_the_duplicate_number/#explanation","text":"This problem can be cleverly solved using Floyd's Tortoise and Hare (Cycle Detection) Algorithm , which is typically used for linked lists. The key insight is to view the array as a linked list where nums[i] is the next node after i . Since there are n+1 numbers in the range [1, n] , and exactly one number is duplicated, this creates a cycle in our conceptual linked list. For example, if nums = [1,3,4,2,2] , the sequence of next pointers would be: 0 -> 1 -> 3 -> 2 -> 2 (a cycle at 2) Phase 1: Detect the Cycle Initialize slow and fast pointers, both starting at nums[0] . In each step, slow moves one step ( slow = nums[slow] ), and fast moves two steps ( fast = nums[nums[fast]] ). If there's a duplicate, slow and fast will eventually meet inside the cycle. When they meet, we break the loop. Phase 2: Find the Start of the Cycle (the Duplicate Number) Reset one pointer ( ptr1 ) back to nums[0] . Keep the other pointer ( ptr2 , which is slow from Phase 1) at the meeting point. Move both ptr1 and ptr2 one step at a time ( ptr1 = nums[ptr1] , ptr2 = nums[ptr2] ). The point where they meet again is the entry point of the cycle, which is the duplicate number. Why this works: The mathematical proof for Floyd's algorithm shows that if a cycle exists, the distance from the start of the list to the cycle entry point is equal to the distance from the meeting point to the cycle entry point. Therefore, by moving one pointer from the start and the other from the meeting point, they will converge at the cycle entry. Time and Space Complexity: Time Complexity: O(n), as both pointers traverse the array at most a constant number of times. Space Complexity: O(1), as we only use a few extra pointers and do not modify the input array.","title":"Explanation"},{"location":"group_anagrams/","text":"37. Group Anagrams Problem Statement Given an array of strings strs , group the anagrams together. You can return the answer in any order . An Anagram is a word or phrase formed by rearranging the letters of a different word or phrase, typically using all the original letters exactly once. Example 1: Input: strs = [\"eat\",\"tea\",\"tan\",\"ate\",\"nat\",\"bat\"] Output: [[\"bat\"],[\"nat\",\"tan\"],[\"ate\",\"eat\",\"tea\"]] Example 2: Input: strs = [\"\"] Output: [[\"\"]] Example 3: Input: strs = [\"a\"] Output: [[\"a\"]] Solution from collections import defaultdict class Solution : def groupAnagrams ( self , strs : list [ str ]) -> list [ list [ str ]]: # Use a defaultdict where keys are sorted tuples of characters # and values are lists of anagrams. anagram_groups = defaultdict ( list ) for s in strs : # Sort the string to create a canonical key for anagrams # e.g., \"eat\" -> \"aet\", \"tea\" -> \"aet\", \"ate\" -> \"aet\" sorted_s = '' . join ( sorted ( s )) anagram_groups [ sorted_s ] . append ( s ) # Return the values (lists of anagrams) from the dictionary return list ( anagram_groups . values ()) Explanation The core idea to group anagrams is to find a canonical representation for each group of anagrams. Since anagrams contain the same characters with the same frequencies, sorting the characters of an anagram will always result in the same string. Canonical Key: For each string in the input list strs , we sort its characters alphabetically. For example, \"eat\", \"tea\", and \"ate\" all become \"aet\" after sorting. This sorted string acts as a unique key for all its anagrams. Hash Map (DefaultDict): We use a hash map (specifically, collections.defaultdict(list) in Python) where: The keys are the sorted strings (our canonical representation). The values are lists of the original strings that produce that sorted key. Grouping: We iterate through the input strs . For each string s , we sort it to get its sorted_s key. We then append the original string s to the list associated with sorted_s in our anagram_groups dictionary. Result: Finally, we extract all the values from the anagram_groups dictionary. Each value is a list of strings that are anagrams of each other. The time complexity is O(N * K log K), where N is the number of strings in strs and K is the maximum length of a string. This is because for each of the N strings, we sort it, which takes K log K time. The space complexity is O(N * K) in the worst case, where all strings are unique and stored in the dictionary.","title":"Group Anagrams"},{"location":"group_anagrams/#37-group-anagrams","text":"","title":"37. Group Anagrams"},{"location":"group_anagrams/#problem-statement","text":"Given an array of strings strs , group the anagrams together. You can return the answer in any order . An Anagram is a word or phrase formed by rearranging the letters of a different word or phrase, typically using all the original letters exactly once. Example 1: Input: strs = [\"eat\",\"tea\",\"tan\",\"ate\",\"nat\",\"bat\"] Output: [[\"bat\"],[\"nat\",\"tan\"],[\"ate\",\"eat\",\"tea\"]] Example 2: Input: strs = [\"\"] Output: [[\"\"]] Example 3: Input: strs = [\"a\"] Output: [[\"a\"]]","title":"Problem Statement"},{"location":"group_anagrams/#solution","text":"from collections import defaultdict class Solution : def groupAnagrams ( self , strs : list [ str ]) -> list [ list [ str ]]: # Use a defaultdict where keys are sorted tuples of characters # and values are lists of anagrams. anagram_groups = defaultdict ( list ) for s in strs : # Sort the string to create a canonical key for anagrams # e.g., \"eat\" -> \"aet\", \"tea\" -> \"aet\", \"ate\" -> \"aet\" sorted_s = '' . join ( sorted ( s )) anagram_groups [ sorted_s ] . append ( s ) # Return the values (lists of anagrams) from the dictionary return list ( anagram_groups . values ())","title":"Solution"},{"location":"group_anagrams/#explanation","text":"The core idea to group anagrams is to find a canonical representation for each group of anagrams. Since anagrams contain the same characters with the same frequencies, sorting the characters of an anagram will always result in the same string. Canonical Key: For each string in the input list strs , we sort its characters alphabetically. For example, \"eat\", \"tea\", and \"ate\" all become \"aet\" after sorting. This sorted string acts as a unique key for all its anagrams. Hash Map (DefaultDict): We use a hash map (specifically, collections.defaultdict(list) in Python) where: The keys are the sorted strings (our canonical representation). The values are lists of the original strings that produce that sorted key. Grouping: We iterate through the input strs . For each string s , we sort it to get its sorted_s key. We then append the original string s to the list associated with sorted_s in our anagram_groups dictionary. Result: Finally, we extract all the values from the anagram_groups dictionary. Each value is a list of strings that are anagrams of each other. The time complexity is O(N * K log K), where N is the number of strings in strs and K is the maximum length of a string. This is because for each of the N strings, we sort it, which takes K log K time. The space complexity is O(N * K) in the worst case, where all strings are unique and stored in the dictionary.","title":"Explanation"},{"location":"happy_number/","text":"52. Happy Number Problem Statement Write an algorithm to determine if a number n is \"happy\". A happy number is a number defined by the following process: Starting with any positive integer, replace the number by the sum of the squares of its digits. Repeat the process until the number equals 1 (where it will stay), or it loops endlessly in a cycle which does not include 1. Those numbers for which this process ends in 1 are happy numbers. Return true if n is a happy number, and false if not. Example 1: Input: n = 19 Output: true Explanation: 1^2 + 9^2 = 1 + 81 = 82 8^2 + 2^2 = 64 + 4 = 68 6^2 + 8^2 = 36 + 64 = 100 1^2 + 0^2 + 0^2 = 1 + 0 + 0 = 1 Example 2: Input: n = 2 Output: false Solution class Solution : def isHappy ( self , n : int ) -> bool : def get_next ( num ): total_sum = 0 while num > 0 : digit = num % 10 total_sum += digit * digit num //= 10 return total_sum slow = n fast = get_next ( n ) while fast != 1 and slow != fast : slow = get_next ( slow ) fast = get_next ( get_next ( fast )) return fast == 1 Explanation This problem can be solved by detecting a cycle in a sequence of numbers. If a number is not happy, it will eventually enter a cycle that does not include 1. If it is happy, it will eventually reach 1. We can use Floyd's Cycle-Finding Algorithm (the tortoise and hare approach) to detect if the sequence of numbers generated by the sum-of-squares process enters a cycle. get_next Function: A helper function get_next(num) calculates the sum of the squares of the digits of a given number. Initialize Pointers: slow pointer starts at n . fast pointer starts at get_next(n) . Cycle Detection: We iterate using a while loop as long as fast is not 1 and slow is not equal to fast . In each step, slow moves one step ( slow = get_next(slow) ). fast moves two steps ( fast = get_next(get_next(fast)) ). If slow and fast meet (i.e., slow == fast ), it means a cycle has been detected. Determine Happiness: After the loop, if fast is 1, it means the sequence eventually reached 1, so the number is happy. Return True . If fast is not 1 (meaning slow == fast and they met in a cycle that doesn't include 1), the number is not happy. Return False . Time and Space Complexity: Time Complexity: The sequence of numbers generated by the sum-of-squares process is bounded. For numbers less than 1000, the maximum sum of squares of digits is for 999 (9^2 + 9^2 + 9^2 = 243). For numbers greater than 999, the sum of squares of digits will eventually become less than 243. This means the sequence will eventually enter a cycle or reach 1. Therefore, the time complexity is effectively O(log n) or O(number of digits), as the number of steps is limited by the maximum possible sum of squares. Space Complexity: O(1), as we only use a few extra variables.","title":"Happy Number"},{"location":"happy_number/#52-happy-number","text":"","title":"52. Happy Number"},{"location":"happy_number/#problem-statement","text":"Write an algorithm to determine if a number n is \"happy\". A happy number is a number defined by the following process: Starting with any positive integer, replace the number by the sum of the squares of its digits. Repeat the process until the number equals 1 (where it will stay), or it loops endlessly in a cycle which does not include 1. Those numbers for which this process ends in 1 are happy numbers. Return true if n is a happy number, and false if not. Example 1: Input: n = 19 Output: true Explanation: 1^2 + 9^2 = 1 + 81 = 82 8^2 + 2^2 = 64 + 4 = 68 6^2 + 8^2 = 36 + 64 = 100 1^2 + 0^2 + 0^2 = 1 + 0 + 0 = 1 Example 2: Input: n = 2 Output: false","title":"Problem Statement"},{"location":"happy_number/#solution","text":"class Solution : def isHappy ( self , n : int ) -> bool : def get_next ( num ): total_sum = 0 while num > 0 : digit = num % 10 total_sum += digit * digit num //= 10 return total_sum slow = n fast = get_next ( n ) while fast != 1 and slow != fast : slow = get_next ( slow ) fast = get_next ( get_next ( fast )) return fast == 1","title":"Solution"},{"location":"happy_number/#explanation","text":"This problem can be solved by detecting a cycle in a sequence of numbers. If a number is not happy, it will eventually enter a cycle that does not include 1. If it is happy, it will eventually reach 1. We can use Floyd's Cycle-Finding Algorithm (the tortoise and hare approach) to detect if the sequence of numbers generated by the sum-of-squares process enters a cycle. get_next Function: A helper function get_next(num) calculates the sum of the squares of the digits of a given number. Initialize Pointers: slow pointer starts at n . fast pointer starts at get_next(n) . Cycle Detection: We iterate using a while loop as long as fast is not 1 and slow is not equal to fast . In each step, slow moves one step ( slow = get_next(slow) ). fast moves two steps ( fast = get_next(get_next(fast)) ). If slow and fast meet (i.e., slow == fast ), it means a cycle has been detected. Determine Happiness: After the loop, if fast is 1, it means the sequence eventually reached 1, so the number is happy. Return True . If fast is not 1 (meaning slow == fast and they met in a cycle that doesn't include 1), the number is not happy. Return False . Time and Space Complexity: Time Complexity: The sequence of numbers generated by the sum-of-squares process is bounded. For numbers less than 1000, the maximum sum of squares of digits is for 999 (9^2 + 9^2 + 9^2 = 243). For numbers greater than 999, the sum of squares of digits will eventually become less than 243. This means the sequence will eventually enter a cycle or reach 1. Therefore, the time complexity is effectively O(log n) or O(number of digits), as the number of steps is limited by the maximum possible sum of squares. Space Complexity: O(1), as we only use a few extra variables.","title":"Explanation"},{"location":"house_robber/","text":"22. House Robber Problem Statement You are a professional robber planning to rob houses along a street. Each house has a certain amount of money stashed, the only constraint stopping you from robbing each of them is that adjacent houses have security systems connected and it will automatically contact the police if two adjacent houses were broken into on the same night . Given an integer array nums representing the amount of money of each house, return the maximum amount of money you can rob tonight without alerting the police **. Example 1: Input: nums = [1,2,3,1] Output: 4 Explanation: Rob house 1 (money = 1) and then rob house 3 (money = 3). Total amount you can rob = 1 + 3 = 4. Example 2: Input: nums = [2,7,9,3,1] Output: 12 Explanation: Rob house 1 (money = 2), rob house 3 (money = 9) and rob house 5 (money = 1). Total amount you can rob = 2 + 9 + 1 = 12. Solution class Solution : def rob ( self , nums : list [ int ]) -> int : rob1 , rob2 = 0 , 0 # [rob1, rob2, n, n+1, ...] # rob1 is the max profit from robbing up to house i-2 # rob2 is the max profit from robbing up to house i-1 for n in nums : # The new max profit is either robbing the current house (n + rob1) # or not robbing it (rob2). temp = max ( n + rob1 , rob2 ) rob1 = rob2 rob2 = temp return rob2 Explanation This is a classic dynamic programming problem. Let's define dp[i] as the maximum amount of money that can be robbed from the first i houses. When considering house i , the robber has two choices: Rob house i : If the robber chooses to rob house i , they cannot rob the previous house ( i-1 ). The total amount would be nums[i] + dp[i-2] (money from the current house plus the max money from two houses before). Don't rob house i : If the robber chooses not to rob house i , the maximum amount of money is simply the maximum amount they could have robbed from the previous i-1 houses, which is dp[i-1] . This gives the recurrence relation: dp[i] = max(nums[i] + dp[i-2], dp[i-1]) . The provided solution is a space-optimized version of this DP approach. rob2 represents the maximum profit up to the previous house ( dp[i-1] ). rob1 represents the maximum profit up to two houses before ( dp[i-2] ). In each iteration, we calculate the new maximum profit ( temp ) and then update rob1 and rob2 for the next iteration. This reduces the space complexity from O(n) to O(1) while keeping the time complexity at O(n).","title":"House Robber"},{"location":"house_robber/#22-house-robber","text":"","title":"22. House Robber"},{"location":"house_robber/#problem-statement","text":"You are a professional robber planning to rob houses along a street. Each house has a certain amount of money stashed, the only constraint stopping you from robbing each of them is that adjacent houses have security systems connected and it will automatically contact the police if two adjacent houses were broken into on the same night . Given an integer array nums representing the amount of money of each house, return the maximum amount of money you can rob tonight without alerting the police **. Example 1: Input: nums = [1,2,3,1] Output: 4 Explanation: Rob house 1 (money = 1) and then rob house 3 (money = 3). Total amount you can rob = 1 + 3 = 4. Example 2: Input: nums = [2,7,9,3,1] Output: 12 Explanation: Rob house 1 (money = 2), rob house 3 (money = 9) and rob house 5 (money = 1). Total amount you can rob = 2 + 9 + 1 = 12.","title":"Problem Statement"},{"location":"house_robber/#solution","text":"class Solution : def rob ( self , nums : list [ int ]) -> int : rob1 , rob2 = 0 , 0 # [rob1, rob2, n, n+1, ...] # rob1 is the max profit from robbing up to house i-2 # rob2 is the max profit from robbing up to house i-1 for n in nums : # The new max profit is either robbing the current house (n + rob1) # or not robbing it (rob2). temp = max ( n + rob1 , rob2 ) rob1 = rob2 rob2 = temp return rob2","title":"Solution"},{"location":"house_robber/#explanation","text":"This is a classic dynamic programming problem. Let's define dp[i] as the maximum amount of money that can be robbed from the first i houses. When considering house i , the robber has two choices: Rob house i : If the robber chooses to rob house i , they cannot rob the previous house ( i-1 ). The total amount would be nums[i] + dp[i-2] (money from the current house plus the max money from two houses before). Don't rob house i : If the robber chooses not to rob house i , the maximum amount of money is simply the maximum amount they could have robbed from the previous i-1 houses, which is dp[i-1] . This gives the recurrence relation: dp[i] = max(nums[i] + dp[i-2], dp[i-1]) . The provided solution is a space-optimized version of this DP approach. rob2 represents the maximum profit up to the previous house ( dp[i-1] ). rob1 represents the maximum profit up to two houses before ( dp[i-2] ). In each iteration, we calculate the new maximum profit ( temp ) and then update rob1 and rob2 for the next iteration. This reduces the space complexity from O(n) to O(1) while keeping the time complexity at O(n).","title":"Explanation"},{"location":"house_robber_ii/","text":"23. House Robber II Problem Statement You are a professional robber planning to rob houses along a street. Each house has a certain amount of money stashed. All houses at this place are arranged in a circle . That means the first house is the neighbor of the last one. Meanwhile, adjacent houses have a security system connected, and it will automatically contact the police if two adjacent houses were broken into on the same night . Given an integer array nums representing the amount of money of each house, return the maximum amount of money you can rob tonight without alerting the police **. Example 1: Input: nums = [2,3,2] Output: 3 Explanation: You cannot rob house 1 (money = 2) and then rob house 3 (money = 2), because they are adjacent houses. Example 2: Input: nums = [1,2,3,1] Output: 4 Explanation: Rob house 1 (money = 1) and then rob house 3 (money = 3). Total amount you can rob = 1 + 3 = 4. Example 3: Input: nums = [1,2,3] Output: 3 Solution class Solution : def rob ( self , nums : list [ int ]) -> int : if len ( nums ) == 1 : return nums [ 0 ] # Helper function for the original House Robber problem def _rob ( sub_nums ): rob1 , rob2 = 0 , 0 for n in sub_nums : temp = max ( n + rob1 , rob2 ) rob1 = rob2 rob2 = temp return rob2 # The problem can be broken down into two subproblems: # 1. Rob houses from index 0 to n-2 (excluding the last house). # 2. Rob houses from index 1 to n-1 (excluding the first house). # The maximum of these two will be the answer. return max ( _rob ( nums [: - 1 ]), _rob ( nums [ 1 :])) Explanation This problem is a variation of the original \"House Robber\" problem, with the added constraint that the houses are in a circle. This means the first and last houses are now considered adjacent. The circular arrangement creates a new dependency: if you rob the first house, you cannot rob the last house, and vice versa. We can break this problem down into two separate, linear subproblems: Case 1: Exclude the last house. We calculate the maximum amount of money that can be robbed from the houses nums[0] to nums[n-2] . Case 2: Exclude the first house. We calculate the maximum amount of money that can be robbed from the houses nums[1] to nums[n-1] . The final answer is the maximum of the results from these two cases. This covers all possibilities while respecting the circular constraint. We can reuse the O(1) space solution from the original House Robber problem to solve each subproblem. The overall time complexity will be O(n) because we are essentially running the linear scan twice on subarrays. The space complexity is O(1).","title":"House Robber II"},{"location":"house_robber_ii/#23-house-robber-ii","text":"","title":"23. House Robber II"},{"location":"house_robber_ii/#problem-statement","text":"You are a professional robber planning to rob houses along a street. Each house has a certain amount of money stashed. All houses at this place are arranged in a circle . That means the first house is the neighbor of the last one. Meanwhile, adjacent houses have a security system connected, and it will automatically contact the police if two adjacent houses were broken into on the same night . Given an integer array nums representing the amount of money of each house, return the maximum amount of money you can rob tonight without alerting the police **. Example 1: Input: nums = [2,3,2] Output: 3 Explanation: You cannot rob house 1 (money = 2) and then rob house 3 (money = 2), because they are adjacent houses. Example 2: Input: nums = [1,2,3,1] Output: 4 Explanation: Rob house 1 (money = 1) and then rob house 3 (money = 3). Total amount you can rob = 1 + 3 = 4. Example 3: Input: nums = [1,2,3] Output: 3","title":"Problem Statement"},{"location":"house_robber_ii/#solution","text":"class Solution : def rob ( self , nums : list [ int ]) -> int : if len ( nums ) == 1 : return nums [ 0 ] # Helper function for the original House Robber problem def _rob ( sub_nums ): rob1 , rob2 = 0 , 0 for n in sub_nums : temp = max ( n + rob1 , rob2 ) rob1 = rob2 rob2 = temp return rob2 # The problem can be broken down into two subproblems: # 1. Rob houses from index 0 to n-2 (excluding the last house). # 2. Rob houses from index 1 to n-1 (excluding the first house). # The maximum of these two will be the answer. return max ( _rob ( nums [: - 1 ]), _rob ( nums [ 1 :]))","title":"Solution"},{"location":"house_robber_ii/#explanation","text":"This problem is a variation of the original \"House Robber\" problem, with the added constraint that the houses are in a circle. This means the first and last houses are now considered adjacent. The circular arrangement creates a new dependency: if you rob the first house, you cannot rob the last house, and vice versa. We can break this problem down into two separate, linear subproblems: Case 1: Exclude the last house. We calculate the maximum amount of money that can be robbed from the houses nums[0] to nums[n-2] . Case 2: Exclude the first house. We calculate the maximum amount of money that can be robbed from the houses nums[1] to nums[n-1] . The final answer is the maximum of the results from these two cases. This covers all possibilities while respecting the circular constraint. We can reuse the O(1) space solution from the original House Robber problem to solve each subproblem. The overall time complexity will be O(n) because we are essentially running the linear scan twice on subarrays. The space complexity is O(1).","title":"Explanation"},{"location":"implement_trie_prefix_tree/","text":"69. Implement Trie (Prefix Tree) Problem Statement A trie (pronounced \"try\") or prefix tree is a tree data structure used to efficiently retrieve keys in a dataset of strings. There are various applications of this data structure, such as autocomplete and spellchecker. Implement the Trie class: Trie() Initializes the trie object. void insert(String word) Inserts the string word into the trie. boolean search(String word) Returns true if the string word is in the trie (i.e., was inserted before), and false otherwise. boolean startsWith(String prefix) Returns true if there is a previously inserted string that has the prefix prefix , and false otherwise. Example 1: Input: [\"Trie\", \"insert\", \"search\", \"search\", \"startsWith\", \"insert\", \"search\"] [[], [\"apple\"], [\"apple\"], [\"app\"], [\"app\"], [\"app\"], [\"app\"]] Output: [null, null, true, false, true, null, true] Explanation: Trie trie = new Trie(); trie.insert(\"apple\"); trie.search(\"apple\"); // return True trie.search(\"app\"); // return False trie.startsWith(\"app\"); // return True trie.insert(\"app\"); trie.search(\"app\"); // return True Solution class TrieNode : def __init__ ( self ): self . children = {} self . is_end_of_word = False class Trie : def __init__ ( self ): self . root = TrieNode () def insert ( self , word : str ) -> None : curr = self . root for char in word : if char not in curr . children : curr . children [ char ] = TrieNode () curr = curr . children [ char ] curr . is_end_of_word = True def search ( self , word : str ) -> bool : curr = self . root for char in word : if char not in curr . children : return False curr = curr . children [ char ] return curr . is_end_of_word def startsWith ( self , prefix : str ) -> bool : curr = self . root for char in prefix : if char not in curr . children : return False curr = curr . children [ char ] return True Explanation A Trie (prefix tree) is a tree-like data structure where each node represents a character, and paths from the root to a node represent prefixes. Each node can have multiple children, typically one for each possible character. TrieNode Class: children : A dictionary (or hash map) that maps a character to its corresponding child TrieNode . This allows for efficient lookup of the next character in a path. is_end_of_word : A boolean flag that is True if the path from the root to this node represents a complete word that was inserted into the trie. Trie Class Methods: __init__(self) : Initializes the trie with a root node, which is an empty TrieNode . insert(self, word) : Start from the root . For each char in the word : If the char is not a child of the current node, create a new TrieNode for it and add it to curr.children . Move curr to this child node. After processing all characters, set curr.is_end_of_word = True to mark the end of the inserted word. search(self, word) : Start from the root . For each char in the word : If the char is not a child of the current node, the word does not exist in the trie. Return False . Move curr to this child node. After traversing all characters, return curr.is_end_of_word . This ensures that we only return True if the entire word was inserted, not just a prefix. startsWith(self, prefix) : Start from the root . For each char in the prefix : If the char is not a child of the current node, the prefix does not exist in the trie. Return False . Move curr to this child node. If the loop completes, it means the entire prefix exists in the trie. Return True . Time and Space Complexity: insert : O(L), where L is the length of the word. We traverse the trie once for each character. search : O(L), where L is the length of the word. We traverse the trie once for each character. startsWith : O(L), where L is the length of the prefix. We traverse the trie once for each character. Space Complexity: O(Total Characters), where Total Characters is the sum of the lengths of all words inserted into the trie. In the worst case, each character creates a new node.","title":"Implement Trie (Prefix Tree)"},{"location":"implement_trie_prefix_tree/#69-implement-trie-prefix-tree","text":"","title":"69. Implement Trie (Prefix Tree)"},{"location":"implement_trie_prefix_tree/#problem-statement","text":"A trie (pronounced \"try\") or prefix tree is a tree data structure used to efficiently retrieve keys in a dataset of strings. There are various applications of this data structure, such as autocomplete and spellchecker. Implement the Trie class: Trie() Initializes the trie object. void insert(String word) Inserts the string word into the trie. boolean search(String word) Returns true if the string word is in the trie (i.e., was inserted before), and false otherwise. boolean startsWith(String prefix) Returns true if there is a previously inserted string that has the prefix prefix , and false otherwise. Example 1: Input: [\"Trie\", \"insert\", \"search\", \"search\", \"startsWith\", \"insert\", \"search\"] [[], [\"apple\"], [\"apple\"], [\"app\"], [\"app\"], [\"app\"], [\"app\"]] Output: [null, null, true, false, true, null, true] Explanation: Trie trie = new Trie(); trie.insert(\"apple\"); trie.search(\"apple\"); // return True trie.search(\"app\"); // return False trie.startsWith(\"app\"); // return True trie.insert(\"app\"); trie.search(\"app\"); // return True","title":"Problem Statement"},{"location":"implement_trie_prefix_tree/#solution","text":"class TrieNode : def __init__ ( self ): self . children = {} self . is_end_of_word = False class Trie : def __init__ ( self ): self . root = TrieNode () def insert ( self , word : str ) -> None : curr = self . root for char in word : if char not in curr . children : curr . children [ char ] = TrieNode () curr = curr . children [ char ] curr . is_end_of_word = True def search ( self , word : str ) -> bool : curr = self . root for char in word : if char not in curr . children : return False curr = curr . children [ char ] return curr . is_end_of_word def startsWith ( self , prefix : str ) -> bool : curr = self . root for char in prefix : if char not in curr . children : return False curr = curr . children [ char ] return True","title":"Solution"},{"location":"implement_trie_prefix_tree/#explanation","text":"A Trie (prefix tree) is a tree-like data structure where each node represents a character, and paths from the root to a node represent prefixes. Each node can have multiple children, typically one for each possible character. TrieNode Class: children : A dictionary (or hash map) that maps a character to its corresponding child TrieNode . This allows for efficient lookup of the next character in a path. is_end_of_word : A boolean flag that is True if the path from the root to this node represents a complete word that was inserted into the trie. Trie Class Methods: __init__(self) : Initializes the trie with a root node, which is an empty TrieNode . insert(self, word) : Start from the root . For each char in the word : If the char is not a child of the current node, create a new TrieNode for it and add it to curr.children . Move curr to this child node. After processing all characters, set curr.is_end_of_word = True to mark the end of the inserted word. search(self, word) : Start from the root . For each char in the word : If the char is not a child of the current node, the word does not exist in the trie. Return False . Move curr to this child node. After traversing all characters, return curr.is_end_of_word . This ensures that we only return True if the entire word was inserted, not just a prefix. startsWith(self, prefix) : Start from the root . For each char in the prefix : If the char is not a child of the current node, the prefix does not exist in the trie. Return False . Move curr to this child node. If the loop completes, it means the entire prefix exists in the trie. Return True . Time and Space Complexity: insert : O(L), where L is the length of the word. We traverse the trie once for each character. search : O(L), where L is the length of the word. We traverse the trie once for each character. startsWith : O(L), where L is the length of the prefix. We traverse the trie once for each character. Space Complexity: O(Total Characters), where Total Characters is the sum of the lengths of all words inserted into the trie. In the worst case, each character creates a new node.","title":"Explanation"},{"location":"insert_interval/","text":"72. Insert Interval Problem Statement You are given an array of non-overlapping intervals intervals where intervals[i] = [starti, endi] represent the start and the end of the i th interval and intervals is sorted in ascending order by starti . You are also given an interval newInterval = [start, end] . Insert newInterval into intervals such that intervals is still sorted in ascending order by starti and intervals still does not have any overlapping intervals (merge overlapping intervals if necessary). Return intervals after the insertion and merging processes . Example 1: Input: intervals = [[1,3],[6,9]], newInterval = [2,5] Output: [[1,5],[6,9]] Example 2: Input: intervals = [[1,2],[3,5],[6,7],[8,10],[12,16]], newInterval = [4,8] Output: [[1,2],[3,10],[12,16]] Explanation: Because the new interval [4,8] overlaps with [3,5],[6,7],[8,10]. Example 3: Input: intervals = [], newInterval = [5,7] Output: [[5,7]] Solution class Solution : def insert ( self , intervals : list [ list [ int ]], newInterval : list [ int ]) -> list [ list [ int ]]: result = [] i = 0 n = len ( intervals ) # Add all intervals that come before newInterval and do not overlap while i < n and intervals [ i ][ 1 ] < newInterval [ 0 ]: result . append ( intervals [ i ]) i += 1 # Merge overlapping intervals while i < n and intervals [ i ][ 0 ] <= newInterval [ 1 ]: newInterval [ 0 ] = min ( newInterval [ 0 ], intervals [ i ][ 0 ]) newInterval [ 1 ] = max ( newInterval [ 1 ], intervals [ i ][ 1 ]) i += 1 result . append ( newInterval ) # Add all remaining intervals that come after newInterval and do not overlap while i < n : result . append ( intervals [ i ]) i += 1 return result Explanation This problem involves inserting a new interval into a sorted list of non-overlapping intervals and then merging any overlaps. Since the input intervals list is already sorted, we can use a linear scan approach. Core Idea: We can divide the existing intervals into three categories relative to the newInterval : Intervals that come completely before newInterval and do not overlap. Intervals that overlap with newInterval . Intervals that come completely after newInterval and do not overlap. Algorithm: Add Non-Overlapping Intervals (Before): Iterate through intervals from the beginning. Append any interval intervals[i] to result if its end time ( intervals[i][1] ) is less than the start time of newInterval ( newInterval[0] ). This means intervals[i] is completely before newInterval and does not overlap. Merge Overlapping Intervals: Continue iterating. Now, we encounter intervals that either overlap with newInterval or come after it. While intervals[i] 's start time ( intervals[i][0] ) is less than or equal to newInterval 's end time ( newInterval[1] ), it means there is an overlap. During this overlap, we update newInterval by taking the minimum of the start times and the maximum of the end times to encompass all overlapping intervals. Increment i to move to the next interval. After this loop, newInterval will have been expanded to cover all intervals it overlapped with. Append this updated newInterval to result . Add Non-Overlapping Intervals (After): Append all remaining intervals from intervals (from the current i to the end) to result . These intervals are guaranteed not to overlap with the (now merged) newInterval . Time and Space Complexity: Time Complexity: O(N), where N is the number of intervals. We iterate through the list of intervals at most once. Space Complexity: O(N) for the result list. In the worst case, no intervals overlap, and result will contain all N intervals plus the newInterval .","title":"Insert Interval"},{"location":"insert_interval/#72-insert-interval","text":"","title":"72. Insert Interval"},{"location":"insert_interval/#problem-statement","text":"You are given an array of non-overlapping intervals intervals where intervals[i] = [starti, endi] represent the start and the end of the i th interval and intervals is sorted in ascending order by starti . You are also given an interval newInterval = [start, end] . Insert newInterval into intervals such that intervals is still sorted in ascending order by starti and intervals still does not have any overlapping intervals (merge overlapping intervals if necessary). Return intervals after the insertion and merging processes . Example 1: Input: intervals = [[1,3],[6,9]], newInterval = [2,5] Output: [[1,5],[6,9]] Example 2: Input: intervals = [[1,2],[3,5],[6,7],[8,10],[12,16]], newInterval = [4,8] Output: [[1,2],[3,10],[12,16]] Explanation: Because the new interval [4,8] overlaps with [3,5],[6,7],[8,10]. Example 3: Input: intervals = [], newInterval = [5,7] Output: [[5,7]]","title":"Problem Statement"},{"location":"insert_interval/#solution","text":"class Solution : def insert ( self , intervals : list [ list [ int ]], newInterval : list [ int ]) -> list [ list [ int ]]: result = [] i = 0 n = len ( intervals ) # Add all intervals that come before newInterval and do not overlap while i < n and intervals [ i ][ 1 ] < newInterval [ 0 ]: result . append ( intervals [ i ]) i += 1 # Merge overlapping intervals while i < n and intervals [ i ][ 0 ] <= newInterval [ 1 ]: newInterval [ 0 ] = min ( newInterval [ 0 ], intervals [ i ][ 0 ]) newInterval [ 1 ] = max ( newInterval [ 1 ], intervals [ i ][ 1 ]) i += 1 result . append ( newInterval ) # Add all remaining intervals that come after newInterval and do not overlap while i < n : result . append ( intervals [ i ]) i += 1 return result","title":"Solution"},{"location":"insert_interval/#explanation","text":"This problem involves inserting a new interval into a sorted list of non-overlapping intervals and then merging any overlaps. Since the input intervals list is already sorted, we can use a linear scan approach. Core Idea: We can divide the existing intervals into three categories relative to the newInterval : Intervals that come completely before newInterval and do not overlap. Intervals that overlap with newInterval . Intervals that come completely after newInterval and do not overlap. Algorithm: Add Non-Overlapping Intervals (Before): Iterate through intervals from the beginning. Append any interval intervals[i] to result if its end time ( intervals[i][1] ) is less than the start time of newInterval ( newInterval[0] ). This means intervals[i] is completely before newInterval and does not overlap. Merge Overlapping Intervals: Continue iterating. Now, we encounter intervals that either overlap with newInterval or come after it. While intervals[i] 's start time ( intervals[i][0] ) is less than or equal to newInterval 's end time ( newInterval[1] ), it means there is an overlap. During this overlap, we update newInterval by taking the minimum of the start times and the maximum of the end times to encompass all overlapping intervals. Increment i to move to the next interval. After this loop, newInterval will have been expanded to cover all intervals it overlapped with. Append this updated newInterval to result . Add Non-Overlapping Intervals (After): Append all remaining intervals from intervals (from the current i to the end) to result . These intervals are guaranteed not to overlap with the (now merged) newInterval . Time and Space Complexity: Time Complexity: O(N), where N is the number of intervals. We iterate through the list of intervals at most once. Space Complexity: O(N) for the result list. In the worst case, no intervals overlap, and result will contain all N intervals plus the newInterval .","title":"Explanation"},{"location":"invert_binary_tree/","text":"56. Invert Binary Tree Problem Statement Given the root of a binary tree, invert the tree, and return its root . Example 1: Input: root = [4,2,7,1,3,6,9] Output: [4,7,2,9,6,3,1] Example 2: Input: root = [2,1,3] Output: [2,3,1] Example 3: Input: root = [] Output: [] Solution # Definition for a binary tree node. class TreeNode : def __init__ ( self , val = 0 , left = None , right = None ): self . val = val self . left = left self . right = right class Solution : def invertTree ( self , root : TreeNode ) -> TreeNode : if not root : return None # Swap the left and right children root . left , root . right = root . right , root . left # Recursively invert the left and right subtrees self . invertTree ( root . left ) self . invertTree ( root . right ) return root Explanation This problem can be solved elegantly using recursion. Core Idea: To invert a binary tree, we need to swap the left and right children of every node in the tree. Recursive Approach: Base Case: If the root is None (an empty tree or a null child), there's nothing to invert, so we return None . Recursive Step: Swap Children: For the current root node, we swap its left and right children. Python's tuple assignment makes this very concise: root.left, root.right = root.right, root.left . Recurse on Subtrees: After swapping the children of the current node, we recursively call invertTree on the (now new) root.left and root.right subtrees. This ensures that the inversion process is applied to all nodes down to the leaves. Return Root: Finally, we return the root of the inverted tree. Time and Space Complexity: Time Complexity: O(N), where N is the number of nodes in the binary tree. We visit each node exactly once. Space Complexity: O(H) in the worst case, where H is the height of the tree. This is due to the recursion stack. In a skewed tree, H can be N (O(N)), and in a balanced tree, H is log N (O(log N)).","title":"Invert Binary Tree"},{"location":"invert_binary_tree/#56-invert-binary-tree","text":"","title":"56. Invert Binary Tree"},{"location":"invert_binary_tree/#problem-statement","text":"Given the root of a binary tree, invert the tree, and return its root . Example 1: Input: root = [4,2,7,1,3,6,9] Output: [4,7,2,9,6,3,1] Example 2: Input: root = [2,1,3] Output: [2,3,1] Example 3: Input: root = [] Output: []","title":"Problem Statement"},{"location":"invert_binary_tree/#solution","text":"# Definition for a binary tree node. class TreeNode : def __init__ ( self , val = 0 , left = None , right = None ): self . val = val self . left = left self . right = right class Solution : def invertTree ( self , root : TreeNode ) -> TreeNode : if not root : return None # Swap the left and right children root . left , root . right = root . right , root . left # Recursively invert the left and right subtrees self . invertTree ( root . left ) self . invertTree ( root . right ) return root","title":"Solution"},{"location":"invert_binary_tree/#explanation","text":"This problem can be solved elegantly using recursion. Core Idea: To invert a binary tree, we need to swap the left and right children of every node in the tree. Recursive Approach: Base Case: If the root is None (an empty tree or a null child), there's nothing to invert, so we return None . Recursive Step: Swap Children: For the current root node, we swap its left and right children. Python's tuple assignment makes this very concise: root.left, root.right = root.right, root.left . Recurse on Subtrees: After swapping the children of the current node, we recursively call invertTree on the (now new) root.left and root.right subtrees. This ensures that the inversion process is applied to all nodes down to the leaves. Return Root: Finally, we return the root of the inverted tree. Time and Space Complexity: Time Complexity: O(N), where N is the number of nodes in the binary tree. We visit each node exactly once. Space Complexity: O(H) in the worst case, where H is the height of the tree. This is due to the recursion stack. In a skewed tree, H can be N (O(N)), and in a balanced tree, H is log N (O(log N)).","title":"Explanation"},{"location":"jump_game/","text":"26. Jump Game Problem Statement You are given an integer array nums . You are initially positioned at the array's first index , and each element in the array represents your maximum jump length at that position. Return true if you can reach the last index, or false otherwise . Example 1: Input: nums = [2,3,1,1,4] Output: true Explanation: Jump 1 step from index 0 to 1, then 3 steps to the last index. Example 2: Input: nums = [3,2,1,0,4] Output: false Explanation: You will always arrive at index 3 no matter what. Its maximum jump length is 0, which makes it impossible to reach the last index. Solution class Solution : def canJump ( self , nums : list [ int ]) -> bool : goal = len ( nums ) - 1 # Iterate backwards from the second to last element for i in range ( len ( nums ) - 2 , - 1 , - 1 ): # If we can reach the current goal from this position if i + nums [ i ] >= goal : # Update the goal to this position goal = i # If we managed to move the goal to the start, it's possible return goal == 0 Explanation This problem can be solved with a greedy approach. The idea is to work backward from the end of the array. Initialization: We set our goal to the last index of the array ( len(nums) - 1 ). Backward Iteration: We iterate from the second to last element ( len(nums) - 2 ) down to the first element ( 0 ). Greedy Choice: In each position i , we check if we can reach the current goal from this position. This is true if i + nums[i] >= goal . If we can reach the goal , it means this position i is a \"good\" position. We can now update our goal to be this position i , because we know if we can reach i , we can definitely reach the end. Final Check: After the loop finishes, we check if the goal has been moved all the way to the starting index (0). If goal == 0 , it means we found a path of \"good\" positions from the start to the end, so it's possible to reach the last index. This greedy algorithm is very efficient, with a time complexity of O(n) and a space complexity of O(1).","title":"Jump Game"},{"location":"jump_game/#26-jump-game","text":"","title":"26. Jump Game"},{"location":"jump_game/#problem-statement","text":"You are given an integer array nums . You are initially positioned at the array's first index , and each element in the array represents your maximum jump length at that position. Return true if you can reach the last index, or false otherwise . Example 1: Input: nums = [2,3,1,1,4] Output: true Explanation: Jump 1 step from index 0 to 1, then 3 steps to the last index. Example 2: Input: nums = [3,2,1,0,4] Output: false Explanation: You will always arrive at index 3 no matter what. Its maximum jump length is 0, which makes it impossible to reach the last index.","title":"Problem Statement"},{"location":"jump_game/#solution","text":"class Solution : def canJump ( self , nums : list [ int ]) -> bool : goal = len ( nums ) - 1 # Iterate backwards from the second to last element for i in range ( len ( nums ) - 2 , - 1 , - 1 ): # If we can reach the current goal from this position if i + nums [ i ] >= goal : # Update the goal to this position goal = i # If we managed to move the goal to the start, it's possible return goal == 0","title":"Solution"},{"location":"jump_game/#explanation","text":"This problem can be solved with a greedy approach. The idea is to work backward from the end of the array. Initialization: We set our goal to the last index of the array ( len(nums) - 1 ). Backward Iteration: We iterate from the second to last element ( len(nums) - 2 ) down to the first element ( 0 ). Greedy Choice: In each position i , we check if we can reach the current goal from this position. This is true if i + nums[i] >= goal . If we can reach the goal , it means this position i is a \"good\" position. We can now update our goal to be this position i , because we know if we can reach i , we can definitely reach the end. Final Check: After the loop finishes, we check if the goal has been moved all the way to the starting index (0). If goal == 0 , it means we found a path of \"good\" positions from the start to the end, so it's possible to reach the last index. This greedy algorithm is very efficient, with a time complexity of O(n) and a space complexity of O(1).","title":"Explanation"},{"location":"kth_smallest_element_in_a_bst/","text":"64. Kth Smallest Element in a BST Problem Statement Given the root of a Binary Search Tree (BST) and an integer k , return the k th smallest value (1-indexed) of all the values of the nodes in the tree . Example 1: Input: root = [3,1,4,null,2], k = 1 Output: 1 Example 2: Input: root = [5,3,6,2,4,null,null,1], k = 3 Output: 3 Solution # Definition for a binary tree node. class TreeNode : def __init__ ( self , val = 0 , left = None , right = None ): self . val = val self . left = left self . right = right class Solution : def kthSmallest ( self , root : TreeNode , k : int ) -> int : stack = [] current = root while current or stack : # Traverse to the leftmost node, pushing nodes onto the stack while current : stack . append ( current ) current = current . left # Pop the smallest node (leftmost node in the current subtree) current = stack . pop () k -= 1 # If k becomes 0, this is our kth smallest element if k == 0 : return current . val # Move to the right subtree to find the next smallest element current = current . right Explanation The property of a Binary Search Tree (BST) is that an in-order traversal of the tree yields the nodes in ascending order. Therefore, to find the k th smallest element, we can perform an in-order traversal and stop when we have visited k nodes. Iterative In-order Traversal (using a stack): Initialization: Create an empty stack . Initialize current to root . Traverse Left: While current is not None : Push current onto the stack . Move current to current.left . This ensures we go as far left as possible, finding the smallest elements first. Process Node: Once current is None (meaning we've reached the leftmost node of the current subtree): Pop a node from the stack . This is the next smallest element in the in-order traversal. Decrement k . If k becomes 0, we have found our k th smallest element. Return its val . Traverse Right: Move current to the right child of the popped node. This prepares for finding the next smallest elements in the right subtree. This process continues until the k th smallest element is found. Time and Space Complexity: Time Complexity: O(H + k), where H is the height of the BST. In the worst case (a skewed tree), H can be N (number of nodes), so O(N). In a balanced BST, H is log N, so O(log N + k). We visit at most k nodes and traverse down to the k th node. Space Complexity: O(H) for the stack. In the worst case, O(N), and in a balanced tree, O(log N).","title":"Kth Smallest Element in a BST"},{"location":"kth_smallest_element_in_a_bst/#64-kth-smallest-element-in-a-bst","text":"","title":"64. Kth Smallest Element in a BST"},{"location":"kth_smallest_element_in_a_bst/#problem-statement","text":"Given the root of a Binary Search Tree (BST) and an integer k , return the k th smallest value (1-indexed) of all the values of the nodes in the tree . Example 1: Input: root = [3,1,4,null,2], k = 1 Output: 1 Example 2: Input: root = [5,3,6,2,4,null,null,1], k = 3 Output: 3","title":"Problem Statement"},{"location":"kth_smallest_element_in_a_bst/#solution","text":"# Definition for a binary tree node. class TreeNode : def __init__ ( self , val = 0 , left = None , right = None ): self . val = val self . left = left self . right = right class Solution : def kthSmallest ( self , root : TreeNode , k : int ) -> int : stack = [] current = root while current or stack : # Traverse to the leftmost node, pushing nodes onto the stack while current : stack . append ( current ) current = current . left # Pop the smallest node (leftmost node in the current subtree) current = stack . pop () k -= 1 # If k becomes 0, this is our kth smallest element if k == 0 : return current . val # Move to the right subtree to find the next smallest element current = current . right","title":"Solution"},{"location":"kth_smallest_element_in_a_bst/#explanation","text":"The property of a Binary Search Tree (BST) is that an in-order traversal of the tree yields the nodes in ascending order. Therefore, to find the k th smallest element, we can perform an in-order traversal and stop when we have visited k nodes. Iterative In-order Traversal (using a stack): Initialization: Create an empty stack . Initialize current to root . Traverse Left: While current is not None : Push current onto the stack . Move current to current.left . This ensures we go as far left as possible, finding the smallest elements first. Process Node: Once current is None (meaning we've reached the leftmost node of the current subtree): Pop a node from the stack . This is the next smallest element in the in-order traversal. Decrement k . If k becomes 0, we have found our k th smallest element. Return its val . Traverse Right: Move current to the right child of the popped node. This prepares for finding the next smallest elements in the right subtree. This process continues until the k th smallest element is found. Time and Space Complexity: Time Complexity: O(H + k), where H is the height of the BST. In the worst case (a skewed tree), H can be N (number of nodes), so O(N). In a balanced BST, H is log N, so O(log N + k). We visit at most k nodes and traverse down to the k th node. Space Complexity: O(H) for the stack. In the worst case, O(N), and in a balanced tree, O(log N).","title":"Explanation"},{"location":"linked_list_cycle/","text":"49. Linked List Cycle Problem Statement Given head , the head of a linked list, determine if the linked list has a cycle in it. There is a cycle in a linked list if there is some node in the list that can be reached again by continuously following the next pointers. Internally, pos is used to denote the index of the node that tail's next pointer is connected to. Note that pos is not passed as a parameter. Return true if there is a cycle in the linked list. Otherwise, return false . Example 1: Input: head = [3,2,0,-4], pos = 1 Output: true Explanation: There is a cycle in the linked list, where the tail connects to the 1st node (0-indexed). Example 2: Input: head = [1,2], pos = 0 Output: true Explanation: There is a cycle in the linked list, where the tail connects to the 0th node. Example 3: Input: head = [1], pos = -1 Output: false Explanation: There is no cycle in the linked list. Solution # Definition for singly-linked list. class ListNode : def __init__ ( self , x ): self . val = x self . next = None class Solution : def hasCycle ( self , head : ListNode ) -> bool : if not head or not head . next : return False slow = head fast = head . next while fast and fast . next : if slow == fast : return True slow = slow . next fast = fast . next . next return False Explanation This problem is a classic application of the Floyd's Cycle-Finding Algorithm , also known as the \"tortoise and hare\" algorithm. Core Idea: If there is a cycle in a linked list, a fast pointer will eventually catch up to a slow pointer if they both start at the beginning and the fast pointer moves twice as fast as the slow pointer. Initialize Pointers: slow pointer starts at head . fast pointer starts at head.next (or head , but head.next is often used to ensure fast is ahead initially). Traverse the List: We iterate using a while loop as long as fast and fast.next are not None . This ensures we don't run into an error if the list ends. In each step, slow moves one step ( slow = slow.next ). fast moves two steps ( fast = fast.next.next ). Cycle Detection: If at any point slow and fast pointers meet (i.e., slow == fast ), it means there is a cycle in the linked list, and we return True . No Cycle: If the loop finishes (meaning fast or fast.next became None ), it implies that fast reached the end of the list without meeting slow . This indicates there is no cycle, and we return False . Time and Space Complexity: Time Complexity: O(N), where N is the number of nodes in the linked list. In the worst case (no cycle or cycle at the very end), the fast pointer traverses the entire list. If there is a cycle, the fast pointer will eventually catch the slow pointer within the cycle. Space Complexity: O(1), as we only use a few extra pointers.","title":"Linked List Cycle"},{"location":"linked_list_cycle/#49-linked-list-cycle","text":"","title":"49. Linked List Cycle"},{"location":"linked_list_cycle/#problem-statement","text":"Given head , the head of a linked list, determine if the linked list has a cycle in it. There is a cycle in a linked list if there is some node in the list that can be reached again by continuously following the next pointers. Internally, pos is used to denote the index of the node that tail's next pointer is connected to. Note that pos is not passed as a parameter. Return true if there is a cycle in the linked list. Otherwise, return false . Example 1: Input: head = [3,2,0,-4], pos = 1 Output: true Explanation: There is a cycle in the linked list, where the tail connects to the 1st node (0-indexed). Example 2: Input: head = [1,2], pos = 0 Output: true Explanation: There is a cycle in the linked list, where the tail connects to the 0th node. Example 3: Input: head = [1], pos = -1 Output: false Explanation: There is no cycle in the linked list.","title":"Problem Statement"},{"location":"linked_list_cycle/#solution","text":"# Definition for singly-linked list. class ListNode : def __init__ ( self , x ): self . val = x self . next = None class Solution : def hasCycle ( self , head : ListNode ) -> bool : if not head or not head . next : return False slow = head fast = head . next while fast and fast . next : if slow == fast : return True slow = slow . next fast = fast . next . next return False","title":"Solution"},{"location":"linked_list_cycle/#explanation","text":"This problem is a classic application of the Floyd's Cycle-Finding Algorithm , also known as the \"tortoise and hare\" algorithm. Core Idea: If there is a cycle in a linked list, a fast pointer will eventually catch up to a slow pointer if they both start at the beginning and the fast pointer moves twice as fast as the slow pointer. Initialize Pointers: slow pointer starts at head . fast pointer starts at head.next (or head , but head.next is often used to ensure fast is ahead initially). Traverse the List: We iterate using a while loop as long as fast and fast.next are not None . This ensures we don't run into an error if the list ends. In each step, slow moves one step ( slow = slow.next ). fast moves two steps ( fast = fast.next.next ). Cycle Detection: If at any point slow and fast pointers meet (i.e., slow == fast ), it means there is a cycle in the linked list, and we return True . No Cycle: If the loop finishes (meaning fast or fast.next became None ), it implies that fast reached the end of the list without meeting slow . This indicates there is no cycle, and we return False . Time and Space Complexity: Time Complexity: O(N), where N is the number of nodes in the linked list. In the worst case (no cycle or cycle at the very end), the fast pointer traverses the entire list. If there is a cycle, the fast pointer will eventually catch the slow pointer within the cycle. Space Complexity: O(1), as we only use a few extra pointers.","title":"Explanation"},{"location":"linked_list_cycle_ii/","text":"50. Linked List Cycle II Problem Statement Given the head of a linked list, return the node where the cycle begins . If there is no cycle, return null . There is a cycle in a linked list if (some node in the list is reached again by continuously following the next pointer) . Internally, pos is used to denote the index of the node that tail's next pointer is connected to. Note that pos is not passed as a parameter. Do not modify the linked list. Example 1: Input: head = [3,2,0,-4], pos = 1 Output: tail connects to node index 1 Explanation: There is a cycle in the linked list, where the tail connects to the 1st node (0-indexed). Example 2: Input: head = [1,2], pos = 0 Output: tail connects to node index 0 Explanation: There is a cycle in the linked list, where the tail connects to the 0th node. Example 3: Input: head = [1], pos = -1 Output: no cycle Explanation: There is no cycle in the linked list. Solution # Definition for singly-linked list. class ListNode : def __init__ ( self , x ): self . val = x self . next = None class Solution : def detectCycle ( self , head : ListNode ) -> ListNode : if not head or not head . next : return None slow = head fast = head # Phase 1: Detect if a cycle exists while fast and fast . next : slow = slow . next fast = fast . next . next if slow == fast : break # Cycle detected else : # No cycle found return None # Phase 2: Find the start of the cycle # Move one pointer to the head, keep the other at the meeting point. # They will meet at the start of the cycle. ptr1 = head ptr2 = slow # or fast, they are at the same point while ptr1 != ptr2 : ptr1 = ptr1 . next ptr2 = ptr2 . next return ptr1 Explanation This problem is a follow-up to \"Linked List Cycle\" and also uses Floyd's Cycle-Finding Algorithm (tortoise and hare). It involves two phases: Phase 1: Detect if a cycle exists Initialize two pointers, slow and fast , both starting at head . Move slow one step at a time ( slow = slow.next ). Move fast two steps at a time ( fast = fast.next.next ). If slow and fast meet at any point, a cycle exists. Break the loop. If fast or fast.next becomes None , it means the end of the list is reached, and there is no cycle. Return None . Phase 2: Find the start of the cycle Once a cycle is detected (i.e., slow and fast have met), we can find the starting node of the cycle using a mathematical property: Move one pointer ( ptr1 ) back to the head of the list. Keep the other pointer ( ptr2 , which is currently at the meeting point) where it is. Move both ptr1 and ptr2 one step at a time. The point where they meet again is the start of the cycle. Why does this work? Let: - D be the distance from the head to the start of the cycle. - L be the length of the cycle. - M be the distance from the start of the cycle to the meeting point. When slow and fast meet: - slow has traveled D + M steps. - fast has traveled D + M + nL steps (where n is some integer, meaning fast has completed n full cycles). Since fast moves twice as fast as slow : 2 * (D + M) = D + M + nL 2D + 2M = D + M + nL D + M = nL D = nL - M D = (n-1)L + (L - M) This equation D = (n-1)L + (L - M) tells us that the distance from the head to the cycle start ( D ) is equal to some number of full cycle lengths plus the distance from the meeting point back to the cycle start ( L - M ). So, if we move one pointer from the head ( ptr1 ) and another from the meeting point ( ptr2 ), they will both reach the cycle start at the same time. Time and Space Complexity: Time Complexity: O(N), where N is the number of nodes in the linked list. Both phases involve traversing the list at most once. Space Complexity: O(1), as we only use a few extra pointers.","title":"Linked List Cycle II"},{"location":"linked_list_cycle_ii/#50-linked-list-cycle-ii","text":"","title":"50. Linked List Cycle II"},{"location":"linked_list_cycle_ii/#problem-statement","text":"Given the head of a linked list, return the node where the cycle begins . If there is no cycle, return null . There is a cycle in a linked list if (some node in the list is reached again by continuously following the next pointer) . Internally, pos is used to denote the index of the node that tail's next pointer is connected to. Note that pos is not passed as a parameter. Do not modify the linked list. Example 1: Input: head = [3,2,0,-4], pos = 1 Output: tail connects to node index 1 Explanation: There is a cycle in the linked list, where the tail connects to the 1st node (0-indexed). Example 2: Input: head = [1,2], pos = 0 Output: tail connects to node index 0 Explanation: There is a cycle in the linked list, where the tail connects to the 0th node. Example 3: Input: head = [1], pos = -1 Output: no cycle Explanation: There is no cycle in the linked list.","title":"Problem Statement"},{"location":"linked_list_cycle_ii/#solution","text":"# Definition for singly-linked list. class ListNode : def __init__ ( self , x ): self . val = x self . next = None class Solution : def detectCycle ( self , head : ListNode ) -> ListNode : if not head or not head . next : return None slow = head fast = head # Phase 1: Detect if a cycle exists while fast and fast . next : slow = slow . next fast = fast . next . next if slow == fast : break # Cycle detected else : # No cycle found return None # Phase 2: Find the start of the cycle # Move one pointer to the head, keep the other at the meeting point. # They will meet at the start of the cycle. ptr1 = head ptr2 = slow # or fast, they are at the same point while ptr1 != ptr2 : ptr1 = ptr1 . next ptr2 = ptr2 . next return ptr1","title":"Solution"},{"location":"linked_list_cycle_ii/#explanation","text":"This problem is a follow-up to \"Linked List Cycle\" and also uses Floyd's Cycle-Finding Algorithm (tortoise and hare). It involves two phases: Phase 1: Detect if a cycle exists Initialize two pointers, slow and fast , both starting at head . Move slow one step at a time ( slow = slow.next ). Move fast two steps at a time ( fast = fast.next.next ). If slow and fast meet at any point, a cycle exists. Break the loop. If fast or fast.next becomes None , it means the end of the list is reached, and there is no cycle. Return None . Phase 2: Find the start of the cycle Once a cycle is detected (i.e., slow and fast have met), we can find the starting node of the cycle using a mathematical property: Move one pointer ( ptr1 ) back to the head of the list. Keep the other pointer ( ptr2 , which is currently at the meeting point) where it is. Move both ptr1 and ptr2 one step at a time. The point where they meet again is the start of the cycle. Why does this work? Let: - D be the distance from the head to the start of the cycle. - L be the length of the cycle. - M be the distance from the start of the cycle to the meeting point. When slow and fast meet: - slow has traveled D + M steps. - fast has traveled D + M + nL steps (where n is some integer, meaning fast has completed n full cycles). Since fast moves twice as fast as slow : 2 * (D + M) = D + M + nL 2D + 2M = D + M + nL D + M = nL D = nL - M D = (n-1)L + (L - M) This equation D = (n-1)L + (L - M) tells us that the distance from the head to the cycle start ( D ) is equal to some number of full cycle lengths plus the distance from the meeting point back to the cycle start ( L - M ). So, if we move one pointer from the head ( ptr1 ) and another from the meeting point ( ptr2 ), they will both reach the cycle start at the same time. Time and Space Complexity: Time Complexity: O(N), where N is the number of nodes in the linked list. Both phases involve traversing the list at most once. Space Complexity: O(1), as we only use a few extra pointers.","title":"Explanation"},{"location":"longest_common_subsequence/","text":"19. Longest Common Subsequence Problem Statement Given two strings text1 and text2 , return the length of their longest common subsequence . If there is no common subsequence, return 0 . A subsequence of a string is a new string generated from the original string with some characters (can be none) deleted without changing the relative order of the remaining characters. For example, \"ace\" is a subsequence of \"abcde\" . A common subsequence of two strings is a subsequence that is common to both strings. Example 1: Input: text1 = \"abcde\", text2 = \"ace\" Output: 3 Explanation: The longest common subsequence is \"ace\" and its length is 3. Example 2: Input: text1 = \"abc\", text2 = \"abc\" Output: 3 Explanation: The longest common subsequence is \"abc\" and its length is 3. Example 3: Input: text1 = \"abc\", text2 = \"def\" Output: 0 Explanation: There is no common subsequence, so the result is 0. Solution class Solution : def longestCommonSubsequence ( self , text1 : str , text2 : str ) -> int : m , n = len ( text1 ), len ( text2 ) # Create a DP table # dp[i][j] will be the length of the LCS of text1[0..i-1] and text2[0..j-1] dp = [[ 0 ] * ( n + 1 ) for _ in range ( m + 1 )] for i in range ( 1 , m + 1 ): for j in range ( 1 , n + 1 ): if text1 [ i - 1 ] == text2 [ j - 1 ]: # If characters match, extend the LCS from the previous diagonal dp [ i ][ j ] = 1 + dp [ i - 1 ][ j - 1 ] else : # If they don't match, take the max from the top or left cell dp [ i ][ j ] = max ( dp [ i - 1 ][ j ], dp [ i ][ j - 1 ]) return dp [ m ][ n ] Explanation This is a classic dynamic programming problem that can be solved using a 2D DP table. Let dp[i][j] be the length of the longest common subsequence (LCS) between the first i characters of text1 and the first j characters of text2 . Initialization: We create a (m+1) x (n+1) DP table, where m and n are the lengths of the strings. The table is initialized to zeros. DP Relation: We fill the table based on the following logic: If the characters text1[i-1] and text2[j-1] are the same, then the LCS is one character longer than the LCS of the strings without these characters ( text1[0..i-2] and text2[0..j-2] ). So, dp[i][j] = 1 + dp[i-1][j-1] . If the characters are different, the LCS is the same as the LCS of either text1[0..i-1] and text2[0..j-2] ( dp[i][j-1] ) or text1[0..i-2] and text2[0..j-1] ( dp[i-1][j] ). We take the maximum of these two. Final Result: The value at dp[m][n] will be the length of the LCS for the entire text1 and text2 . The time complexity is O(m n) due to the nested loops for filling the DP table. The space complexity is also O(m n) for the table itself. (Space Optimization) We can optimize the space to O(min(m, n)) because each cell dp[i][j] only depends on the previous row and the current row. We can use two rows (or even one row with a temporary variable) to store the necessary values.","title":"Longest Common Subsequence"},{"location":"longest_common_subsequence/#19-longest-common-subsequence","text":"","title":"19. Longest Common Subsequence"},{"location":"longest_common_subsequence/#problem-statement","text":"Given two strings text1 and text2 , return the length of their longest common subsequence . If there is no common subsequence, return 0 . A subsequence of a string is a new string generated from the original string with some characters (can be none) deleted without changing the relative order of the remaining characters. For example, \"ace\" is a subsequence of \"abcde\" . A common subsequence of two strings is a subsequence that is common to both strings. Example 1: Input: text1 = \"abcde\", text2 = \"ace\" Output: 3 Explanation: The longest common subsequence is \"ace\" and its length is 3. Example 2: Input: text1 = \"abc\", text2 = \"abc\" Output: 3 Explanation: The longest common subsequence is \"abc\" and its length is 3. Example 3: Input: text1 = \"abc\", text2 = \"def\" Output: 0 Explanation: There is no common subsequence, so the result is 0.","title":"Problem Statement"},{"location":"longest_common_subsequence/#solution","text":"class Solution : def longestCommonSubsequence ( self , text1 : str , text2 : str ) -> int : m , n = len ( text1 ), len ( text2 ) # Create a DP table # dp[i][j] will be the length of the LCS of text1[0..i-1] and text2[0..j-1] dp = [[ 0 ] * ( n + 1 ) for _ in range ( m + 1 )] for i in range ( 1 , m + 1 ): for j in range ( 1 , n + 1 ): if text1 [ i - 1 ] == text2 [ j - 1 ]: # If characters match, extend the LCS from the previous diagonal dp [ i ][ j ] = 1 + dp [ i - 1 ][ j - 1 ] else : # If they don't match, take the max from the top or left cell dp [ i ][ j ] = max ( dp [ i - 1 ][ j ], dp [ i ][ j - 1 ]) return dp [ m ][ n ]","title":"Solution"},{"location":"longest_common_subsequence/#explanation","text":"This is a classic dynamic programming problem that can be solved using a 2D DP table. Let dp[i][j] be the length of the longest common subsequence (LCS) between the first i characters of text1 and the first j characters of text2 . Initialization: We create a (m+1) x (n+1) DP table, where m and n are the lengths of the strings. The table is initialized to zeros. DP Relation: We fill the table based on the following logic: If the characters text1[i-1] and text2[j-1] are the same, then the LCS is one character longer than the LCS of the strings without these characters ( text1[0..i-2] and text2[0..j-2] ). So, dp[i][j] = 1 + dp[i-1][j-1] . If the characters are different, the LCS is the same as the LCS of either text1[0..i-1] and text2[0..j-2] ( dp[i][j-1] ) or text1[0..i-2] and text2[0..j-1] ( dp[i-1][j] ). We take the maximum of these two. Final Result: The value at dp[m][n] will be the length of the LCS for the entire text1 and text2 . The time complexity is O(m n) due to the nested loops for filling the DP table. The space complexity is also O(m n) for the table itself. (Space Optimization) We can optimize the space to O(min(m, n)) because each cell dp[i][j] only depends on the previous row and the current row. We can use two rows (or even one row with a temporary variable) to store the necessary values.","title":"Explanation"},{"location":"longest_increasing_subsequence/","text":"18. Longest Increasing Subsequence Problem Statement Given an integer array nums , return the length of the longest strictly increasing subsequence . Example 1: Input: nums = [10,9,2,5,3,7,101,18] Output: 4 Explanation: The longest increasing subsequence is [2,3,7,101], therefore the length is 4. Example 2: Input: nums = [0,1,0,3,2,3] Output: 4 Example 3: Input: nums = [7,7,7,7,7,7,7] Output: 1 Solution import bisect class Solution : def lengthOfLIS ( self , nums : list [ int ]) -> int : # This list will store the smallest tail of all increasing subsequences # with length i+1 in tails[i]. tails = [] for num in nums : # Find the first position where num can be inserted to maintain order i = bisect . bisect_left ( tails , num ) if i == len ( tails ): # If num is greater than all elements in tails, extend the subsequence tails . append ( num ) else : # Replace the tail of an existing subsequence with a smaller number # This allows for potentially longer subsequences later on tails [ i ] = num return len ( tails ) Explanation This problem can be solved with a clever approach that uses both dynamic programming and binary search, resulting in an O(n log n) time complexity. The core idea is to maintain a list called tails . This list stores the smallest tail of all increasing subsequences with a certain length. tails[i] will be the smallest tail of an increasing subsequence of length i+1 . Let's trace nums = [10, 9, 2, 5, 3, 7, 101, 18] : num = 10 : tails is [] . i=0 . tails becomes [10] . num = 9 : tails is [10] . i=0 . tails becomes [9] (replace 10). num = 2 : tails is [9] . i=0 . tails becomes [2] (replace 9). num = 5 : tails is [2] . i=1 . tails becomes [2, 5] . num = 3 : tails is [2, 5] . i=1 . tails becomes [2, 3] (replace 5). num = 7 : tails is [2, 3] . i=2 . tails becomes [2, 3, 7] . num = 101 : tails is [2, 3, 7] . i=3 . tails becomes [2, 3, 7, 101] . num = 18 : tails is [2, 3, 7, 101] . i=3 . tails becomes [2, 3, 7, 18] (replace 101). The final tails list is [2, 3, 7, 18] . The length of this list, 4, is the length of the longest increasing subsequence. We use bisect.bisect_left to perform the binary search efficiently. This finds the insertion point for num in tails to keep it sorted. This is the key to the O(n log n) performance. The space complexity is O(n) for the tails list.","title":"Longest Increasing Subsequence"},{"location":"longest_increasing_subsequence/#18-longest-increasing-subsequence","text":"","title":"18. Longest Increasing Subsequence"},{"location":"longest_increasing_subsequence/#problem-statement","text":"Given an integer array nums , return the length of the longest strictly increasing subsequence . Example 1: Input: nums = [10,9,2,5,3,7,101,18] Output: 4 Explanation: The longest increasing subsequence is [2,3,7,101], therefore the length is 4. Example 2: Input: nums = [0,1,0,3,2,3] Output: 4 Example 3: Input: nums = [7,7,7,7,7,7,7] Output: 1","title":"Problem Statement"},{"location":"longest_increasing_subsequence/#solution","text":"import bisect class Solution : def lengthOfLIS ( self , nums : list [ int ]) -> int : # This list will store the smallest tail of all increasing subsequences # with length i+1 in tails[i]. tails = [] for num in nums : # Find the first position where num can be inserted to maintain order i = bisect . bisect_left ( tails , num ) if i == len ( tails ): # If num is greater than all elements in tails, extend the subsequence tails . append ( num ) else : # Replace the tail of an existing subsequence with a smaller number # This allows for potentially longer subsequences later on tails [ i ] = num return len ( tails )","title":"Solution"},{"location":"longest_increasing_subsequence/#explanation","text":"This problem can be solved with a clever approach that uses both dynamic programming and binary search, resulting in an O(n log n) time complexity. The core idea is to maintain a list called tails . This list stores the smallest tail of all increasing subsequences with a certain length. tails[i] will be the smallest tail of an increasing subsequence of length i+1 . Let's trace nums = [10, 9, 2, 5, 3, 7, 101, 18] : num = 10 : tails is [] . i=0 . tails becomes [10] . num = 9 : tails is [10] . i=0 . tails becomes [9] (replace 10). num = 2 : tails is [9] . i=0 . tails becomes [2] (replace 9). num = 5 : tails is [2] . i=1 . tails becomes [2, 5] . num = 3 : tails is [2, 5] . i=1 . tails becomes [2, 3] (replace 5). num = 7 : tails is [2, 3] . i=2 . tails becomes [2, 3, 7] . num = 101 : tails is [2, 3, 7] . i=3 . tails becomes [2, 3, 7, 101] . num = 18 : tails is [2, 3, 7, 101] . i=3 . tails becomes [2, 3, 7, 18] (replace 101). The final tails list is [2, 3, 7, 18] . The length of this list, 4, is the length of the longest increasing subsequence. We use bisect.bisect_left to perform the binary search efficiently. This finds the insertion point for num in tails to keep it sorted. This is the key to the O(n log n) performance. The space complexity is O(n) for the tails list.","title":"Explanation"},{"location":"longest_palindrome/","text":"41. Longest Palindrome Problem Statement Given a string s which consists of lowercase or uppercase English letters, return the length of the longest palindrome that can be built with those letters . Letters are case sensitive, for example, \"Aa\" is not considered a palindrome here. Example 1: Input: s = \"abccccdd\" Output: 7 Explanation: One longest palindrome that can be built is \"dccaccd\", whose length is 7. Example 2: Input: s = \"a\" Output: 1 Example 3: Input: s = \"bb\" Output: 2 Solution from collections import Counter class Solution : def longestPalindrome ( self , s : str ) -> int : char_counts = Counter ( s ) length = 0 has_odd = False for count in char_counts . values (): if count % 2 == 0 : length += count else : # If a character appears an odd number of times, # we can use all but one of its occurrences to form pairs. length += count - 1 # We can use one character with an odd count as the center # of the palindrome. has_odd = True # If there was at least one character with an odd count, # we can add 1 to the total length for the center character. if has_odd : length += 1 return length Explanation To form the longest possible palindrome from a given set of characters, we can use all characters that appear an even number of times. For characters that appear an odd number of times, we can use all but one of their occurrences to form pairs, and then use one of these characters as the center of the palindrome. Algorithm: Count Character Frequencies: Use a Counter (or a hash map) to count the occurrences of each character in the input string s . Build Palindrome Length: Iterate through the counts of each character: If a character's count is even, we can use all of its occurrences to form pairs, so we add count to our length . If a character's count is odd, we can use count - 1 of its occurrences to form pairs. We add count - 1 to our length . We also set a flag has_odd to True , indicating that we have at least one character that can serve as the center of the palindrome. Add Center Character: After iterating through all characters, if has_odd is True , it means we have at least one character that appeared an odd number of times. We can use one of these as the central character of our palindrome, increasing the total length by 1. Example: s = \"abccccdd\" a : 1 (odd) -> length = 0 , has_odd = True b : 1 (odd) -> length = 0 , has_odd = True c : 4 (even) -> length = 4 d : 2 (even) -> length = 4 + 2 = 6 After loop: length = 6 , has_odd = True . Add 1 for the center: length = 7 . This approach has a time complexity of O(n) for counting characters and O(k) for iterating through the unique characters (where k is the size of the alphabet, which is constant). So, overall O(n). The space complexity is O(k) for the Counter .","title":"Longest Palindrome"},{"location":"longest_palindrome/#41-longest-palindrome","text":"","title":"41. Longest Palindrome"},{"location":"longest_palindrome/#problem-statement","text":"Given a string s which consists of lowercase or uppercase English letters, return the length of the longest palindrome that can be built with those letters . Letters are case sensitive, for example, \"Aa\" is not considered a palindrome here. Example 1: Input: s = \"abccccdd\" Output: 7 Explanation: One longest palindrome that can be built is \"dccaccd\", whose length is 7. Example 2: Input: s = \"a\" Output: 1 Example 3: Input: s = \"bb\" Output: 2","title":"Problem Statement"},{"location":"longest_palindrome/#solution","text":"from collections import Counter class Solution : def longestPalindrome ( self , s : str ) -> int : char_counts = Counter ( s ) length = 0 has_odd = False for count in char_counts . values (): if count % 2 == 0 : length += count else : # If a character appears an odd number of times, # we can use all but one of its occurrences to form pairs. length += count - 1 # We can use one character with an odd count as the center # of the palindrome. has_odd = True # If there was at least one character with an odd count, # we can add 1 to the total length for the center character. if has_odd : length += 1 return length","title":"Solution"},{"location":"longest_palindrome/#explanation","text":"To form the longest possible palindrome from a given set of characters, we can use all characters that appear an even number of times. For characters that appear an odd number of times, we can use all but one of their occurrences to form pairs, and then use one of these characters as the center of the palindrome. Algorithm: Count Character Frequencies: Use a Counter (or a hash map) to count the occurrences of each character in the input string s . Build Palindrome Length: Iterate through the counts of each character: If a character's count is even, we can use all of its occurrences to form pairs, so we add count to our length . If a character's count is odd, we can use count - 1 of its occurrences to form pairs. We add count - 1 to our length . We also set a flag has_odd to True , indicating that we have at least one character that can serve as the center of the palindrome. Add Center Character: After iterating through all characters, if has_odd is True , it means we have at least one character that appeared an odd number of times. We can use one of these as the central character of our palindrome, increasing the total length by 1. Example: s = \"abccccdd\" a : 1 (odd) -> length = 0 , has_odd = True b : 1 (odd) -> length = 0 , has_odd = True c : 4 (even) -> length = 4 d : 2 (even) -> length = 4 + 2 = 6 After loop: length = 6 , has_odd = True . Add 1 for the center: length = 7 . This approach has a time complexity of O(n) for counting characters and O(k) for iterating through the unique characters (where k is the size of the alphabet, which is constant). So, overall O(n). The space complexity is O(k) for the Counter .","title":"Explanation"},{"location":"longest_palindromic_substring/","text":"31. Longest Palindromic Substring Problem Statement Given a string s , return the longest palindromic substring in s . Example 1: Input: s = \"babad\" Output: \"bab\" Explanation: \"aba\" is also a valid answer. Example 2: Input: s = \"cbbd\" Output: \"bb\" Solution class Solution : def longestPalindrome ( self , s : str ) -> str : if not s : return \"\" start , end = 0 , 0 def expand_around_center ( left , right ): while left >= 0 and right < len ( s ) and s [ left ] == s [ right ]: left -= 1 right += 1 return left + 1 , right - 1 for i in range ( len ( s )): # Odd length palindromes (e.g., \"aba\") l1 , r1 = expand_around_center ( i , i ) # Even length palindromes (e.g., \"abba\") l2 , r2 = expand_around_center ( i , i + 1 ) # Compare lengths and update start, end if ( r1 - l1 ) > ( end - start ): start , end = l1 , r1 if ( r2 - l2 ) > ( end - start ): start , end = l2 , r2 return s [ start : end + 1 ] Explanation This problem can be solved using the \"expand around center\" approach. A palindrome is a string that reads the same forwards and backward. This means it has a center. A palindrome can have either an odd length (e.g., \"aba\", center is 'b') or an even length (e.g., \"abba\", center is between the two 'b's). The algorithm iterates through each character of the string, treating it as a potential center of a palindrome. For each character, it considers two cases: Odd Length Palindromes: The center is a single character ( s[i] ). We expand outwards from i ( left = i , right = i ). Even Length Palindromes: The center is between two characters ( s[i] and s[i+1] ). We expand outwards from i and i+1 ( left = i , right = i + 1 ). The expand_around_center helper function takes left and right pointers and expands them as long as the characters at s[left] and s[right] match and are within the string boundaries. It returns the final left and right indices of the palindrome found. We keep track of the start and end indices of the longest palindrome found so far and update them whenever a longer palindrome is discovered. The time complexity is O(n^2) because we iterate through each character (n) and for each character, we expand outwards (up to n/2 times). The space complexity is O(1).","title":"Longest Palindromic Substring"},{"location":"longest_palindromic_substring/#31-longest-palindromic-substring","text":"","title":"31. Longest Palindromic Substring"},{"location":"longest_palindromic_substring/#problem-statement","text":"Given a string s , return the longest palindromic substring in s . Example 1: Input: s = \"babad\" Output: \"bab\" Explanation: \"aba\" is also a valid answer. Example 2: Input: s = \"cbbd\" Output: \"bb\"","title":"Problem Statement"},{"location":"longest_palindromic_substring/#solution","text":"class Solution : def longestPalindrome ( self , s : str ) -> str : if not s : return \"\" start , end = 0 , 0 def expand_around_center ( left , right ): while left >= 0 and right < len ( s ) and s [ left ] == s [ right ]: left -= 1 right += 1 return left + 1 , right - 1 for i in range ( len ( s )): # Odd length palindromes (e.g., \"aba\") l1 , r1 = expand_around_center ( i , i ) # Even length palindromes (e.g., \"abba\") l2 , r2 = expand_around_center ( i , i + 1 ) # Compare lengths and update start, end if ( r1 - l1 ) > ( end - start ): start , end = l1 , r1 if ( r2 - l2 ) > ( end - start ): start , end = l2 , r2 return s [ start : end + 1 ]","title":"Solution"},{"location":"longest_palindromic_substring/#explanation","text":"This problem can be solved using the \"expand around center\" approach. A palindrome is a string that reads the same forwards and backward. This means it has a center. A palindrome can have either an odd length (e.g., \"aba\", center is 'b') or an even length (e.g., \"abba\", center is between the two 'b's). The algorithm iterates through each character of the string, treating it as a potential center of a palindrome. For each character, it considers two cases: Odd Length Palindromes: The center is a single character ( s[i] ). We expand outwards from i ( left = i , right = i ). Even Length Palindromes: The center is between two characters ( s[i] and s[i+1] ). We expand outwards from i and i+1 ( left = i , right = i + 1 ). The expand_around_center helper function takes left and right pointers and expands them as long as the characters at s[left] and s[right] match and are within the string boundaries. It returns the final left and right indices of the palindrome found. We keep track of the start and end indices of the longest palindrome found so far and update them whenever a longer palindrome is discovered. The time complexity is O(n^2) because we iterate through each character (n) and for each character, we expand outwards (up to n/2 times). The space complexity is O(1).","title":"Explanation"},{"location":"longest_repeating_character_replacement/","text":"34. Longest Repeating Character Replacement Problem Statement You are given a string s and an integer k . You can choose any character of the string and change it to any other uppercase English character any number of times. You can perform this operation at most k times. Return the length of the longest substring containing the same letter you can get after performing the above operations . Example 1: Input: s = \"ABAB\", k = 2 Output: 4 Explanation: Replace the two 'A's with two 'B's or vice versa. Example 2: Input: s = \"AABABBA\", k = 1 Output: 4 Explanation: Replace the one 'A' in the middle with 'B' and form \"AABBBBA\". The substring \"BBBB\" has a length of 4. Solution from collections import defaultdict class Solution : def characterReplacement ( self , s : str , k : int ) -> int : char_counts = defaultdict ( int ) left = 0 max_freq = 0 max_len = 0 for right in range ( len ( s )): char_counts [ s [ right ]] += 1 max_freq = max ( max_freq , char_counts [ s [ right ]]) # Current window size - count of most frequent char in window # This difference is the number of characters that need to be replaced. # If this is greater than k, we need to shrink the window. if ( right - left + 1 ) - max_freq > k : char_counts [ s [ left ]] -= 1 left += 1 max_len = max ( max_len , right - left + 1 ) return max_len Explanation This problem can be solved using a sliding window approach. The goal is to find the longest substring where, after at most k replacements, all characters in that substring become the same. Key Idea: In any valid window (substring), the number of characters that are not the most frequent character in that window must be less than or equal to k . Sliding Window: We use a window defined by left and right pointers. Character Counts: We maintain a frequency map ( char_counts ) of characters within the current window. max_freq : We also keep track of max_freq , which is the count of the most frequent character within the current window. Algorithm: We expand the window by moving right one step at a time. For each s[right] , we increment its count in char_counts and update max_freq . We then check the condition: (current_window_size - max_freq) > k . current_window_size is right - left + 1 . current_window_size - max_freq represents the number of characters in the current window that are different from the most frequent character. These are the characters we would need to replace. If this value exceeds k , it means our current window is invalid. We need to shrink the window from the left side by decrementing the count of s[left] and incrementing left . We update max_len with the maximum length of a valid window found so far. This greedy approach works because we are always trying to expand the window as much as possible. When the window becomes invalid, we shrink it just enough to make it valid again. The max_freq doesn't necessarily need to be re-calculated for the entire window when left moves, because if a previous max_freq was higher, it means we had a longer valid window at that point, and we are only interested in the maximum length. The time complexity is O(n) because both left and right pointers traverse the string at most once. The space complexity is O(1) because the char_counts map will store at most 26 uppercase English letters.","title":"Longest Repeating Character Replacement"},{"location":"longest_repeating_character_replacement/#34-longest-repeating-character-replacement","text":"","title":"34. Longest Repeating Character Replacement"},{"location":"longest_repeating_character_replacement/#problem-statement","text":"You are given a string s and an integer k . You can choose any character of the string and change it to any other uppercase English character any number of times. You can perform this operation at most k times. Return the length of the longest substring containing the same letter you can get after performing the above operations . Example 1: Input: s = \"ABAB\", k = 2 Output: 4 Explanation: Replace the two 'A's with two 'B's or vice versa. Example 2: Input: s = \"AABABBA\", k = 1 Output: 4 Explanation: Replace the one 'A' in the middle with 'B' and form \"AABBBBA\". The substring \"BBBB\" has a length of 4.","title":"Problem Statement"},{"location":"longest_repeating_character_replacement/#solution","text":"from collections import defaultdict class Solution : def characterReplacement ( self , s : str , k : int ) -> int : char_counts = defaultdict ( int ) left = 0 max_freq = 0 max_len = 0 for right in range ( len ( s )): char_counts [ s [ right ]] += 1 max_freq = max ( max_freq , char_counts [ s [ right ]]) # Current window size - count of most frequent char in window # This difference is the number of characters that need to be replaced. # If this is greater than k, we need to shrink the window. if ( right - left + 1 ) - max_freq > k : char_counts [ s [ left ]] -= 1 left += 1 max_len = max ( max_len , right - left + 1 ) return max_len","title":"Solution"},{"location":"longest_repeating_character_replacement/#explanation","text":"This problem can be solved using a sliding window approach. The goal is to find the longest substring where, after at most k replacements, all characters in that substring become the same. Key Idea: In any valid window (substring), the number of characters that are not the most frequent character in that window must be less than or equal to k . Sliding Window: We use a window defined by left and right pointers. Character Counts: We maintain a frequency map ( char_counts ) of characters within the current window. max_freq : We also keep track of max_freq , which is the count of the most frequent character within the current window. Algorithm: We expand the window by moving right one step at a time. For each s[right] , we increment its count in char_counts and update max_freq . We then check the condition: (current_window_size - max_freq) > k . current_window_size is right - left + 1 . current_window_size - max_freq represents the number of characters in the current window that are different from the most frequent character. These are the characters we would need to replace. If this value exceeds k , it means our current window is invalid. We need to shrink the window from the left side by decrementing the count of s[left] and incrementing left . We update max_len with the maximum length of a valid window found so far. This greedy approach works because we are always trying to expand the window as much as possible. When the window becomes invalid, we shrink it just enough to make it valid again. The max_freq doesn't necessarily need to be re-calculated for the entire window when left moves, because if a previous max_freq was higher, it means we had a longer valid window at that point, and we are only interested in the maximum length. The time complexity is O(n) because both left and right pointers traverse the string at most once. The space complexity is O(1) because the char_counts map will store at most 26 uppercase English letters.","title":"Explanation"},{"location":"longest_substring_without_repeating_characters/","text":"33. Longest Substring Without Repeating Characters Problem Statement Given a string s , find the length of the longest substring without repeating characters. Example 1: Input: s = \"abcabcbb\" Output: 3 Explanation: The answer is \"abc\", with the length of 3. Example 2: Input: s = \"bbbbb\" Output: 1 Explanation: The answer is \"b\", with the length of 1. Example 3: Input: s = \"pwwkew\" Output: 3 Explanation: The answer is \"wke\", with the length of 3. Notice that the answer must be a substring, \"pwke\" is a subsequence and not a substring. Solution class Solution : def lengthOfLongestSubstring ( self , s : str ) -> int : char_set = set () left = 0 max_len = 0 for right in range ( len ( s )): while s [ right ] in char_set : char_set . remove ( s [ left ]) left += 1 char_set . add ( s [ right ]) max_len = max ( max_len , right - left + 1 ) return max_len Explanation This problem can be efficiently solved using a sliding window approach with a hash set. Sliding Window: We maintain a window [left, right] that represents the current substring without repeating characters. Hash Set ( char_set ): We use a hash set to store the characters currently within our window. This allows for O(1) average time complexity for checking if a character is already in the window and for adding/removing characters. Algorithm: We initialize left to 0 and max_len to 0. We iterate with right from the beginning of the string to the end. For each s[right] : Check for Duplicates: If s[right] is already in char_set , it means we have a repeating character. To resolve this, we shrink the window from the left side by removing s[left] from char_set and incrementing left , until the duplicate is removed. Add Current Character: Once s[right] is not in char_set (or after removing the duplicate), we add s[right] to char_set . Update Max Length: We then update max_len with the maximum of its current value and the current window size ( right - left + 1 ). This approach ensures that at any point, our window [left, right] contains only unique characters. The time complexity is O(n) because both left and right pointers traverse the string at most once. The space complexity is O(min(n, alphabet_size)) for the hash set.","title":"Longest Substring Without Repeating Characters"},{"location":"longest_substring_without_repeating_characters/#33-longest-substring-without-repeating-characters","text":"","title":"33. Longest Substring Without Repeating Characters"},{"location":"longest_substring_without_repeating_characters/#problem-statement","text":"Given a string s , find the length of the longest substring without repeating characters. Example 1: Input: s = \"abcabcbb\" Output: 3 Explanation: The answer is \"abc\", with the length of 3. Example 2: Input: s = \"bbbbb\" Output: 1 Explanation: The answer is \"b\", with the length of 1. Example 3: Input: s = \"pwwkew\" Output: 3 Explanation: The answer is \"wke\", with the length of 3. Notice that the answer must be a substring, \"pwke\" is a subsequence and not a substring.","title":"Problem Statement"},{"location":"longest_substring_without_repeating_characters/#solution","text":"class Solution : def lengthOfLongestSubstring ( self , s : str ) -> int : char_set = set () left = 0 max_len = 0 for right in range ( len ( s )): while s [ right ] in char_set : char_set . remove ( s [ left ]) left += 1 char_set . add ( s [ right ]) max_len = max ( max_len , right - left + 1 ) return max_len","title":"Solution"},{"location":"longest_substring_without_repeating_characters/#explanation","text":"This problem can be efficiently solved using a sliding window approach with a hash set. Sliding Window: We maintain a window [left, right] that represents the current substring without repeating characters. Hash Set ( char_set ): We use a hash set to store the characters currently within our window. This allows for O(1) average time complexity for checking if a character is already in the window and for adding/removing characters. Algorithm: We initialize left to 0 and max_len to 0. We iterate with right from the beginning of the string to the end. For each s[right] : Check for Duplicates: If s[right] is already in char_set , it means we have a repeating character. To resolve this, we shrink the window from the left side by removing s[left] from char_set and incrementing left , until the duplicate is removed. Add Current Character: Once s[right] is not in char_set (or after removing the duplicate), we add s[right] to char_set . Update Max Length: We then update max_len with the maximum of its current value and the current window size ( right - left + 1 ). This approach ensures that at any point, our window [left, right] contains only unique characters. The time complexity is O(n) because both left and right pointers traverse the string at most once. The space complexity is O(min(n, alphabet_size)) for the hash set.","title":"Explanation"},{"location":"lowest_common_ancestor_of_a_binary_search_tree/","text":"61. Lowest Common Ancestor of a Binary Search Tree Problem Statement Given a Binary Search Tree (BST), find the lowest common ancestor (LCA) of two given nodes in the BST. According to the definition of LCA on Wikipedia: \"The lowest common ancestor is defined between two nodes p and q as the lowest node in T that has both p and q as descendants (where we allow a node to be a descendant of itself).\" Example 1: Input: root = [6,2,8,0,4,7,9,null,null,3,5], p = 2, q = 8 Output: 6 Explanation: The LCA of nodes 2 and 8 is 6. Example 2: Input: root = [6,2,8,0,4,7,9,null,null,3,5], p = 2, q = 4 Output: 2 Explanation: The LCA of nodes 2 and 4 is 2, since a node can be a descendant of itself according to the LCA definition. Example 3: Input: root = [2,1], p = 2, q = 1 Output: 2 Solution # Definition for a binary tree node. class TreeNode : def __init__ ( self , x ): self . val = x self . left = None self . right = None class Solution : def lowestCommonAncestor ( self , root : 'TreeNode' , p : 'TreeNode' , q : 'TreeNode' ) -> 'TreeNode' : # If both p and q are smaller than the current root, then LCA must be in the left subtree if p . val < root . val and q . val < root . val : return self . lowestCommonAncestor ( root . left , p , q ) # If both p and q are larger than the current root, then LCA must be in the right subtree elif p . val > root . val and q . val > root . val : return self . lowestCommonAncestor ( root . right , p , q ) # If one is smaller and the other is larger, or one of them is the root itself, # then the current root is the LCA. else : return root Explanation This problem leverages the special property of a Binary Search Tree (BST): for any node, all values in its left subtree are smaller, and all values in its right subtree are larger. Core Idea: The lowest common ancestor (LCA) of two nodes p and q in a BST will be the first node encountered during a traversal from the root where p and q are on opposite sides (one in the left subtree, one in the right subtree), or where one of p or q is the current node. Recursive Approach: Both p and q are smaller than root.val : If both p.val and q.val are less than the current root.val , it means both p and q must reside in the left subtree of the current root . Therefore, the LCA must also be in the left subtree, so we recursively call lowestCommonAncestor on root.left . Both p and q are larger than root.val : Similarly, if both p.val and q.val are greater than the current root.val , they must both reside in the right subtree. We recursively call lowestCommonAncestor on root.right . One is smaller, one is larger, or one is the root itself: If neither of the above conditions is met, it means one of the following is true: p.val < root.val and q.val > root.val (or vice versa): p and q are on opposite sides of the current root . This means the current root is their LCA. p.val == root.val or q.val == root.val : One of the target nodes is the current root . According to the definition, a node can be a descendant of itself, so the current root is the LCA. In all these cases, the current root is the LCA, so we return root . Time and Space Complexity: Time Complexity: O(H), where H is the height of the BST. In the worst case (a skewed tree), H can be N (number of nodes), leading to O(N). In a balanced BST, H is log N, leading to O(log N). Space Complexity: O(H) for the recursion stack. In the worst case, O(N), and in a balanced tree, O(log N).","title":"Lowest Common Ancestor of a Binary Search Tree"},{"location":"lowest_common_ancestor_of_a_binary_search_tree/#61-lowest-common-ancestor-of-a-binary-search-tree","text":"","title":"61. Lowest Common Ancestor of a Binary Search Tree"},{"location":"lowest_common_ancestor_of_a_binary_search_tree/#problem-statement","text":"Given a Binary Search Tree (BST), find the lowest common ancestor (LCA) of two given nodes in the BST. According to the definition of LCA on Wikipedia: \"The lowest common ancestor is defined between two nodes p and q as the lowest node in T that has both p and q as descendants (where we allow a node to be a descendant of itself).\" Example 1: Input: root = [6,2,8,0,4,7,9,null,null,3,5], p = 2, q = 8 Output: 6 Explanation: The LCA of nodes 2 and 8 is 6. Example 2: Input: root = [6,2,8,0,4,7,9,null,null,3,5], p = 2, q = 4 Output: 2 Explanation: The LCA of nodes 2 and 4 is 2, since a node can be a descendant of itself according to the LCA definition. Example 3: Input: root = [2,1], p = 2, q = 1 Output: 2","title":"Problem Statement"},{"location":"lowest_common_ancestor_of_a_binary_search_tree/#solution","text":"# Definition for a binary tree node. class TreeNode : def __init__ ( self , x ): self . val = x self . left = None self . right = None class Solution : def lowestCommonAncestor ( self , root : 'TreeNode' , p : 'TreeNode' , q : 'TreeNode' ) -> 'TreeNode' : # If both p and q are smaller than the current root, then LCA must be in the left subtree if p . val < root . val and q . val < root . val : return self . lowestCommonAncestor ( root . left , p , q ) # If both p and q are larger than the current root, then LCA must be in the right subtree elif p . val > root . val and q . val > root . val : return self . lowestCommonAncestor ( root . right , p , q ) # If one is smaller and the other is larger, or one of them is the root itself, # then the current root is the LCA. else : return root","title":"Solution"},{"location":"lowest_common_ancestor_of_a_binary_search_tree/#explanation","text":"This problem leverages the special property of a Binary Search Tree (BST): for any node, all values in its left subtree are smaller, and all values in its right subtree are larger. Core Idea: The lowest common ancestor (LCA) of two nodes p and q in a BST will be the first node encountered during a traversal from the root where p and q are on opposite sides (one in the left subtree, one in the right subtree), or where one of p or q is the current node. Recursive Approach: Both p and q are smaller than root.val : If both p.val and q.val are less than the current root.val , it means both p and q must reside in the left subtree of the current root . Therefore, the LCA must also be in the left subtree, so we recursively call lowestCommonAncestor on root.left . Both p and q are larger than root.val : Similarly, if both p.val and q.val are greater than the current root.val , they must both reside in the right subtree. We recursively call lowestCommonAncestor on root.right . One is smaller, one is larger, or one is the root itself: If neither of the above conditions is met, it means one of the following is true: p.val < root.val and q.val > root.val (or vice versa): p and q are on opposite sides of the current root . This means the current root is their LCA. p.val == root.val or q.val == root.val : One of the target nodes is the current root . According to the definition, a node can be a descendant of itself, so the current root is the LCA. In all these cases, the current root is the LCA, so we return root . Time and Space Complexity: Time Complexity: O(H), where H is the height of the BST. In the worst case (a skewed tree), H can be N (number of nodes), leading to O(N). In a balanced BST, H is log N, leading to O(log N). Space Complexity: O(H) for the recursion stack. In the worst case, O(N), and in a balanced tree, O(log N).","title":"Explanation"},{"location":"lowest_common_ancestor_of_a_binary_tree/","text":"68. Lowest Common Ancestor of a Binary Tree Problem Statement Given a binary tree, find the lowest common ancestor (LCA) of two given nodes in the tree. According to the definition of LCA on Wikipedia: \"The lowest common ancestor is defined between two nodes p and q as the lowest node in T that has both p and q as descendants (where we allow a node to be a descendant of itself).\" Example 1: Input: root = [3,5,1,6,2,0,8,null,null,7,4], p = 5, q = 1 Output: 3 Explanation: The LCA of nodes 5 and 1 is 3. Example 2: Input: root = [3,5,1,6,2,0,8,null,null,7,4], p = 5, q = 4 Output: 5 Explanation: The LCA of nodes 5 and 4 is 5, since a node can be a descendant of itself according to the LCA definition. Example 3: Input: root = [1,2], p = 1, q = 2 Output: 1 Solution # Definition for a binary tree node. class TreeNode : def __init__ ( self , x ): self . val = x self . left = None self . right = None class Solution : def lowestCommonAncestor ( self , root : 'TreeNode' , p : 'TreeNode' , q : 'TreeNode' ) -> 'TreeNode' : # Base Case 1: If root is None, or root is p or q, then root is the LCA if not root or root == p or root == q : return root # Recursively search in left and right subtrees left_lca = self . lowestCommonAncestor ( root . left , p , q ) right_lca = self . lowestCommonAncestor ( root . right , p , q ) # Case 1: Both p and q are found in different subtrees # This means the current root is the LCA if left_lca and right_lca : return root # Case 2: Only one of p or q is found (or both are in the same subtree) # If left_lca is not None, it means p or q (or both) were found in the left subtree. # So, left_lca is the LCA. elif left_lca : return left_lca # Case 3: Only right_lca is not None, meaning p or q (or both) were found in the right subtree. # So, right_lca is the LCA. else : return right_lca Explanation This problem is a classic recursive tree traversal problem. Unlike a BST, in a general binary tree, we cannot use the node values to guide our search. We must explore both left and right subtrees. Core Idea: The lowest common ancestor (LCA) of two nodes p and q can be found by recursively searching the tree. The LCA is the first node where p and q are found in different subtrees, or where one of them is the current node and the other is in one of its subtrees. Recursive Approach: Base Case: If root is None , it means we've reached the end of a branch without finding p or q . Return None . If root is p or root is q , it means we've found one of the target nodes. According to the definition, a node can be a descendant of itself, so this root is a potential LCA. Return root . Recursive Calls: Recursively call lowestCommonAncestor on the root.left subtree to find left_lca . Recursively call lowestCommonAncestor on the root.right subtree to find right_lca . Combine Results: After the recursive calls return: If both left_lca and right_lca are not None : This means p was found in one subtree and q in the other (or vice versa). Therefore, the current root is the LCA. Return root . If only left_lca is not None : This means both p and q (or just one of them) were found in the left subtree. So, left_lca is the LCA. Return left_lca . If only right_lca is not None : This means both p and q (or just one of them) were found in the right subtree. So, right_lca is the LCA. Return right_lca . If both are None : Neither p nor q were found in the current subtree. Return None . Time and Space Complexity: Time Complexity: O(N), where N is the number of nodes in the binary tree. In the worst case, we visit each node once. Space Complexity: O(H) for the recursion stack, where H is the height of the tree. In a skewed tree, H can be N (O(N)), and in a balanced tree, H is log N (O(log N)).","title":"Lowest Common Ancestor of a Binary Tree"},{"location":"lowest_common_ancestor_of_a_binary_tree/#68-lowest-common-ancestor-of-a-binary-tree","text":"","title":"68. Lowest Common Ancestor of a Binary Tree"},{"location":"lowest_common_ancestor_of_a_binary_tree/#problem-statement","text":"Given a binary tree, find the lowest common ancestor (LCA) of two given nodes in the tree. According to the definition of LCA on Wikipedia: \"The lowest common ancestor is defined between two nodes p and q as the lowest node in T that has both p and q as descendants (where we allow a node to be a descendant of itself).\" Example 1: Input: root = [3,5,1,6,2,0,8,null,null,7,4], p = 5, q = 1 Output: 3 Explanation: The LCA of nodes 5 and 1 is 3. Example 2: Input: root = [3,5,1,6,2,0,8,null,null,7,4], p = 5, q = 4 Output: 5 Explanation: The LCA of nodes 5 and 4 is 5, since a node can be a descendant of itself according to the LCA definition. Example 3: Input: root = [1,2], p = 1, q = 2 Output: 1","title":"Problem Statement"},{"location":"lowest_common_ancestor_of_a_binary_tree/#solution","text":"# Definition for a binary tree node. class TreeNode : def __init__ ( self , x ): self . val = x self . left = None self . right = None class Solution : def lowestCommonAncestor ( self , root : 'TreeNode' , p : 'TreeNode' , q : 'TreeNode' ) -> 'TreeNode' : # Base Case 1: If root is None, or root is p or q, then root is the LCA if not root or root == p or root == q : return root # Recursively search in left and right subtrees left_lca = self . lowestCommonAncestor ( root . left , p , q ) right_lca = self . lowestCommonAncestor ( root . right , p , q ) # Case 1: Both p and q are found in different subtrees # This means the current root is the LCA if left_lca and right_lca : return root # Case 2: Only one of p or q is found (or both are in the same subtree) # If left_lca is not None, it means p or q (or both) were found in the left subtree. # So, left_lca is the LCA. elif left_lca : return left_lca # Case 3: Only right_lca is not None, meaning p or q (or both) were found in the right subtree. # So, right_lca is the LCA. else : return right_lca","title":"Solution"},{"location":"lowest_common_ancestor_of_a_binary_tree/#explanation","text":"This problem is a classic recursive tree traversal problem. Unlike a BST, in a general binary tree, we cannot use the node values to guide our search. We must explore both left and right subtrees. Core Idea: The lowest common ancestor (LCA) of two nodes p and q can be found by recursively searching the tree. The LCA is the first node where p and q are found in different subtrees, or where one of them is the current node and the other is in one of its subtrees. Recursive Approach: Base Case: If root is None , it means we've reached the end of a branch without finding p or q . Return None . If root is p or root is q , it means we've found one of the target nodes. According to the definition, a node can be a descendant of itself, so this root is a potential LCA. Return root . Recursive Calls: Recursively call lowestCommonAncestor on the root.left subtree to find left_lca . Recursively call lowestCommonAncestor on the root.right subtree to find right_lca . Combine Results: After the recursive calls return: If both left_lca and right_lca are not None : This means p was found in one subtree and q in the other (or vice versa). Therefore, the current root is the LCA. Return root . If only left_lca is not None : This means both p and q (or just one of them) were found in the left subtree. So, left_lca is the LCA. Return left_lca . If only right_lca is not None : This means both p and q (or just one of them) were found in the right subtree. So, right_lca is the LCA. Return right_lca . If both are None : Neither p nor q were found in the current subtree. Return None . Time and Space Complexity: Time Complexity: O(N), where N is the number of nodes in the binary tree. In the worst case, we visit each node once. Space Complexity: O(H) for the recursion stack, where H is the height of the tree. In a skewed tree, H can be N (O(N)), and in a balanced tree, H is log N (O(log N)).","title":"Explanation"},{"location":"maximum_depth_of_binary_tree/","text":"57. Maximum Depth of Binary Tree Problem Statement Given the root of a binary tree, return its maximum depth . A binary tree's maximum depth is the number of nodes along the longest path from the root node down to the farthest leaf node. Example 1: Input: root = [3,9,20,null,null,15,7] Output: 3 Example 2: Input: root = [1,null,2] Output: 2 Example 3: Input: root = [] Output: 0 Solution # Definition for a binary tree node. class TreeNode : def __init__ ( self , val = 0 , left = None , right = None ): self . val = val self . left = left self . right = right class Solution : def maxDepth ( self , root : TreeNode ) -> int : if not root : return 0 # The maximum depth is 1 (for the current node) plus the maximum # depth of its left or right subtree. return 1 + max ( self . maxDepth ( root . left ), self . maxDepth ( root . right )) Explanation This problem can be solved very concisely using recursion. Core Idea: The maximum depth of a binary tree is 1 (for the root node itself) plus the maximum depth of its left or right subtree. Recursive Approach: Base Case: If the root is None (meaning we've reached past a leaf node), the depth is 0. This is our stopping condition for the recursion. Recursive Step: Recursively call maxDepth on the root.left subtree to find its maximum depth. Recursively call maxDepth on the root.right subtree to find its maximum depth. Take the maximum of these two depths. Add 1 to this maximum (to account for the current root node). Example Trace: For root = [3,9,20,null,null,15,7] : maxDepth(3) : 1 + max(maxDepth(9), maxDepth(20)) maxDepth(9) : 1 + max(maxDepth(None), maxDepth(None)) 1 + max(0, 0) = 1 maxDepth(20) : 1 + max(maxDepth(15), maxDepth(7)) maxDepth(15) : 1 + max(maxDepth(None), maxDepth(None)) = 1 maxDepth(7) : 1 + max(maxDepth(None), maxDepth(None)) = 1 So, maxDepth(20) becomes 1 + max(1, 1) = 2 . Finally, maxDepth(3) becomes 1 + max(1, 2) = 3 . Time and Space Complexity: Time Complexity: O(N), where N is the number of nodes in the binary tree. We visit each node exactly once. Space Complexity: O(H) in the worst case, where H is the height of the tree. This is due to the recursion stack. In a skewed tree, H can be N (O(N)), and in a balanced tree, H is log N (O(log N)).","title":"Maximum Depth of Binary Tree"},{"location":"maximum_depth_of_binary_tree/#57-maximum-depth-of-binary-tree","text":"","title":"57. Maximum Depth of Binary Tree"},{"location":"maximum_depth_of_binary_tree/#problem-statement","text":"Given the root of a binary tree, return its maximum depth . A binary tree's maximum depth is the number of nodes along the longest path from the root node down to the farthest leaf node. Example 1: Input: root = [3,9,20,null,null,15,7] Output: 3 Example 2: Input: root = [1,null,2] Output: 2 Example 3: Input: root = [] Output: 0","title":"Problem Statement"},{"location":"maximum_depth_of_binary_tree/#solution","text":"# Definition for a binary tree node. class TreeNode : def __init__ ( self , val = 0 , left = None , right = None ): self . val = val self . left = left self . right = right class Solution : def maxDepth ( self , root : TreeNode ) -> int : if not root : return 0 # The maximum depth is 1 (for the current node) plus the maximum # depth of its left or right subtree. return 1 + max ( self . maxDepth ( root . left ), self . maxDepth ( root . right ))","title":"Solution"},{"location":"maximum_depth_of_binary_tree/#explanation","text":"This problem can be solved very concisely using recursion. Core Idea: The maximum depth of a binary tree is 1 (for the root node itself) plus the maximum depth of its left or right subtree. Recursive Approach: Base Case: If the root is None (meaning we've reached past a leaf node), the depth is 0. This is our stopping condition for the recursion. Recursive Step: Recursively call maxDepth on the root.left subtree to find its maximum depth. Recursively call maxDepth on the root.right subtree to find its maximum depth. Take the maximum of these two depths. Add 1 to this maximum (to account for the current root node). Example Trace: For root = [3,9,20,null,null,15,7] : maxDepth(3) : 1 + max(maxDepth(9), maxDepth(20)) maxDepth(9) : 1 + max(maxDepth(None), maxDepth(None)) 1 + max(0, 0) = 1 maxDepth(20) : 1 + max(maxDepth(15), maxDepth(7)) maxDepth(15) : 1 + max(maxDepth(None), maxDepth(None)) = 1 maxDepth(7) : 1 + max(maxDepth(None), maxDepth(None)) = 1 So, maxDepth(20) becomes 1 + max(1, 1) = 2 . Finally, maxDepth(3) becomes 1 + max(1, 2) = 3 . Time and Space Complexity: Time Complexity: O(N), where N is the number of nodes in the binary tree. We visit each node exactly once. Space Complexity: O(H) in the worst case, where H is the height of the tree. This is due to the recursion stack. In a skewed tree, H can be N (O(N)), and in a balanced tree, H is log N (O(log N)).","title":"Explanation"},{"location":"maximum_product_subarray/","text":"6. Maximum Product Subarray Problem Statement Given an integer array nums , find a subarray that has the largest product, and return the product . The test cases are generated so that the answer will fit in a 32-bit integer. Example 1: Input: nums = [2,3,-2,4] Output: 6 Explanation: [2,3] has the largest product 6. Example 2: Input: nums = [-2,0,-1] Output: 0 Explanation: The result cannot be 2, because [-2,-1] is not a subarray. Solution class Solution : def maxProduct ( self , nums : list [ int ]) -> int : if not nums : return 0 max_prod = nums [ 0 ] min_prod = nums [ 0 ] result = max_prod for i in range ( 1 , len ( nums )): curr = nums [ i ] temp_max = max ( curr , max_prod * curr , min_prod * curr ) min_prod = min ( curr , max_prod * curr , min_prod * curr ) max_prod = temp_max result = max ( max_prod , result ) return result Explanation This problem is similar to \"Maximum Subarray\", but with a twist: negative numbers. A negative number multiplied by another negative number becomes positive. This means we need to keep track of both the maximum and minimum product at each position. The algorithm iterates through the array, maintaining: max_prod : The maximum product of a subarray ending at the current position. min_prod : The minimum product of a subarray ending at the current position (this is needed to handle negative numbers). result : The overall maximum product found so far. For each element, the new max_prod is the maximum of the current number itself, the product of the old max_prod and the current number, and the product of the old min_prod and the current number. The same logic applies to min_prod . This ensures we correctly handle the sign changes and find the maximum product in O(n) time and O(1) space.","title":"Maximum Product Subarray"},{"location":"maximum_product_subarray/#6-maximum-product-subarray","text":"","title":"6. Maximum Product Subarray"},{"location":"maximum_product_subarray/#problem-statement","text":"Given an integer array nums , find a subarray that has the largest product, and return the product . The test cases are generated so that the answer will fit in a 32-bit integer. Example 1: Input: nums = [2,3,-2,4] Output: 6 Explanation: [2,3] has the largest product 6. Example 2: Input: nums = [-2,0,-1] Output: 0 Explanation: The result cannot be 2, because [-2,-1] is not a subarray.","title":"Problem Statement"},{"location":"maximum_product_subarray/#solution","text":"class Solution : def maxProduct ( self , nums : list [ int ]) -> int : if not nums : return 0 max_prod = nums [ 0 ] min_prod = nums [ 0 ] result = max_prod for i in range ( 1 , len ( nums )): curr = nums [ i ] temp_max = max ( curr , max_prod * curr , min_prod * curr ) min_prod = min ( curr , max_prod * curr , min_prod * curr ) max_prod = temp_max result = max ( max_prod , result ) return result","title":"Solution"},{"location":"maximum_product_subarray/#explanation","text":"This problem is similar to \"Maximum Subarray\", but with a twist: negative numbers. A negative number multiplied by another negative number becomes positive. This means we need to keep track of both the maximum and minimum product at each position. The algorithm iterates through the array, maintaining: max_prod : The maximum product of a subarray ending at the current position. min_prod : The minimum product of a subarray ending at the current position (this is needed to handle negative numbers). result : The overall maximum product found so far. For each element, the new max_prod is the maximum of the current number itself, the product of the old max_prod and the current number, and the product of the old min_prod and the current number. The same logic applies to min_prod . This ensures we correctly handle the sign changes and find the maximum product in O(n) time and O(1) space.","title":"Explanation"},{"location":"maximum_subarray/","text":"5. Maximum Subarray Problem Statement Given an integer array nums , find the subarray with the largest sum, and return its sum . Example 1: Input: nums = [-2,1,-3,4,-1,2,1,-5,4] Output: 6 Explanation: The subarray [4,-1,2,1] has the largest sum 6. Example 2: Input: nums = [1] Output: 1 Explanation: The subarray [1] has the largest sum 1. Example 3: Input: nums = [5,4,-1,7,8] Output: 23 Explanation: The subarray [5,4,-1,7,8] has the largest sum 23. Solution class Solution : def maxSubArray ( self , nums : list [ int ]) -> int : max_so_far = nums [ 0 ] current_max = nums [ 0 ] for i in range ( 1 , len ( nums )): current_max = max ( nums [ i ], current_max + nums [ i ]) max_so_far = max ( max_so_far , current_max ) return max_so_far Explanation This problem is a classic example of Kadane's Algorithm. The algorithm iterates through the array, keeping track of two variables: current_max : The maximum sum of a subarray ending at the current position. max_so_far : The overall maximum sum found so far. For each element, we have two choices: Start a new subarray at the current element. Extend the previous subarray by adding the current element. We choose the one that gives a larger sum for current_max . Then, we update max_so_far if current_max is greater. This dynamic programming approach efficiently finds the maximum subarray sum in O(n) time with O(1) space complexity.","title":"Maximum Subarray"},{"location":"maximum_subarray/#5-maximum-subarray","text":"","title":"5. Maximum Subarray"},{"location":"maximum_subarray/#problem-statement","text":"Given an integer array nums , find the subarray with the largest sum, and return its sum . Example 1: Input: nums = [-2,1,-3,4,-1,2,1,-5,4] Output: 6 Explanation: The subarray [4,-1,2,1] has the largest sum 6. Example 2: Input: nums = [1] Output: 1 Explanation: The subarray [1] has the largest sum 1. Example 3: Input: nums = [5,4,-1,7,8] Output: 23 Explanation: The subarray [5,4,-1,7,8] has the largest sum 23.","title":"Problem Statement"},{"location":"maximum_subarray/#solution","text":"class Solution : def maxSubArray ( self , nums : list [ int ]) -> int : max_so_far = nums [ 0 ] current_max = nums [ 0 ] for i in range ( 1 , len ( nums )): current_max = max ( nums [ i ], current_max + nums [ i ]) max_so_far = max ( max_so_far , current_max ) return max_so_far","title":"Solution"},{"location":"maximum_subarray/#explanation","text":"This problem is a classic example of Kadane's Algorithm. The algorithm iterates through the array, keeping track of two variables: current_max : The maximum sum of a subarray ending at the current position. max_so_far : The overall maximum sum found so far. For each element, we have two choices: Start a new subarray at the current element. Extend the previous subarray by adding the current element. We choose the one that gives a larger sum for current_max . Then, we update max_so_far if current_max is greater. This dynamic programming approach efficiently finds the maximum subarray sum in O(n) time with O(1) space complexity.","title":"Explanation"},{"location":"meeting_rooms/","text":"73. Meeting Rooms Problem Statement Given an array of meeting time intervals intervals where intervals[i] = [starti, endi] , determine if a person could attend all meetings. Example 1: Input: intervals = [[0,30],[5,10],[15,20]] Output: false Example 2: Input: intervals = [[7,10],[2,4]] Output: true Solution class Solution : def canAttendMeetings ( self , intervals : list [ list [ int ]]) -> bool : # Sort the intervals by their start times intervals . sort ( key = lambda x : x [ 0 ]) # Iterate through the sorted intervals and check for overlaps for i in range ( 1 , len ( intervals )): # If the current meeting starts before the previous meeting ends, # there is an overlap. if intervals [ i ][ 0 ] < intervals [ i - 1 ][ 1 ]: return False return True Explanation This problem asks whether a person can attend all meetings, which means we need to check if any two meetings overlap. Core Idea: If we sort the meetings by their start times, then we only need to check if a meeting overlaps with the immediately preceding meeting. If meeting[i] overlaps with meeting[i-1] , then it's impossible to attend all meetings. Sort Intervals: The first and most crucial step is to sort the intervals list based on the start times of the meetings. This ensures that we process meetings in chronological order. Check for Overlaps: Iterate through the sorted intervals list, starting from the second meeting ( i = 1 ). For each intervals[i] , compare its start time ( intervals[i][0] ) with the end time of the previous meeting ( intervals[i-1][1] ). If intervals[i][0] < intervals[i-1][1] , it means the current meeting starts before the previous one ends, indicating an overlap. In this case, the person cannot attend all meetings, so we immediately return False . Return True: If the loop completes without finding any overlaps, it means all meetings can be attended, so we return True . Time and Space Complexity: Time Complexity: O(N log N), primarily due to the sorting step, where N is the number of meetings. The iteration and checking part takes O(N). Space Complexity: O(1) if the sorting is done in-place, or O(N) if a new sorted list is created (depending on the sorting algorithm implementation).","title":"Meeting Rooms"},{"location":"meeting_rooms/#73-meeting-rooms","text":"","title":"73. Meeting Rooms"},{"location":"meeting_rooms/#problem-statement","text":"Given an array of meeting time intervals intervals where intervals[i] = [starti, endi] , determine if a person could attend all meetings. Example 1: Input: intervals = [[0,30],[5,10],[15,20]] Output: false Example 2: Input: intervals = [[7,10],[2,4]] Output: true","title":"Problem Statement"},{"location":"meeting_rooms/#solution","text":"class Solution : def canAttendMeetings ( self , intervals : list [ list [ int ]]) -> bool : # Sort the intervals by their start times intervals . sort ( key = lambda x : x [ 0 ]) # Iterate through the sorted intervals and check for overlaps for i in range ( 1 , len ( intervals )): # If the current meeting starts before the previous meeting ends, # there is an overlap. if intervals [ i ][ 0 ] < intervals [ i - 1 ][ 1 ]: return False return True","title":"Solution"},{"location":"meeting_rooms/#explanation","text":"This problem asks whether a person can attend all meetings, which means we need to check if any two meetings overlap. Core Idea: If we sort the meetings by their start times, then we only need to check if a meeting overlaps with the immediately preceding meeting. If meeting[i] overlaps with meeting[i-1] , then it's impossible to attend all meetings. Sort Intervals: The first and most crucial step is to sort the intervals list based on the start times of the meetings. This ensures that we process meetings in chronological order. Check for Overlaps: Iterate through the sorted intervals list, starting from the second meeting ( i = 1 ). For each intervals[i] , compare its start time ( intervals[i][0] ) with the end time of the previous meeting ( intervals[i-1][1] ). If intervals[i][0] < intervals[i-1][1] , it means the current meeting starts before the previous one ends, indicating an overlap. In this case, the person cannot attend all meetings, so we immediately return False . Return True: If the loop completes without finding any overlaps, it means all meetings can be attended, so we return True . Time and Space Complexity: Time Complexity: O(N log N), primarily due to the sorting step, where N is the number of meetings. The iteration and checking part takes O(N). Space Complexity: O(1) if the sorting is done in-place, or O(N) if a new sorted list is created (depending on the sorting algorithm implementation).","title":"Explanation"},{"location":"meeting_rooms_ii/","text":"74. Meeting Rooms II Problem Statement Given an array of meeting time intervals intervals where intervals[i] = [starti, endi] , return the minimum number of conference rooms required . Example 1: Input: intervals = [[0,30],[5,10],[15,20]] Output: 2 Explanation: We need two rooms: Room 1: (0,30) Room 2: (5,10), (15,20) Example 2: Input: intervals = [[7,10],[2,4]] Output: 1 Solution import heapq class Solution : def minMeetingRooms ( self , intervals : list [ list [ int ]]) -> int : if not intervals : return 0 # Sort the intervals by their start times intervals . sort ( key = lambda x : x [ 0 ]) # Min-heap to store the end times of meetings currently in rooms # The smallest end time will always be at the top rooms = [] # Add the first meeting's end time to the heap heapq . heappush ( rooms , intervals [ 0 ][ 1 ]) # Process the rest of the meetings for i in range ( 1 , len ( intervals )): # If the current meeting starts at or after the earliest ending meeting, # we can reuse that room. if intervals [ i ][ 0 ] >= rooms [ 0 ]: heapq . heappop ( rooms ) # Remove the earliest ending meeting # Assign the current meeting to a room (either a new one or a reused one) heapq . heappush ( rooms , intervals [ i ][ 1 ]) # The number of rooms in the heap is the minimum number of rooms required return len ( rooms ) Explanation This problem asks for the minimum number of meeting rooms needed. This is a classic scheduling problem that can be solved efficiently using a min-heap. Core Idea: We want to reuse rooms as much as possible. When a new meeting starts, we check if any existing meeting has already ended. If so, we can reuse that room. Otherwise, we need a new room. Sort Intervals: First, sort all meeting intervals by their start times. This ensures we process meetings in the order they begin. Min-Heap for Room End Times: Create a min-heap ( rooms ). This heap will store the end times of all meetings that are currently occupying a room. The smallest end time will always be at the top of the heap. Process Meetings: Add the end time of the first meeting to the rooms heap. Iterate through the rest of the sorted intervals : For each current_meeting ( intervals[i] ): Check if the current_meeting 's start time ( intervals[i][0] ) is greater than or equal to the end time of the earliest ending meeting in our rooms heap ( rooms[0] ). If it is, it means a room has become free. We can reuse that room, so we heapq.heappop(rooms) to remove the earliest ending meeting. Regardless of whether a room was reused or not, we assign the current_meeting to a room by adding its end time ( intervals[i][1] ) to the rooms heap ( heapq.heappush ). This effectively marks the room as occupied until this meeting ends. Result: After processing all meetings, the number of elements remaining in the rooms heap will be the minimum number of conference rooms required. This is because each element in the heap represents a room that is currently occupied. Time and Space Complexity: Time Complexity: O(N log N), where N is the number of intervals. The sorting takes O(N log N). Each heap operation (push and pop) takes O(log K) time, where K is the number of rooms (at most N). Since we perform N heap operations, this part is O(N log N). Space Complexity: O(N) in the worst case, as the heap could potentially store all N meeting end times if all meetings overlap.","title":"Meeting Rooms II"},{"location":"meeting_rooms_ii/#74-meeting-rooms-ii","text":"","title":"74. Meeting Rooms II"},{"location":"meeting_rooms_ii/#problem-statement","text":"Given an array of meeting time intervals intervals where intervals[i] = [starti, endi] , return the minimum number of conference rooms required . Example 1: Input: intervals = [[0,30],[5,10],[15,20]] Output: 2 Explanation: We need two rooms: Room 1: (0,30) Room 2: (5,10), (15,20) Example 2: Input: intervals = [[7,10],[2,4]] Output: 1","title":"Problem Statement"},{"location":"meeting_rooms_ii/#solution","text":"import heapq class Solution : def minMeetingRooms ( self , intervals : list [ list [ int ]]) -> int : if not intervals : return 0 # Sort the intervals by their start times intervals . sort ( key = lambda x : x [ 0 ]) # Min-heap to store the end times of meetings currently in rooms # The smallest end time will always be at the top rooms = [] # Add the first meeting's end time to the heap heapq . heappush ( rooms , intervals [ 0 ][ 1 ]) # Process the rest of the meetings for i in range ( 1 , len ( intervals )): # If the current meeting starts at or after the earliest ending meeting, # we can reuse that room. if intervals [ i ][ 0 ] >= rooms [ 0 ]: heapq . heappop ( rooms ) # Remove the earliest ending meeting # Assign the current meeting to a room (either a new one or a reused one) heapq . heappush ( rooms , intervals [ i ][ 1 ]) # The number of rooms in the heap is the minimum number of rooms required return len ( rooms )","title":"Solution"},{"location":"meeting_rooms_ii/#explanation","text":"This problem asks for the minimum number of meeting rooms needed. This is a classic scheduling problem that can be solved efficiently using a min-heap. Core Idea: We want to reuse rooms as much as possible. When a new meeting starts, we check if any existing meeting has already ended. If so, we can reuse that room. Otherwise, we need a new room. Sort Intervals: First, sort all meeting intervals by their start times. This ensures we process meetings in the order they begin. Min-Heap for Room End Times: Create a min-heap ( rooms ). This heap will store the end times of all meetings that are currently occupying a room. The smallest end time will always be at the top of the heap. Process Meetings: Add the end time of the first meeting to the rooms heap. Iterate through the rest of the sorted intervals : For each current_meeting ( intervals[i] ): Check if the current_meeting 's start time ( intervals[i][0] ) is greater than or equal to the end time of the earliest ending meeting in our rooms heap ( rooms[0] ). If it is, it means a room has become free. We can reuse that room, so we heapq.heappop(rooms) to remove the earliest ending meeting. Regardless of whether a room was reused or not, we assign the current_meeting to a room by adding its end time ( intervals[i][1] ) to the rooms heap ( heapq.heappush ). This effectively marks the room as occupied until this meeting ends. Result: After processing all meetings, the number of elements remaining in the rooms heap will be the minimum number of conference rooms required. This is because each element in the heap represents a room that is currently occupied. Time and Space Complexity: Time Complexity: O(N log N), where N is the number of intervals. The sorting takes O(N log N). Each heap operation (push and pop) takes O(log K) time, where K is the number of rooms (at most N). Since we perform N heap operations, this part is O(N log N). Space Complexity: O(N) in the worst case, as the heap could potentially store all N meeting end times if all meetings overlap.","title":"Explanation"},{"location":"merge_intervals/","text":"71. Merge Intervals Problem Statement Given an array of intervals where intervals[i] = [starti, endi] , merge all overlapping intervals, and return an array of the non-overlapping intervals that cover all the intervals in the input . Example 1: Input: intervals = [[1,3],[2,6],[8,10],[15,18]] Output: [[1,6],[8,10],[15,18]] Explanation: Since intervals [1,3] and [2,6] overlap, merge them into [1,6]. Example 2: Input: intervals = [[1,4],[4,5]] Output: [[1,5]] Explanation: Intervals [1,4] and [4,5] are considered overlapping. Solution class Solution : def merge ( self , intervals : list [ list [ int ]]) -> list [ list [ int ]]: if not intervals : return [] # Sort intervals based on their start times intervals . sort ( key = lambda x : x [ 0 ]) merged = [] for interval in intervals : # If the merged list is empty or the current interval does not overlap # with the previous merged interval, simply add it. if not merged or interval [ 0 ] > merged [ - 1 ][ 1 ]: merged . append ( interval ) else : # Otherwise, there is an overlap, so merge the current and previous intervals # by updating the end time of the last merged interval. merged [ - 1 ][ 1 ] = max ( merged [ - 1 ][ 1 ], interval [ 1 ]) return merged Explanation This problem can be solved efficiently by first sorting the intervals and then iterating through them to merge overlapping ones. Core Idea: If intervals are sorted by their start times, then any overlapping intervals must be adjacent or partially overlapping in the sorted list. Sort Intervals: The first crucial step is to sort the input intervals based on their start times. This ensures that we process intervals in a sequential order. Iterate and Merge: Initialize an empty list merged to store the non-overlapping intervals. Iterate through each interval in the sorted intervals list. Check for Overlap: If merged is empty, or if the current interval 's start time is greater than the end time of the last interval in merged , it means there is no overlap. In this case, simply append the current interval to merged . If there is an overlap (i.e., interval[0] <= merged[-1][1] ), it means the current interval can be merged with the last interval in merged . To merge, we update the end time of the last interval in merged to be the maximum of its current end time and the current interval 's end time ( merged[-1][1] = max(merged[-1][1], interval[1]) ). Return Result: After iterating through all intervals, merged will contain the non-overlapping intervals. Time and Space Complexity: Time Complexity: O(N log N), primarily due to the sorting step, where N is the number of intervals. The iteration and merging part takes O(N). Space Complexity: O(N) for storing the merged list. In the worst case, no intervals overlap, and merged will contain all N intervals.","title":"Merge Intervals"},{"location":"merge_intervals/#71-merge-intervals","text":"","title":"71. Merge Intervals"},{"location":"merge_intervals/#problem-statement","text":"Given an array of intervals where intervals[i] = [starti, endi] , merge all overlapping intervals, and return an array of the non-overlapping intervals that cover all the intervals in the input . Example 1: Input: intervals = [[1,3],[2,6],[8,10],[15,18]] Output: [[1,6],[8,10],[15,18]] Explanation: Since intervals [1,3] and [2,6] overlap, merge them into [1,6]. Example 2: Input: intervals = [[1,4],[4,5]] Output: [[1,5]] Explanation: Intervals [1,4] and [4,5] are considered overlapping.","title":"Problem Statement"},{"location":"merge_intervals/#solution","text":"class Solution : def merge ( self , intervals : list [ list [ int ]]) -> list [ list [ int ]]: if not intervals : return [] # Sort intervals based on their start times intervals . sort ( key = lambda x : x [ 0 ]) merged = [] for interval in intervals : # If the merged list is empty or the current interval does not overlap # with the previous merged interval, simply add it. if not merged or interval [ 0 ] > merged [ - 1 ][ 1 ]: merged . append ( interval ) else : # Otherwise, there is an overlap, so merge the current and previous intervals # by updating the end time of the last merged interval. merged [ - 1 ][ 1 ] = max ( merged [ - 1 ][ 1 ], interval [ 1 ]) return merged","title":"Solution"},{"location":"merge_intervals/#explanation","text":"This problem can be solved efficiently by first sorting the intervals and then iterating through them to merge overlapping ones. Core Idea: If intervals are sorted by their start times, then any overlapping intervals must be adjacent or partially overlapping in the sorted list. Sort Intervals: The first crucial step is to sort the input intervals based on their start times. This ensures that we process intervals in a sequential order. Iterate and Merge: Initialize an empty list merged to store the non-overlapping intervals. Iterate through each interval in the sorted intervals list. Check for Overlap: If merged is empty, or if the current interval 's start time is greater than the end time of the last interval in merged , it means there is no overlap. In this case, simply append the current interval to merged . If there is an overlap (i.e., interval[0] <= merged[-1][1] ), it means the current interval can be merged with the last interval in merged . To merge, we update the end time of the last interval in merged to be the maximum of its current end time and the current interval 's end time ( merged[-1][1] = max(merged[-1][1], interval[1]) ). Return Result: After iterating through all intervals, merged will contain the non-overlapping intervals. Time and Space Complexity: Time Complexity: O(N log N), primarily due to the sorting step, where N is the number of intervals. The iteration and merging part takes O(N). Space Complexity: O(N) for storing the merged list. In the worst case, no intervals overlap, and merged will contain all N intervals.","title":"Explanation"},{"location":"merge_k_sorted_lists/","text":"47. Merge K Sorted Lists Problem Statement You are given an array of k linked-lists lists , each linked list is sorted in ascending order. Merge all the linked-lists into one sorted linked list and return it. Example 1: Input: lists = [[1,4,5],[1,3,4],[2,6]] Output: [1,1,2,3,4,4,5,6] Explanation: The linked lists are: [ 1->4->5, 1->3->4, 2->6 ] merging them into one sorted list: 1->1->2->3->4->4->5->6 Example 2: Input: lists = [] Output: [] Example 3: Input: lists = [[]] Output: [] Solution import heapq # Definition for singly-linked list. class ListNode : def __init__ ( self , val = 0 , next = None ): self . val = val self . next = next class Solution : def mergeKLists ( self , lists : list [ ListNode ]) -> ListNode : # Use a min-heap to keep track of the smallest element from each list min_heap = [] # Push the head of each non-empty list into the heap # The heap stores tuples: (value, list_index, node_object) # We need list_index to break ties if values are equal, though not strictly necessary for correctness # but good practice for heapq with custom objects. for i , l in enumerate ( lists ): if l : heapq . heappush ( min_heap , ( l . val , i , l )) # Create a dummy node to build the merged list dummy = ListNode () current = dummy while min_heap : # Pop the smallest element from the heap val , list_idx , node = heapq . heappop ( min_heap ) # Append it to the merged list current . next = node current = current . next # If the popped node has a next node, push it to the heap if node . next : heapq . heappush ( min_heap , ( node . next . val , list_idx , node . next )) return dummy . next Explanation This problem can be efficiently solved using a min-priority queue (min-heap). Core Idea: At any point, the next node to be added to our merged list must be the smallest among the current heads of all k linked lists. A min-heap is perfect for this, as it always gives us the minimum element in O(log k) time. Initialize Min-Heap: Create an empty min-heap. Populate Heap with Initial Nodes: Iterate through the k linked lists. For each non-empty list, push its head node into the min-heap. The heap will store tuples of (node.val, list_index, node_object) . The list_index is used to break ties if two nodes have the same value, which is important for heapq when comparing custom objects. Build Merged List: Create a dummy node and a current pointer to build the merged list. While the min_heap is not empty: Extract the node with the smallest value from the heap ( heapq.heappop ). Append this node to current.next and advance current . If the extracted node has a next node, push that next node into the heap. This ensures that we always have the next available smallest element from that particular list. Return Result: The merged sorted list starts from dummy.next . Time and Space Complexity: Time Complexity: O(N log k), where N is the total number of nodes across all linked lists, and k is the number of linked lists. Each node is pushed and popped from the heap exactly once. Each heap operation takes O(log k) time. Space Complexity: O(k) for the min-heap, as it will store at most k nodes (one from each list) at any given time.","title":"Merge K Sorted Lists"},{"location":"merge_k_sorted_lists/#47-merge-k-sorted-lists","text":"","title":"47. Merge K Sorted Lists"},{"location":"merge_k_sorted_lists/#problem-statement","text":"You are given an array of k linked-lists lists , each linked list is sorted in ascending order. Merge all the linked-lists into one sorted linked list and return it. Example 1: Input: lists = [[1,4,5],[1,3,4],[2,6]] Output: [1,1,2,3,4,4,5,6] Explanation: The linked lists are: [ 1->4->5, 1->3->4, 2->6 ] merging them into one sorted list: 1->1->2->3->4->4->5->6 Example 2: Input: lists = [] Output: [] Example 3: Input: lists = [[]] Output: []","title":"Problem Statement"},{"location":"merge_k_sorted_lists/#solution","text":"import heapq # Definition for singly-linked list. class ListNode : def __init__ ( self , val = 0 , next = None ): self . val = val self . next = next class Solution : def mergeKLists ( self , lists : list [ ListNode ]) -> ListNode : # Use a min-heap to keep track of the smallest element from each list min_heap = [] # Push the head of each non-empty list into the heap # The heap stores tuples: (value, list_index, node_object) # We need list_index to break ties if values are equal, though not strictly necessary for correctness # but good practice for heapq with custom objects. for i , l in enumerate ( lists ): if l : heapq . heappush ( min_heap , ( l . val , i , l )) # Create a dummy node to build the merged list dummy = ListNode () current = dummy while min_heap : # Pop the smallest element from the heap val , list_idx , node = heapq . heappop ( min_heap ) # Append it to the merged list current . next = node current = current . next # If the popped node has a next node, push it to the heap if node . next : heapq . heappush ( min_heap , ( node . next . val , list_idx , node . next )) return dummy . next","title":"Solution"},{"location":"merge_k_sorted_lists/#explanation","text":"This problem can be efficiently solved using a min-priority queue (min-heap). Core Idea: At any point, the next node to be added to our merged list must be the smallest among the current heads of all k linked lists. A min-heap is perfect for this, as it always gives us the minimum element in O(log k) time. Initialize Min-Heap: Create an empty min-heap. Populate Heap with Initial Nodes: Iterate through the k linked lists. For each non-empty list, push its head node into the min-heap. The heap will store tuples of (node.val, list_index, node_object) . The list_index is used to break ties if two nodes have the same value, which is important for heapq when comparing custom objects. Build Merged List: Create a dummy node and a current pointer to build the merged list. While the min_heap is not empty: Extract the node with the smallest value from the heap ( heapq.heappop ). Append this node to current.next and advance current . If the extracted node has a next node, push that next node into the heap. This ensures that we always have the next available smallest element from that particular list. Return Result: The merged sorted list starts from dummy.next . Time and Space Complexity: Time Complexity: O(N log k), where N is the total number of nodes across all linked lists, and k is the number of linked lists. Each node is pushed and popped from the heap exactly once. Each heap operation takes O(log k) time. Space Complexity: O(k) for the min-heap, as it will store at most k nodes (one from each list) at any given time.","title":"Explanation"},{"location":"merge_two_sorted_lists/","text":"43. Merge Two Sorted Lists Problem Statement You are given the heads of two sorted linked lists list1 and list2 . Merge the two lists into one sorted list. The list should be made by splicing together the nodes of the first two lists. Return the head of the merged linked list . Example 1: Input: list1 = [1,2,4], list2 = [1,3,4] Output: [1,1,2,3,4,4] Example 2: Input: list1 = [], list2 = [] Output: [] Example 3: Input: list1 = [], list2 = [0] Output: [0] Solution # Definition for singly-linked list. class ListNode : def __init__ ( self , val = 0 , next = None ): self . val = val self . next = next class Solution : def mergeTwoLists ( self , list1 : ListNode , list2 : ListNode ) -> ListNode : # Create a dummy node to simplify handling the head of the merged list dummy = ListNode () current = dummy while list1 and list2 : if list1 . val < list2 . val : current . next = list1 list1 = list1 . next else : current . next = list2 list2 = list2 . next current = current . next # Attach the remaining part of the non-empty list if list1 : current . next = list1 elif list2 : current . next = list2 return dummy . next Explanation This problem can be solved iteratively or recursively. The iterative approach is generally preferred for linked list problems to avoid potential recursion depth limits. Iterative Approach: Dummy Node: We create a dummy node. This is a common technique in linked list problems to simplify the logic of handling the head of the new list. We also use a current pointer, initially pointing to dummy . Traverse Both Lists: We use a while loop that continues as long as both list1 and list2 have nodes. In each iteration, we compare the values of the current nodes in list1 and list2 . We append the node with the smaller value to current.next . We then advance the pointer of the list from which we took the node (either list1 or list2 ). Finally, we advance the current pointer to the newly appended node. Attach Remaining Nodes: After the loop, one of the lists might still have remaining nodes (if one list was longer than the other). Since both input lists are sorted, these remaining nodes are already in sorted order. We simply attach the rest of the non-empty list to current.next . Return Result: The merged sorted list starts from dummy.next . Time and Space Complexity: Time Complexity: O(m + n), where m and n are the lengths of list1 and list2 respectively. We traverse each list at most once. Space Complexity: O(1) because we are only using a few extra pointers and not creating new nodes (we are just rearranging existing nodes).","title":"Merge Two Sorted Lists"},{"location":"merge_two_sorted_lists/#43-merge-two-sorted-lists","text":"","title":"43. Merge Two Sorted Lists"},{"location":"merge_two_sorted_lists/#problem-statement","text":"You are given the heads of two sorted linked lists list1 and list2 . Merge the two lists into one sorted list. The list should be made by splicing together the nodes of the first two lists. Return the head of the merged linked list . Example 1: Input: list1 = [1,2,4], list2 = [1,3,4] Output: [1,1,2,3,4,4] Example 2: Input: list1 = [], list2 = [] Output: [] Example 3: Input: list1 = [], list2 = [0] Output: [0]","title":"Problem Statement"},{"location":"merge_two_sorted_lists/#solution","text":"# Definition for singly-linked list. class ListNode : def __init__ ( self , val = 0 , next = None ): self . val = val self . next = next class Solution : def mergeTwoLists ( self , list1 : ListNode , list2 : ListNode ) -> ListNode : # Create a dummy node to simplify handling the head of the merged list dummy = ListNode () current = dummy while list1 and list2 : if list1 . val < list2 . val : current . next = list1 list1 = list1 . next else : current . next = list2 list2 = list2 . next current = current . next # Attach the remaining part of the non-empty list if list1 : current . next = list1 elif list2 : current . next = list2 return dummy . next","title":"Solution"},{"location":"merge_two_sorted_lists/#explanation","text":"This problem can be solved iteratively or recursively. The iterative approach is generally preferred for linked list problems to avoid potential recursion depth limits. Iterative Approach: Dummy Node: We create a dummy node. This is a common technique in linked list problems to simplify the logic of handling the head of the new list. We also use a current pointer, initially pointing to dummy . Traverse Both Lists: We use a while loop that continues as long as both list1 and list2 have nodes. In each iteration, we compare the values of the current nodes in list1 and list2 . We append the node with the smaller value to current.next . We then advance the pointer of the list from which we took the node (either list1 or list2 ). Finally, we advance the current pointer to the newly appended node. Attach Remaining Nodes: After the loop, one of the lists might still have remaining nodes (if one list was longer than the other). Since both input lists are sorted, these remaining nodes are already in sorted order. We simply attach the rest of the non-empty list to current.next . Return Result: The merged sorted list starts from dummy.next . Time and Space Complexity: Time Complexity: O(m + n), where m and n are the lengths of list1 and list2 respectively. We traverse each list at most once. Space Complexity: O(1) because we are only using a few extra pointers and not creating new nodes (we are just rearranging existing nodes).","title":"Explanation"},{"location":"minimum_window_substring/","text":"35. Minimum Window Substring Problem Statement Given two strings s and t of lengths m and n respectively, return the minimum window substring of s such that every character in t (including duplicates) is included in the window . If there is no such substring, return the empty string \"\" . The test cases will be generated such that the answer is unique. A substring is a contiguous sequence of characters within a string. Example 1: Input: s = \"ADOBECODEBANC\", t = \"ABC\" Output: \"BANC\" Explanation: The minimum window substring \"BANC\" includes 'A', 'B', and 'C' from string t. Example 2: Input: s = \"a\", t = \"a\" Output: \"a\" Explanation: The entire string s is the minimum window. Example 3: Input: s = \"a\", t = \"aa\" Output: \"\" Explanation: Both 'a's from t must be included in the window. Since s only has one 'a', no such window exists. Solution from collections import Counter class Solution : def minWindow ( self , s : str , t : str ) -> str : if not t or not s : return \"\" # Dictionary to store frequency of characters in t dict_t = Counter ( t ) # Number of unique characters in t that must be present in window required = len ( dict_t ) # left and right pointers for the sliding window left = 0 # formed is the number of unique characters in the current window # that match the required count in dict_t. formed = 0 # Dictionary to store frequency of characters in the current window window_counts = {} # ans tuple of the form (window length, left, right) ans = float ( 'inf' ), None , None for right in range ( len ( s )): character = s [ right ] window_counts [ character ] = window_counts . get ( character , 0 ) + 1 # If the current character's count in window matches its count in t if character in dict_t and window_counts [ character ] == dict_t [ character ]: formed += 1 # Try to contract the window from the left while left <= right and formed == required : character = s [ left ] # Update the minimum window found so far if right - left + 1 < ans [ 0 ]: ans = ( right - left + 1 , left , right ) # Remove character from the left of the window window_counts [ character ] -= 1 if character in dict_t and window_counts [ character ] < dict_t [ character ]: formed -= 1 left += 1 return \"\" if ans [ 0 ] == float ( 'inf' ) else s [ ans [ 1 ] : ans [ 2 ] + 1 ] Explanation This problem is a classic application of the sliding window technique. Core Idea: We expand the window from the right until it contains all characters of t . Once it does, we try to shrink it from the left to find the smallest valid window. We keep track of the best (smallest) window found so far. Character Frequencies: dict_t : Stores the frequency of each character in string t . window_counts : Stores the frequency of each character in the current sliding window. required and formed : required : The number of unique characters from t that we need to have in our window (with at least their required frequencies). formed : The number of unique characters in the current window that satisfy their frequency requirement from dict_t . Algorithm: Expand Window (Right Pointer): The right pointer iterates through s , adding characters to window_counts . If a character s[right] is in dict_t and its count in window_counts matches dict_t , we increment formed . Contract Window (Left Pointer): Once formed == required (meaning the current window contains all characters of t with their required frequencies), we enter a while loop to try and shrink the window from the left . Inside this loop, we first check if the current window is smaller than the ans found so far and update ans if it is. Then, we remove s[left] from window_counts and increment left . If s[left] was a character from t and its count in window_counts drops below its required count in dict_t , we decrement formed . The while loop continues as long as formed == required , meaning we keep shrinking the window from the left until it becomes invalid (i.e., formed < required ). At that point, we resume expanding the window from the right. This approach ensures that we find the minimum window. The time complexity is O(S + T) where S is the length of s and T is the length of t , because both pointers traverse s at most once, and Counter(t) takes O(T). The space complexity is O(alphabet_size) for the dictionaries.","title":"Minimum Window Substring"},{"location":"minimum_window_substring/#35-minimum-window-substring","text":"","title":"35. Minimum Window Substring"},{"location":"minimum_window_substring/#problem-statement","text":"Given two strings s and t of lengths m and n respectively, return the minimum window substring of s such that every character in t (including duplicates) is included in the window . If there is no such substring, return the empty string \"\" . The test cases will be generated such that the answer is unique. A substring is a contiguous sequence of characters within a string. Example 1: Input: s = \"ADOBECODEBANC\", t = \"ABC\" Output: \"BANC\" Explanation: The minimum window substring \"BANC\" includes 'A', 'B', and 'C' from string t. Example 2: Input: s = \"a\", t = \"a\" Output: \"a\" Explanation: The entire string s is the minimum window. Example 3: Input: s = \"a\", t = \"aa\" Output: \"\" Explanation: Both 'a's from t must be included in the window. Since s only has one 'a', no such window exists.","title":"Problem Statement"},{"location":"minimum_window_substring/#solution","text":"from collections import Counter class Solution : def minWindow ( self , s : str , t : str ) -> str : if not t or not s : return \"\" # Dictionary to store frequency of characters in t dict_t = Counter ( t ) # Number of unique characters in t that must be present in window required = len ( dict_t ) # left and right pointers for the sliding window left = 0 # formed is the number of unique characters in the current window # that match the required count in dict_t. formed = 0 # Dictionary to store frequency of characters in the current window window_counts = {} # ans tuple of the form (window length, left, right) ans = float ( 'inf' ), None , None for right in range ( len ( s )): character = s [ right ] window_counts [ character ] = window_counts . get ( character , 0 ) + 1 # If the current character's count in window matches its count in t if character in dict_t and window_counts [ character ] == dict_t [ character ]: formed += 1 # Try to contract the window from the left while left <= right and formed == required : character = s [ left ] # Update the minimum window found so far if right - left + 1 < ans [ 0 ]: ans = ( right - left + 1 , left , right ) # Remove character from the left of the window window_counts [ character ] -= 1 if character in dict_t and window_counts [ character ] < dict_t [ character ]: formed -= 1 left += 1 return \"\" if ans [ 0 ] == float ( 'inf' ) else s [ ans [ 1 ] : ans [ 2 ] + 1 ]","title":"Solution"},{"location":"minimum_window_substring/#explanation","text":"This problem is a classic application of the sliding window technique. Core Idea: We expand the window from the right until it contains all characters of t . Once it does, we try to shrink it from the left to find the smallest valid window. We keep track of the best (smallest) window found so far. Character Frequencies: dict_t : Stores the frequency of each character in string t . window_counts : Stores the frequency of each character in the current sliding window. required and formed : required : The number of unique characters from t that we need to have in our window (with at least their required frequencies). formed : The number of unique characters in the current window that satisfy their frequency requirement from dict_t . Algorithm: Expand Window (Right Pointer): The right pointer iterates through s , adding characters to window_counts . If a character s[right] is in dict_t and its count in window_counts matches dict_t , we increment formed . Contract Window (Left Pointer): Once formed == required (meaning the current window contains all characters of t with their required frequencies), we enter a while loop to try and shrink the window from the left . Inside this loop, we first check if the current window is smaller than the ans found so far and update ans if it is. Then, we remove s[left] from window_counts and increment left . If s[left] was a character from t and its count in window_counts drops below its required count in dict_t , we decrement formed . The while loop continues as long as formed == required , meaning we keep shrinking the window from the left until it becomes invalid (i.e., formed < required ). At that point, we resume expanding the window from the right. This approach ensures that we find the minimum window. The time complexity is O(S + T) where S is the length of s and T is the length of t , because both pointers traverse s at most once, and Counter(t) takes O(T). The space complexity is O(alphabet_size) for the dictionaries.","title":"Explanation"},{"location":"missing_number/","text":"14. Missing Number Problem Statement Given an array nums containing n distinct numbers in the range [0, n] , return the only number in the range that is missing from the array . Example 1: Input: nums = [3,0,1] Output: 2 Explanation: n = 3 since there are 3 numbers, so all numbers are in the range [0,3]. 2 is the missing number in the range since it does not appear in nums. Example 2: Input: nums = [0,1] Output: 2 Explanation: n = 2 since there are 2 numbers, so all numbers are in the range [0,2]. 2 is the missing number in the range since it does not appear in nums. Example 3: Input: nums = [9,6,4,2,3,5,7,0,1] Output: 8 Explanation: n = 9 since there are 9 numbers, so all numbers are in the range [0,9]. 8 is the missing number in the range since it does not appear in nums. Solution class Solution : def missingNumber ( self , nums : list [ int ]) -> int : n = len ( nums ) # Calculate the expected sum of numbers from 0 to n expected_sum = n * ( n + 1 ) // 2 # Calculate the actual sum of numbers in the array actual_sum = sum ( nums ) # The difference is the missing number return expected_sum - actual_sum Explanation This solution uses a mathematical approach based on Gauss's formula for the sum of an arithmetic series. Expected Sum: The input array nums has n numbers and is missing one number from the range [0, n] . If the array were complete, it would contain n + 1 numbers from 0 to n . The sum of such a series is given by the formula n * (n + 1) / 2 . Actual Sum: We calculate the sum of the numbers actually present in the nums array. The Difference: The difference between the expected_sum (the sum of a complete series) and the actual_sum (the sum of the given numbers) is precisely the missing number. This approach is very efficient, with a time complexity of O(n) due to the sum() function and a space complexity of O(1). Alternative (Bit Manipulation): Another clever solution uses the XOR operation. The XOR of a number with itself is 0. If we XOR all the numbers from 0 to n and all the numbers in the nums array, all the numbers that are present in both will cancel out, leaving only the missing number. class Solution : def missingNumber_xor ( self , nums : list [ int ]) -> int : missing = len ( nums ) for i , num in enumerate ( nums ): missing ^= i ^ num return missing","title":"Missing Number"},{"location":"missing_number/#14-missing-number","text":"","title":"14. Missing Number"},{"location":"missing_number/#problem-statement","text":"Given an array nums containing n distinct numbers in the range [0, n] , return the only number in the range that is missing from the array . Example 1: Input: nums = [3,0,1] Output: 2 Explanation: n = 3 since there are 3 numbers, so all numbers are in the range [0,3]. 2 is the missing number in the range since it does not appear in nums. Example 2: Input: nums = [0,1] Output: 2 Explanation: n = 2 since there are 2 numbers, so all numbers are in the range [0,2]. 2 is the missing number in the range since it does not appear in nums. Example 3: Input: nums = [9,6,4,2,3,5,7,0,1] Output: 8 Explanation: n = 9 since there are 9 numbers, so all numbers are in the range [0,9]. 8 is the missing number in the range since it does not appear in nums.","title":"Problem Statement"},{"location":"missing_number/#solution","text":"class Solution : def missingNumber ( self , nums : list [ int ]) -> int : n = len ( nums ) # Calculate the expected sum of numbers from 0 to n expected_sum = n * ( n + 1 ) // 2 # Calculate the actual sum of numbers in the array actual_sum = sum ( nums ) # The difference is the missing number return expected_sum - actual_sum","title":"Solution"},{"location":"missing_number/#explanation","text":"This solution uses a mathematical approach based on Gauss's formula for the sum of an arithmetic series. Expected Sum: The input array nums has n numbers and is missing one number from the range [0, n] . If the array were complete, it would contain n + 1 numbers from 0 to n . The sum of such a series is given by the formula n * (n + 1) / 2 . Actual Sum: We calculate the sum of the numbers actually present in the nums array. The Difference: The difference between the expected_sum (the sum of a complete series) and the actual_sum (the sum of the given numbers) is precisely the missing number. This approach is very efficient, with a time complexity of O(n) due to the sum() function and a space complexity of O(1). Alternative (Bit Manipulation): Another clever solution uses the XOR operation. The XOR of a number with itself is 0. If we XOR all the numbers from 0 to n and all the numbers in the nums array, all the numbers that are present in both will cancel out, leaving only the missing number. class Solution : def missingNumber_xor ( self , nums : list [ int ]) -> int : missing = len ( nums ) for i , num in enumerate ( nums ): missing ^= i ^ num return missing","title":"Explanation"},{"location":"non_overlapping_intervals/","text":"75. Non-overlapping Intervals Problem Statement Given an array of intervals where intervals[i] = [starti, endi] , return the minimum number of intervals you need to remove to make the rest of the intervals non-overlapping . Example 1: Input: intervals = [[1,2],[2,3],[3,4],[1,3]] Output: 1 Explanation: [1,3] can be removed and the rest of the intervals are non-overlapping. Example 2: Input: intervals = [[1,2],[1,2],[1,2]] Output: 2 Explanation: You need to remove two [1,2] intervals to make the rest non-overlapping. Example 3: Input: intervals = [[1,2],[2,3]] Output: 0 Explanation: You don't need to remove any of the intervals since they're already non-overlapping. Solution class Solution : def eraseOverlapIntervals ( self , intervals : list [ list [ int ]]) -> int : if not intervals : return 0 # Sort intervals by their end times # This greedy approach works because choosing the interval that ends earliest # leaves the maximum room for subsequent non-overlapping intervals. intervals . sort ( key = lambda x : x [ 1 ]) end = intervals [ 0 ][ 1 ] count = 1 # Start with one non-overlapping interval for i in range ( 1 , len ( intervals )): # If the current interval's start time is greater than or equal to # the end time of the last chosen non-overlapping interval, # then it does not overlap and can be included. if intervals [ i ][ 0 ] >= end : end = intervals [ i ][ 1 ] count += 1 # The minimum number of intervals to remove is total intervals - max non-overlapping intervals return len ( intervals ) - count Explanation This problem asks for the minimum number of intervals to remove to make the remaining intervals non-overlapping. This is equivalent to finding the maximum number of non-overlapping intervals and then subtracting that from the total number of intervals. Core Idea (Greedy Approach): To maximize the number of non-overlapping intervals, we should always pick the interval that ends earliest among the available non-overlapping choices. This leaves the maximum possible space for subsequent intervals. Sort by End Times: The crucial step is to sort the intervals based on their end times . If two intervals have the same end time, their start times can be used as a tie-breaker (though not strictly necessary for correctness in this specific problem). Iterate and Select Non-Overlapping: Initialize end with the end time of the first interval (after sorting). Initialize count to 1, as the first interval is always part of our non-overlapping set. Iterate through the sorted intervals starting from the second interval ( i = 1 ). For each current_interval ( intervals[i] ): If current_interval[0] (its start time) is greater than or equal to end (the end time of the last chosen non-overlapping interval), it means the current_interval does not overlap with the previously chosen one. We can include it in our non-overlapping set. If included, update end to current_interval[1] and increment count . Calculate Removals: The count variable now holds the maximum number of non-overlapping intervals. To find the minimum number of intervals to remove, we subtract this count from the total number of intervals ( len(intervals) - count ). Time and Space Complexity: Time Complexity: O(N log N), primarily due to the sorting step, where N is the number of intervals. The iteration and checking part takes O(N). Space Complexity: O(1) if the sorting is done in-place, or O(N) if a new sorted list is created (depending on the sorting algorithm implementation).","title":"Non-overlapping Intervals"},{"location":"non_overlapping_intervals/#75-non-overlapping-intervals","text":"","title":"75. Non-overlapping Intervals"},{"location":"non_overlapping_intervals/#problem-statement","text":"Given an array of intervals where intervals[i] = [starti, endi] , return the minimum number of intervals you need to remove to make the rest of the intervals non-overlapping . Example 1: Input: intervals = [[1,2],[2,3],[3,4],[1,3]] Output: 1 Explanation: [1,3] can be removed and the rest of the intervals are non-overlapping. Example 2: Input: intervals = [[1,2],[1,2],[1,2]] Output: 2 Explanation: You need to remove two [1,2] intervals to make the rest non-overlapping. Example 3: Input: intervals = [[1,2],[2,3]] Output: 0 Explanation: You don't need to remove any of the intervals since they're already non-overlapping.","title":"Problem Statement"},{"location":"non_overlapping_intervals/#solution","text":"class Solution : def eraseOverlapIntervals ( self , intervals : list [ list [ int ]]) -> int : if not intervals : return 0 # Sort intervals by their end times # This greedy approach works because choosing the interval that ends earliest # leaves the maximum room for subsequent non-overlapping intervals. intervals . sort ( key = lambda x : x [ 1 ]) end = intervals [ 0 ][ 1 ] count = 1 # Start with one non-overlapping interval for i in range ( 1 , len ( intervals )): # If the current interval's start time is greater than or equal to # the end time of the last chosen non-overlapping interval, # then it does not overlap and can be included. if intervals [ i ][ 0 ] >= end : end = intervals [ i ][ 1 ] count += 1 # The minimum number of intervals to remove is total intervals - max non-overlapping intervals return len ( intervals ) - count","title":"Solution"},{"location":"non_overlapping_intervals/#explanation","text":"This problem asks for the minimum number of intervals to remove to make the remaining intervals non-overlapping. This is equivalent to finding the maximum number of non-overlapping intervals and then subtracting that from the total number of intervals. Core Idea (Greedy Approach): To maximize the number of non-overlapping intervals, we should always pick the interval that ends earliest among the available non-overlapping choices. This leaves the maximum possible space for subsequent intervals. Sort by End Times: The crucial step is to sort the intervals based on their end times . If two intervals have the same end time, their start times can be used as a tie-breaker (though not strictly necessary for correctness in this specific problem). Iterate and Select Non-Overlapping: Initialize end with the end time of the first interval (after sorting). Initialize count to 1, as the first interval is always part of our non-overlapping set. Iterate through the sorted intervals starting from the second interval ( i = 1 ). For each current_interval ( intervals[i] ): If current_interval[0] (its start time) is greater than or equal to end (the end time of the last chosen non-overlapping interval), it means the current_interval does not overlap with the previously chosen one. We can include it in our non-overlapping set. If included, update end to current_interval[1] and increment count . Calculate Removals: The count variable now holds the maximum number of non-overlapping intervals. To find the minimum number of intervals to remove, we subtract this count from the total number of intervals ( len(intervals) - count ). Time and Space Complexity: Time Complexity: O(N log N), primarily due to the sorting step, where N is the number of intervals. The iteration and checking part takes O(N). Space Complexity: O(1) if the sorting is done in-place, or O(N) if a new sorted list is created (depending on the sorting algorithm implementation).","title":"Explanation"},{"location":"number_of_1_bits/","text":"12. Number of 1 Bits Problem Statement Write a function that takes an unsigned integer and returns the number of '1' bits it has (also known as the Hamming weight). Note: Note that in some languages, such as Java, there is no unsigned integer type. In this case, the input will be given as a signed integer type. It should not affect your implementation, as the integer's internal binary representation is the same, whether it is signed or unsigned. In Java, the compiler represents the signed integers using 2's complement notation. Therefore, in Example 3, the input represents the signed integer. -3. Example 1: Input: n = 00000000000000000000000000001011 Output: 3 Explanation: The input binary string 00000000000000000000000000001011 has a total of three '1' bits. Example 2: Input: n = 00000000000000000000000010000000 Output: 1 Explanation: The input binary string 00000000000000000000000010000000 has a total of one '1' bit. Example 3: Input: n = 11111111111111111111111111111101 Output: 31 Explanation: The input binary string 11111111111111111111111111111101 has a total of thirty one '1' bits. Solution class Solution : def hammingWeight ( self , n : int ) -> int : count = 0 while n != 0 : # This operation removes the rightmost '1' bit n = n & ( n - 1 ) count += 1 return count Explanation This clever bit manipulation trick provides an efficient way to count the number of set bits. The expression n & (n - 1) always flips the least significant '1' bit of n to '0'. Let's see an example: n = 12 (binary 1100 ) n = 1100 , n - 1 = 1011 . n & (n - 1) = 1000 . count is 1. n = 1000 , n - 1 = 0111 . n & (n - 1) = 0000 . count is 2. The loop continues until n becomes 0. The number of times the loop runs is equal to the number of '1' bits in the original number. This method is often more efficient than checking each bit one by one, as its runtime depends on the number of set bits, not the total number of bits.","title":"Number of 1 Bits"},{"location":"number_of_1_bits/#12-number-of-1-bits","text":"","title":"12. Number of 1 Bits"},{"location":"number_of_1_bits/#problem-statement","text":"Write a function that takes an unsigned integer and returns the number of '1' bits it has (also known as the Hamming weight). Note: Note that in some languages, such as Java, there is no unsigned integer type. In this case, the input will be given as a signed integer type. It should not affect your implementation, as the integer's internal binary representation is the same, whether it is signed or unsigned. In Java, the compiler represents the signed integers using 2's complement notation. Therefore, in Example 3, the input represents the signed integer. -3. Example 1: Input: n = 00000000000000000000000000001011 Output: 3 Explanation: The input binary string 00000000000000000000000000001011 has a total of three '1' bits. Example 2: Input: n = 00000000000000000000000010000000 Output: 1 Explanation: The input binary string 00000000000000000000000010000000 has a total of one '1' bit. Example 3: Input: n = 11111111111111111111111111111101 Output: 31 Explanation: The input binary string 11111111111111111111111111111101 has a total of thirty one '1' bits.","title":"Problem Statement"},{"location":"number_of_1_bits/#solution","text":"class Solution : def hammingWeight ( self , n : int ) -> int : count = 0 while n != 0 : # This operation removes the rightmost '1' bit n = n & ( n - 1 ) count += 1 return count","title":"Solution"},{"location":"number_of_1_bits/#explanation","text":"This clever bit manipulation trick provides an efficient way to count the number of set bits. The expression n & (n - 1) always flips the least significant '1' bit of n to '0'. Let's see an example: n = 12 (binary 1100 ) n = 1100 , n - 1 = 1011 . n & (n - 1) = 1000 . count is 1. n = 1000 , n - 1 = 0111 . n & (n - 1) = 0000 . count is 2. The loop continues until n becomes 0. The number of times the loop runs is equal to the number of '1' bits in the original number. This method is often more efficient than checking each bit one by one, as its runtime depends on the number of set bits, not the total number of bits.","title":"Explanation"},{"location":"number_of_islands/","text":"30. Number of Islands Problem Statement Given an m x n 2D binary grid grid which represents a map of '1's (land) and '0's (water), return the number of islands . An island is surrounded by water and is formed by connecting adjacent lands horizontally or vertically. You may assume all four edges of the grid are all surrounded by water. Example 1: Input: grid = [ [\"1\",\"1\",\"1\",\"1\",\"0\"], [\"1\",\"1\",\"0\",\"1\",\"0\"], [\"1\",\"1\",\"0\",\"0\",\"0\"], [\"0\",\"0\",\"0\",\"0\",\"0\"] ] Output: 1 Example 2: Input: grid = [ [\"1\",\"1\",\"0\",\"0\",\"0\"], [\"1\",\"1\",\"0\",\"0\",\"0\"], [\"0\",\"0\",\"1\",\"0\",\"0\"], [\"0\",\"0\",\"0\",\"1\",\"1\"] ] Output: 3 Solution class Solution : def numIslands ( self , grid : list [ list [ str ]]) -> int : if not grid or not grid [ 0 ]: return 0 rows , cols = len ( grid ), len ( grid [ 0 ]) num_islands = 0 def dfs ( r , c ): # Base cases for DFS: # 1. Out of bounds # 2. Current cell is water ('0') # 3. Current cell has already been visited (marked as '2') if ( r < 0 or r >= rows or c < 0 or c >= cols or grid [ r ][ c ] == '0' or grid [ r ][ c ] == '2' ): return # Mark the current cell as visited grid [ r ][ c ] = '2' # Explore neighbors dfs ( r + 1 , c ) dfs ( r - 1 , c ) dfs ( r , c + 1 ) dfs ( r , c - 1 ) for r in range ( rows ): for c in range ( cols ): if grid [ r ][ c ] == '1' : num_islands += 1 dfs ( r , c ) return num_islands Explanation This problem can be solved using a graph traversal algorithm, either Depth-First Search (DFS) or Breadth-First Search (BFS). The idea is to iterate through each cell of the grid. If we encounter a '1' (land), it means we've found a part of an island. We increment our island count and then use DFS (or BFS) to explore the entire connected component of land cells belonging to this island. As we visit each land cell, we mark it as '0' (or any other visited marker, like '2' in the solution) to ensure we don't count it again or get stuck in an infinite loop. DFS Approach: Initialization: Initialize num_islands to 0. Iterate Grid: Loop through each cell (r, c) in the grid. Find Land: If grid[r][c] is '1': Increment num_islands . Call a dfs helper function starting from (r, c) . dfs Helper Function: Base Cases: The dfs function stops if it goes out of bounds, encounters a '0' (water), or encounters a cell that has already been visited. Mark Visited: If the current cell is '1', mark it as visited (e.g., change it to '2'). Explore Neighbors: Recursively call dfs for all four adjacent neighbors (up, down, left, right). By marking visited land cells, we ensure that each island is counted exactly once. The time complexity is O(M * N) because we visit each cell in the grid at most once. The space complexity is O(M * N) in the worst case for the recursion stack of DFS (e.g., a grid full of land).","title":"Number of Islands"},{"location":"number_of_islands/#30-number-of-islands","text":"","title":"30. Number of Islands"},{"location":"number_of_islands/#problem-statement","text":"Given an m x n 2D binary grid grid which represents a map of '1's (land) and '0's (water), return the number of islands . An island is surrounded by water and is formed by connecting adjacent lands horizontally or vertically. You may assume all four edges of the grid are all surrounded by water. Example 1: Input: grid = [ [\"1\",\"1\",\"1\",\"1\",\"0\"], [\"1\",\"1\",\"0\",\"1\",\"0\"], [\"1\",\"1\",\"0\",\"0\",\"0\"], [\"0\",\"0\",\"0\",\"0\",\"0\"] ] Output: 1 Example 2: Input: grid = [ [\"1\",\"1\",\"0\",\"0\",\"0\"], [\"1\",\"1\",\"0\",\"0\",\"0\"], [\"0\",\"0\",\"1\",\"0\",\"0\"], [\"0\",\"0\",\"0\",\"1\",\"1\"] ] Output: 3","title":"Problem Statement"},{"location":"number_of_islands/#solution","text":"class Solution : def numIslands ( self , grid : list [ list [ str ]]) -> int : if not grid or not grid [ 0 ]: return 0 rows , cols = len ( grid ), len ( grid [ 0 ]) num_islands = 0 def dfs ( r , c ): # Base cases for DFS: # 1. Out of bounds # 2. Current cell is water ('0') # 3. Current cell has already been visited (marked as '2') if ( r < 0 or r >= rows or c < 0 or c >= cols or grid [ r ][ c ] == '0' or grid [ r ][ c ] == '2' ): return # Mark the current cell as visited grid [ r ][ c ] = '2' # Explore neighbors dfs ( r + 1 , c ) dfs ( r - 1 , c ) dfs ( r , c + 1 ) dfs ( r , c - 1 ) for r in range ( rows ): for c in range ( cols ): if grid [ r ][ c ] == '1' : num_islands += 1 dfs ( r , c ) return num_islands","title":"Solution"},{"location":"number_of_islands/#explanation","text":"This problem can be solved using a graph traversal algorithm, either Depth-First Search (DFS) or Breadth-First Search (BFS). The idea is to iterate through each cell of the grid. If we encounter a '1' (land), it means we've found a part of an island. We increment our island count and then use DFS (or BFS) to explore the entire connected component of land cells belonging to this island. As we visit each land cell, we mark it as '0' (or any other visited marker, like '2' in the solution) to ensure we don't count it again or get stuck in an infinite loop. DFS Approach: Initialization: Initialize num_islands to 0. Iterate Grid: Loop through each cell (r, c) in the grid. Find Land: If grid[r][c] is '1': Increment num_islands . Call a dfs helper function starting from (r, c) . dfs Helper Function: Base Cases: The dfs function stops if it goes out of bounds, encounters a '0' (water), or encounters a cell that has already been visited. Mark Visited: If the current cell is '1', mark it as visited (e.g., change it to '2'). Explore Neighbors: Recursively call dfs for all four adjacent neighbors (up, down, left, right). By marking visited land cells, we ensure that each island is counted exactly once. The time complexity is O(M * N) because we visit each cell in the grid at most once. The space complexity is O(M * N) in the worst case for the recursion stack of DFS (e.g., a grid full of land).","title":"Explanation"},{"location":"pacific_atlantic_water_flow/","text":"29. Pacific Atlantic Water Flow Problem Statement There is an m x n rectangular island that borders both the Pacific Ocean and the Atlantic Ocean . The Pacific Ocean touches the island's left and top edges, and the Atlantic Ocean touches the island's right and bottom edges. The island is partitioned into a grid of square cells. You are given an m x n integer matrix heights where heights[r][c] represents the height above sea level of the cell at coordinate (r, c) . The island receives a lot of rain, and the rain water can flow to neighboring cells directly north, south, east, and west if the neighboring cell's height is less than or equal to the current cell's height. Water can flow from any cell adjacent to an ocean into the ocean. Return a 2D list of grid coordinates result where result[i] = [ri, ci] denotes that rain water can flow from cell (ri, ci) to both the Pacific and Atlantic oceans . Example 1: Input: heights = [[1,2,2,3,5],[3,2,3,4,4],[2,4,5,3,1],[6,7,1,4,5],[5,1,1,2,4]] Output: [[0,4],[1,3],[1,4],[2,2],[3,0],[3,1],[4,0]] Example 2: Input: heights = [[1]] Output: [[0,0]] Solution class Solution : def pacificAtlantic ( self , heights : list [ list [ int ]]) -> list [ list [ int ]]: if not heights : return [] m , n = len ( heights ), len ( heights [ 0 ]) pacific_reachable = set () atlantic_reachable = set () def dfs ( r , c , reachable_set , prev_height ): # Check boundaries, if already visited, or if water cannot flow up if ( r < 0 or r >= m or c < 0 or c >= n or ( r , c ) in reachable_set or heights [ r ][ c ] < prev_height ): return reachable_set . add (( r , c )) # Explore neighbors dfs ( r + 1 , c , reachable_set , heights [ r ][ c ]) dfs ( r - 1 , c , reachable_set , heights [ r ][ c ]) dfs ( r , c + 1 , reachable_set , heights [ r ][ c ]) dfs ( r , c - 1 , reachable_set , heights [ r ][ c ]) # Start DFS from all cells bordering the Pacific Ocean for r in range ( m ): dfs ( r , 0 , pacific_reachable , 0 ) for c in range ( n ): dfs ( 0 , c , pacific_reachable , 0 ) # Start DFS from all cells bordering the Atlantic Ocean for r in range ( m ): dfs ( r , n - 1 , atlantic_reachable , 0 ) for c in range ( n ): dfs ( m - 1 , c , atlantic_reachable , 0 ) # The result is the intersection of the two sets return list ( pacific_reachable . intersection ( atlantic_reachable )) Explanation Instead of trying to trace the path of water from every cell to the oceans, it's much more efficient to start from the oceans and see which cells the water can reach. The core idea is to find all cells that can flow to the Pacific and all cells that can flow to the Atlantic. The answer is the intersection of these two sets. Start from the Oceans: We can think of this as water flowing \"uphill\" from the oceans. A cell (r, c) can be reached from an ocean if its height is greater than or equal to the height of the cell from which the water is coming. Two Reachable Sets: We use two sets, pacific_reachable and atlantic_reachable , to store the coordinates of the cells that can be reached by each ocean. DFS from Borders: We perform a DFS starting from all the cells on the Pacific border (top and left edges). The dfs function explores all reachable cells from a starting point, adding them to the pacific_reachable set. Similarly, we perform another DFS starting from all the cells on the Atlantic border (bottom and right edges), adding reachable cells to the atlantic_reachable set. DFS Logic: The dfs function takes the current cell (r, c) , the appropriate reachable_set , and the prev_height . It only continues the search if the current cell is within bounds, hasn't been visited yet, and its height is greater than or equal to the prev_height (allowing water to flow \"uphill\"). Intersection: Finally, the cells that can reach both oceans are the ones present in both sets. We find the intersection of pacific_reachable and atlantic_reachable to get our final result. The time complexity is O(m * n) because we visit each cell at most twice (once for the Pacific DFS and once for the Atlantic DFS). The space complexity is also O(m * n) for the recursion stack and the reachable sets.","title":"Pacific Atlantic Water Flow"},{"location":"pacific_atlantic_water_flow/#29-pacific-atlantic-water-flow","text":"","title":"29. Pacific Atlantic Water Flow"},{"location":"pacific_atlantic_water_flow/#problem-statement","text":"There is an m x n rectangular island that borders both the Pacific Ocean and the Atlantic Ocean . The Pacific Ocean touches the island's left and top edges, and the Atlantic Ocean touches the island's right and bottom edges. The island is partitioned into a grid of square cells. You are given an m x n integer matrix heights where heights[r][c] represents the height above sea level of the cell at coordinate (r, c) . The island receives a lot of rain, and the rain water can flow to neighboring cells directly north, south, east, and west if the neighboring cell's height is less than or equal to the current cell's height. Water can flow from any cell adjacent to an ocean into the ocean. Return a 2D list of grid coordinates result where result[i] = [ri, ci] denotes that rain water can flow from cell (ri, ci) to both the Pacific and Atlantic oceans . Example 1: Input: heights = [[1,2,2,3,5],[3,2,3,4,4],[2,4,5,3,1],[6,7,1,4,5],[5,1,1,2,4]] Output: [[0,4],[1,3],[1,4],[2,2],[3,0],[3,1],[4,0]] Example 2: Input: heights = [[1]] Output: [[0,0]]","title":"Problem Statement"},{"location":"pacific_atlantic_water_flow/#solution","text":"class Solution : def pacificAtlantic ( self , heights : list [ list [ int ]]) -> list [ list [ int ]]: if not heights : return [] m , n = len ( heights ), len ( heights [ 0 ]) pacific_reachable = set () atlantic_reachable = set () def dfs ( r , c , reachable_set , prev_height ): # Check boundaries, if already visited, or if water cannot flow up if ( r < 0 or r >= m or c < 0 or c >= n or ( r , c ) in reachable_set or heights [ r ][ c ] < prev_height ): return reachable_set . add (( r , c )) # Explore neighbors dfs ( r + 1 , c , reachable_set , heights [ r ][ c ]) dfs ( r - 1 , c , reachable_set , heights [ r ][ c ]) dfs ( r , c + 1 , reachable_set , heights [ r ][ c ]) dfs ( r , c - 1 , reachable_set , heights [ r ][ c ]) # Start DFS from all cells bordering the Pacific Ocean for r in range ( m ): dfs ( r , 0 , pacific_reachable , 0 ) for c in range ( n ): dfs ( 0 , c , pacific_reachable , 0 ) # Start DFS from all cells bordering the Atlantic Ocean for r in range ( m ): dfs ( r , n - 1 , atlantic_reachable , 0 ) for c in range ( n ): dfs ( m - 1 , c , atlantic_reachable , 0 ) # The result is the intersection of the two sets return list ( pacific_reachable . intersection ( atlantic_reachable ))","title":"Solution"},{"location":"pacific_atlantic_water_flow/#explanation","text":"Instead of trying to trace the path of water from every cell to the oceans, it's much more efficient to start from the oceans and see which cells the water can reach. The core idea is to find all cells that can flow to the Pacific and all cells that can flow to the Atlantic. The answer is the intersection of these two sets. Start from the Oceans: We can think of this as water flowing \"uphill\" from the oceans. A cell (r, c) can be reached from an ocean if its height is greater than or equal to the height of the cell from which the water is coming. Two Reachable Sets: We use two sets, pacific_reachable and atlantic_reachable , to store the coordinates of the cells that can be reached by each ocean. DFS from Borders: We perform a DFS starting from all the cells on the Pacific border (top and left edges). The dfs function explores all reachable cells from a starting point, adding them to the pacific_reachable set. Similarly, we perform another DFS starting from all the cells on the Atlantic border (bottom and right edges), adding reachable cells to the atlantic_reachable set. DFS Logic: The dfs function takes the current cell (r, c) , the appropriate reachable_set , and the prev_height . It only continues the search if the current cell is within bounds, hasn't been visited yet, and its height is greater than or equal to the prev_height (allowing water to flow \"uphill\"). Intersection: Finally, the cells that can reach both oceans are the ones present in both sets. We find the intersection of pacific_reachable and atlantic_reachable to get our final result. The time complexity is O(m * n) because we visit each cell at most twice (once for the Pacific DFS and once for the Atlantic DFS). The space complexity is also O(m * n) for the recursion stack and the reachable sets.","title":"Explanation"},{"location":"palindromic_substrings/","text":"32. Palindromic Substrings Problem Statement Given a string s , return the number of palindromic substrings in it . A string is a palindrome when it reads the same backward as forward. A substring is a contiguous sequence of characters within the string. Example 1: Input: s = \"abc\" Output: 3 Explanation: Three palindromic strings: \"a\", \"b\", \"c\". Example 2: Input: s = \"aaa\" Output: 6 Explanation: Six palindromic strings: \"a\", \"a\", \"a\", \"aa\", \"aa\", \"aaa\". Solution class Solution : def countSubstrings ( self , s : str ) -> int : count = 0 n = len ( s ) def expand_around_center ( left , right ): nonlocal count while left >= 0 and right < n and s [ left ] == s [ right ]: count += 1 # Found a new palindromic substring left -= 1 right += 1 for i in range ( n ): # Odd length palindromes (e.g., \"aba\"), center is s[i] expand_around_center ( i , i ) # Even length palindromes (e.g., \"abba\"), center is between s[i] and s[i+1] expand_around_center ( i , i + 1 ) return count Explanation This problem is a variation of the \"Longest Palindromic Substring\" problem. Instead of finding the longest one, we need to count all of them. The \"expand around center\" approach is very suitable here. Iterate through potential centers: Every single character in the string can be the center of an odd-length palindrome (e.g., a in b_a_b ). Every pair of adjacent characters can be the center of an even-length palindrome (e.g., bb in a_bb_a ). expand_around_center function: This helper function takes left and right pointers, representing the initial center(s). It expands outwards from these pointers as long as the characters match and are within the string boundaries. Crucially, every time a match is found and the pointers are expanded, it means we have found a new palindromic substring . So, we increment our count . Total Count: By calling expand_around_center for every possible single-character center ( i, i ) and every possible two-character center ( i, i+1 ), we ensure that all palindromic substrings are found and counted. The time complexity is O(n^2) because we iterate through each character (n) and for each character, we expand outwards (up to n/2 times). The space complexity is O(1).","title":"Palindromic Substrings"},{"location":"palindromic_substrings/#32-palindromic-substrings","text":"","title":"32. Palindromic Substrings"},{"location":"palindromic_substrings/#problem-statement","text":"Given a string s , return the number of palindromic substrings in it . A string is a palindrome when it reads the same backward as forward. A substring is a contiguous sequence of characters within the string. Example 1: Input: s = \"abc\" Output: 3 Explanation: Three palindromic strings: \"a\", \"b\", \"c\". Example 2: Input: s = \"aaa\" Output: 6 Explanation: Six palindromic strings: \"a\", \"a\", \"a\", \"aa\", \"aa\", \"aaa\".","title":"Problem Statement"},{"location":"palindromic_substrings/#solution","text":"class Solution : def countSubstrings ( self , s : str ) -> int : count = 0 n = len ( s ) def expand_around_center ( left , right ): nonlocal count while left >= 0 and right < n and s [ left ] == s [ right ]: count += 1 # Found a new palindromic substring left -= 1 right += 1 for i in range ( n ): # Odd length palindromes (e.g., \"aba\"), center is s[i] expand_around_center ( i , i ) # Even length palindromes (e.g., \"abba\"), center is between s[i] and s[i+1] expand_around_center ( i , i + 1 ) return count","title":"Solution"},{"location":"palindromic_substrings/#explanation","text":"This problem is a variation of the \"Longest Palindromic Substring\" problem. Instead of finding the longest one, we need to count all of them. The \"expand around center\" approach is very suitable here. Iterate through potential centers: Every single character in the string can be the center of an odd-length palindrome (e.g., a in b_a_b ). Every pair of adjacent characters can be the center of an even-length palindrome (e.g., bb in a_bb_a ). expand_around_center function: This helper function takes left and right pointers, representing the initial center(s). It expands outwards from these pointers as long as the characters match and are within the string boundaries. Crucially, every time a match is found and the pointers are expanded, it means we have found a new palindromic substring . So, we increment our count . Total Count: By calling expand_around_center for every possible single-character center ( i, i ) and every possible two-character center ( i, i+1 ), we ensure that all palindromic substrings are found and counted. The time complexity is O(n^2) because we iterate through each character (n) and for each character, we expand outwards (up to n/2 times). The space complexity is O(1).","title":"Explanation"},{"location":"permutation_in_string/","text":"42. Permutation in String Problem Statement Given two strings s1 and s2 , return true if s2 contains one of the permutations of s1 , or false otherwise. In other words, return true if one of s1 's permutations is the substring of s2 . Example 1: Input: s1 = \"ab\", s2 = \"eidbaooo\" Output: true Explanation: s2 contains one permutation of s1 (\"ba\"). Example 2: Input: s1 = \"ab\", s2 = \"eidboaoo\" Output: false Solution from collections import Counter class Solution : def checkInclusion ( self , s1 : str , s2 : str ) -> bool : len1 , len2 = len ( s1 ), len ( s2 ) if len1 > len2 : return False # Count character frequencies for s1 s1_counts = Counter ( s1 ) # Count character frequencies for the initial window in s2 window_counts = Counter ( s2 [: len1 ]) # Check if the initial window is a permutation if s1_counts == window_counts : return True # Slide the window across s2 for i in range ( len1 , len2 ): # Add the new character entering the window window_counts [ s2 [ i ]] += 1 # Remove the character leaving the window window_counts [ s2 [ i - len1 ]] -= 1 # If a character count becomes zero, remove it from the counter # to ensure accurate comparison with s1_counts if window_counts [ s2 [ i - len1 ]] == 0 : del window_counts [ s2 [ i - len1 ]] # Check if the current window is a permutation if s1_counts == window_counts : return True return False Explanation This problem can be solved using a sliding window approach combined with frequency maps. Core Idea: A string s2 contains a permutation of s1 if there is a substring in s2 that has the exact same character counts as s1 . Initial Setup: Check if len(s1) is greater than len(s2) . If so, a permutation of s1 cannot exist in s2 , so return False . Create a frequency map ( s1_counts ) for s1 . Create a frequency map ( window_counts ) for the initial window in s2 (of length len(s1) ). Compare s1_counts and window_counts . If they are equal, we found a permutation. Sliding Window: Iterate from len1 to len2 - 1 (the end of s2 ). In each iteration, we simulate sliding the window one position to the right. Add Character: Add the new character s2[i] (entering the window) to window_counts . Remove Character: Remove the character s2[i - len1] (leaving the window) from window_counts . If its count becomes 0, delete it from the map to ensure accurate comparison. Compare: After updating window_counts , compare it with s1_counts . If they are equal, return True . Return False: If the loop completes without finding a matching window, return False . Time and Space Complexity: Time Complexity: O(L1 + L2), where L1 is len(s1) and L2 is len(s2) . We iterate through s1 once to build its frequency map, and then iterate through s2 once with the sliding window. Dictionary operations (add, remove, compare) take O(alphabet_size) time, which is constant (26 for lowercase English letters). Space Complexity: O(alphabet_size) for storing the frequency maps.","title":"Permutation in String"},{"location":"permutation_in_string/#42-permutation-in-string","text":"","title":"42. Permutation in String"},{"location":"permutation_in_string/#problem-statement","text":"Given two strings s1 and s2 , return true if s2 contains one of the permutations of s1 , or false otherwise. In other words, return true if one of s1 's permutations is the substring of s2 . Example 1: Input: s1 = \"ab\", s2 = \"eidbaooo\" Output: true Explanation: s2 contains one permutation of s1 (\"ba\"). Example 2: Input: s1 = \"ab\", s2 = \"eidboaoo\" Output: false","title":"Problem Statement"},{"location":"permutation_in_string/#solution","text":"from collections import Counter class Solution : def checkInclusion ( self , s1 : str , s2 : str ) -> bool : len1 , len2 = len ( s1 ), len ( s2 ) if len1 > len2 : return False # Count character frequencies for s1 s1_counts = Counter ( s1 ) # Count character frequencies for the initial window in s2 window_counts = Counter ( s2 [: len1 ]) # Check if the initial window is a permutation if s1_counts == window_counts : return True # Slide the window across s2 for i in range ( len1 , len2 ): # Add the new character entering the window window_counts [ s2 [ i ]] += 1 # Remove the character leaving the window window_counts [ s2 [ i - len1 ]] -= 1 # If a character count becomes zero, remove it from the counter # to ensure accurate comparison with s1_counts if window_counts [ s2 [ i - len1 ]] == 0 : del window_counts [ s2 [ i - len1 ]] # Check if the current window is a permutation if s1_counts == window_counts : return True return False","title":"Solution"},{"location":"permutation_in_string/#explanation","text":"This problem can be solved using a sliding window approach combined with frequency maps. Core Idea: A string s2 contains a permutation of s1 if there is a substring in s2 that has the exact same character counts as s1 . Initial Setup: Check if len(s1) is greater than len(s2) . If so, a permutation of s1 cannot exist in s2 , so return False . Create a frequency map ( s1_counts ) for s1 . Create a frequency map ( window_counts ) for the initial window in s2 (of length len(s1) ). Compare s1_counts and window_counts . If they are equal, we found a permutation. Sliding Window: Iterate from len1 to len2 - 1 (the end of s2 ). In each iteration, we simulate sliding the window one position to the right. Add Character: Add the new character s2[i] (entering the window) to window_counts . Remove Character: Remove the character s2[i - len1] (leaving the window) from window_counts . If its count becomes 0, delete it from the map to ensure accurate comparison. Compare: After updating window_counts , compare it with s1_counts . If they are equal, return True . Return False: If the loop completes without finding a matching window, return False . Time and Space Complexity: Time Complexity: O(L1 + L2), where L1 is len(s1) and L2 is len(s2) . We iterate through s1 once to build its frequency map, and then iterate through s2 once with the sliding window. Dictionary operations (add, remove, compare) take O(alphabet_size) time, which is constant (26 for lowercase English letters). Space Complexity: O(alphabet_size) for storing the frequency maps.","title":"Explanation"},{"location":"product_of_array_except_self/","text":"4. Product of Array Except Self Problem Statement Given an integer array nums , return an array answer such that answer[i] is equal to the product of all the elements of nums except nums[i] . The product of any prefix or suffix of nums is guaranteed to fit in a 32-bit integer. You must write an algorithm that runs in O(n) time and without using the division operation. Example 1: Input: nums = [1,2,3,4] Output: [24,12,8,6] Example 2: Input: nums = [-1,1,0,-3,3] Output: [0,0,9,0,0] Solution class Solution : def productExceptSelf ( self , nums : list [ int ]) -> list [ int ]: n = len ( nums ) answer = [ 1 ] * n # Calculate left products left_product = 1 for i in range ( n ): answer [ i ] = left_product left_product *= nums [ i ] # Calculate right products and multiply right_product = 1 for i in range ( n - 1 , - 1 , - 1 ): answer [ i ] *= right_product right_product *= nums [ i ] return answer Explanation This solution avoids division and achieves O(n) time complexity by using a two-pass approach. First Pass (Left Products): We create an answer array of the same size as nums , initialized with 1s. We iterate from left to right. For each position i , we set answer[i] to the product of all elements to its left. We use a left_product variable to keep track of this running product. Second Pass (Right Products): We then iterate from right to left. This time, we use a right_product variable to track the product of elements to the right of the current position. We multiply the existing answer[i] (which already holds the left product) by the right_product to get the final result. This method cleverly calculates the total product except for the element at the current index by combining the products of its left and right sides. The space complexity is O(1) if we don't count the output array, as we are modifying it in place.","title":"Product of Array Except Self"},{"location":"product_of_array_except_self/#4-product-of-array-except-self","text":"","title":"4. Product of Array Except Self"},{"location":"product_of_array_except_self/#problem-statement","text":"Given an integer array nums , return an array answer such that answer[i] is equal to the product of all the elements of nums except nums[i] . The product of any prefix or suffix of nums is guaranteed to fit in a 32-bit integer. You must write an algorithm that runs in O(n) time and without using the division operation. Example 1: Input: nums = [1,2,3,4] Output: [24,12,8,6] Example 2: Input: nums = [-1,1,0,-3,3] Output: [0,0,9,0,0]","title":"Problem Statement"},{"location":"product_of_array_except_self/#solution","text":"class Solution : def productExceptSelf ( self , nums : list [ int ]) -> list [ int ]: n = len ( nums ) answer = [ 1 ] * n # Calculate left products left_product = 1 for i in range ( n ): answer [ i ] = left_product left_product *= nums [ i ] # Calculate right products and multiply right_product = 1 for i in range ( n - 1 , - 1 , - 1 ): answer [ i ] *= right_product right_product *= nums [ i ] return answer","title":"Solution"},{"location":"product_of_array_except_self/#explanation","text":"This solution avoids division and achieves O(n) time complexity by using a two-pass approach. First Pass (Left Products): We create an answer array of the same size as nums , initialized with 1s. We iterate from left to right. For each position i , we set answer[i] to the product of all elements to its left. We use a left_product variable to keep track of this running product. Second Pass (Right Products): We then iterate from right to left. This time, we use a right_product variable to track the product of elements to the right of the current position. We multiply the existing answer[i] (which already holds the left product) by the right_product to get the final result. This method cleverly calculates the total product except for the element at the current index by combining the products of its left and right sides. The space complexity is O(1) if we don't count the output array, as we are modifying it in place.","title":"Explanation"},{"location":"remove_duplicates_from_sorted_list/","text":"54. Remove Duplicates from Sorted List Problem Statement Given the head of a sorted linked list, delete all duplicates such that each element appears only once . Return the linked list sorted as well . Example 1: Input: head = [1,1,2] Output: [1,2] Example 2: Input: head = [1,1,2,3,3] Output: [1,2,3] Solution # Definition for singly-linked list. class ListNode : def __init__ ( self , val = 0 , next = None ): self . val = val self . next = next class Solution : def deleteDuplicates ( self , head : ListNode ) -> ListNode : current = head while current and current . next : if current . val == current . next . val : # Skip the duplicate node current . next = current . next . next else : # Move to the next node if no duplicate is found current = current . next return head Explanation This problem is straightforward because the linked list is already sorted. This means any duplicate values will be adjacent to each other. Algorithm: Initialize current pointer: Start a current pointer at the head of the linked list. Iterate and Compare: Iterate through the list as long as current and current.next are not None . If current.val is equal to current.next.val : This indicates a duplicate. To remove the duplicate, we simply bypass current.next by setting current.next = current.next.next . We do not advance current in this case, because the new current.next might also be a duplicate of current.val . If current.val is not equal to current.next.val : No duplicate is found, so we advance current to current.next to check the next pair. Return Head: After the loop finishes, the list will have all duplicates removed, and we return the original head (which might have changed if the first few elements were duplicates). Time and Space Complexity: Time Complexity: O(n), where n is the number of nodes in the linked list, as we iterate through the list once. Space Complexity: O(1), as we only use a few extra pointers.","title":"Remove Duplicates from Sorted List"},{"location":"remove_duplicates_from_sorted_list/#54-remove-duplicates-from-sorted-list","text":"","title":"54. Remove Duplicates from Sorted List"},{"location":"remove_duplicates_from_sorted_list/#problem-statement","text":"Given the head of a sorted linked list, delete all duplicates such that each element appears only once . Return the linked list sorted as well . Example 1: Input: head = [1,1,2] Output: [1,2] Example 2: Input: head = [1,1,2,3,3] Output: [1,2,3]","title":"Problem Statement"},{"location":"remove_duplicates_from_sorted_list/#solution","text":"# Definition for singly-linked list. class ListNode : def __init__ ( self , val = 0 , next = None ): self . val = val self . next = next class Solution : def deleteDuplicates ( self , head : ListNode ) -> ListNode : current = head while current and current . next : if current . val == current . next . val : # Skip the duplicate node current . next = current . next . next else : # Move to the next node if no duplicate is found current = current . next return head","title":"Solution"},{"location":"remove_duplicates_from_sorted_list/#explanation","text":"This problem is straightforward because the linked list is already sorted. This means any duplicate values will be adjacent to each other. Algorithm: Initialize current pointer: Start a current pointer at the head of the linked list. Iterate and Compare: Iterate through the list as long as current and current.next are not None . If current.val is equal to current.next.val : This indicates a duplicate. To remove the duplicate, we simply bypass current.next by setting current.next = current.next.next . We do not advance current in this case, because the new current.next might also be a duplicate of current.val . If current.val is not equal to current.next.val : No duplicate is found, so we advance current to current.next to check the next pair. Return Head: After the loop finishes, the list will have all duplicates removed, and we return the original head (which might have changed if the first few elements were duplicates). Time and Space Complexity: Time Complexity: O(n), where n is the number of nodes in the linked list, as we iterate through the list once. Space Complexity: O(1), as we only use a few extra pointers.","title":"Explanation"},{"location":"remove_duplicates_from_sorted_list_ii/","text":"55. Remove Duplicates from Sorted List II Problem Statement Given the head of a sorted linked list, delete all nodes that have duplicate numbers, leaving only distinct numbers from the original list . Return the linked list sorted as well . Example 1: Input: head = [1,2,3,3,4,4,5] Output: [1,2,5] Example 2: Input: head = [1,1,1,2,3] Output: [2,3] Solution # Definition for singly-linked list. class ListNode : def __init__ ( self , val = 0 , next = None ): self . val = val self . next = next class Solution : def deleteDuplicates ( self , head : ListNode ) -> ListNode : # Create a dummy node to handle cases where the head might be a duplicate dummy = ListNode ( 0 , head ) prev = dummy while head : # If it's a duplicate (current node's value is same as next node's value) # and next node exists if head . next and head . val == head . next . val : # Skip all nodes with the same value while head . next and head . val == head . next . val : head = head . next # Link prev to the node after the duplicates prev . next = head . next else : # Not a duplicate, move prev forward prev = prev . next # Move head forward head = head . next return dummy . next Explanation This problem is a more complex version of \"Remove Duplicates from Sorted List\". Here, we need to remove all nodes that have duplicate numbers, not just the duplicate occurrences themselves. Algorithm: Dummy Node: We use a dummy node to simplify handling cases where the original head itself might be a duplicate and needs to be removed. prev pointer is initialized to dummy . Iterate with head and prev : We use head to traverse the list and prev to build the new list without duplicates. Duplicate Detection and Removal: Condition for Duplicate: We check if head.next exists and if head.val == head.next.val . This indicates that head is part of a sequence of duplicates. Skip Duplicates: If a duplicate sequence is found, we enter an inner while loop. This loop advances head past all nodes that have the same value as the current head.val . Relink prev : After the inner loop, head will be pointing to the last duplicate node (or the node just before the next distinct value). We then update prev.next = head.next . This effectively removes the entire block of duplicate nodes from the list. Non-Duplicate Case: If head.next does not exist or head.val != head.next.val , it means head is a unique node (or the last node in a sequence of duplicates). In this case, we simply advance prev to prev.next . Advance head : In both cases (duplicate or not), we advance head to head.next to continue scanning the list. Return Result: dummy.next will be the head of the modified list. Time and Space Complexity: Time Complexity: O(n), where n is the number of nodes in the linked list. We iterate through the list once. Space Complexity: O(1), as we only use a few extra pointers.","title":"Remove Duplicates from Sorted List II"},{"location":"remove_duplicates_from_sorted_list_ii/#55-remove-duplicates-from-sorted-list-ii","text":"","title":"55. Remove Duplicates from Sorted List II"},{"location":"remove_duplicates_from_sorted_list_ii/#problem-statement","text":"Given the head of a sorted linked list, delete all nodes that have duplicate numbers, leaving only distinct numbers from the original list . Return the linked list sorted as well . Example 1: Input: head = [1,2,3,3,4,4,5] Output: [1,2,5] Example 2: Input: head = [1,1,1,2,3] Output: [2,3]","title":"Problem Statement"},{"location":"remove_duplicates_from_sorted_list_ii/#solution","text":"# Definition for singly-linked list. class ListNode : def __init__ ( self , val = 0 , next = None ): self . val = val self . next = next class Solution : def deleteDuplicates ( self , head : ListNode ) -> ListNode : # Create a dummy node to handle cases where the head might be a duplicate dummy = ListNode ( 0 , head ) prev = dummy while head : # If it's a duplicate (current node's value is same as next node's value) # and next node exists if head . next and head . val == head . next . val : # Skip all nodes with the same value while head . next and head . val == head . next . val : head = head . next # Link prev to the node after the duplicates prev . next = head . next else : # Not a duplicate, move prev forward prev = prev . next # Move head forward head = head . next return dummy . next","title":"Solution"},{"location":"remove_duplicates_from_sorted_list_ii/#explanation","text":"This problem is a more complex version of \"Remove Duplicates from Sorted List\". Here, we need to remove all nodes that have duplicate numbers, not just the duplicate occurrences themselves. Algorithm: Dummy Node: We use a dummy node to simplify handling cases where the original head itself might be a duplicate and needs to be removed. prev pointer is initialized to dummy . Iterate with head and prev : We use head to traverse the list and prev to build the new list without duplicates. Duplicate Detection and Removal: Condition for Duplicate: We check if head.next exists and if head.val == head.next.val . This indicates that head is part of a sequence of duplicates. Skip Duplicates: If a duplicate sequence is found, we enter an inner while loop. This loop advances head past all nodes that have the same value as the current head.val . Relink prev : After the inner loop, head will be pointing to the last duplicate node (or the node just before the next distinct value). We then update prev.next = head.next . This effectively removes the entire block of duplicate nodes from the list. Non-Duplicate Case: If head.next does not exist or head.val != head.next.val , it means head is a unique node (or the last node in a sequence of duplicates). In this case, we simply advance prev to prev.next . Advance head : In both cases (duplicate or not), we advance head to head.next to continue scanning the list. Return Result: dummy.next will be the head of the modified list. Time and Space Complexity: Time Complexity: O(n), where n is the number of nodes in the linked list. We iterate through the list once. Space Complexity: O(1), as we only use a few extra pointers.","title":"Explanation"},{"location":"remove_nth_node_from_end_of_list/","text":"46. Remove Nth Node From End of List Problem Statement Given the head of a linked list, remove the n th node from the end of the list and return its head. Example 1: Input: head = [1,2,3,4,5], n = 2 Output: [1,2,3,5] Example 2: Input: head = [1], n = 1 Output: [] Example 3: Input: head = [1,2], n = 1 Output: [1] Solution # Definition for singly-linked list. class ListNode : def __init__ ( self , val = 0 , next = None ): self . val = val self . next = next class Solution : def removeNthFromEnd ( self , head : ListNode , n : int ) -> ListNode : # Create a dummy node to handle edge cases (e.g., removing the head) dummy = ListNode ( 0 , head ) first = dummy second = dummy # Move first pointer n+1 steps ahead # This creates a gap of n nodes between first and second for _ in range ( n + 1 ): first = first . next # Move both pointers until first reaches the end # When first reaches the end, second will be at the node just before # the one to be removed. while first : first = first . next second = second . next # Remove the nth node from the end second . next = second . next . next return dummy . next Explanation This problem can be efficiently solved using the two-pointer technique. Core Idea: We want to find the node that is n positions away from the end of the list. If we have two pointers, first and second , and first is n steps ahead of second , then when first reaches the end of the list, second will be at the node just before the n th node from the end. Dummy Node: We create a dummy node and point its next to the head of the original list. This simplifies handling edge cases, especially when the node to be removed is the head of the original list. Initialize Pointers: Both first and second pointers are initialized to the dummy node. Advance first : We move the first pointer n + 1 steps ahead. This creates a gap of n nodes between first and second . Move Both Pointers: We then move both first and second pointers one step at a time until first reaches None (the end of the list). When first becomes None , second will be pointing to the node before the n th node from the end. Remove Node: We then update second.next to second.next.next , effectively bypassing and removing the n th node from the end. Return Result: We return dummy.next , which is the head of the modified list. Time and Space Complexity: Time Complexity: O(L), where L is the length of the linked list. We traverse the list at most twice (once to advance first , and then both pointers move together). Space Complexity: O(1), as we only use a few extra pointers.","title":"Remove Nth Node From End of List"},{"location":"remove_nth_node_from_end_of_list/#46-remove-nth-node-from-end-of-list","text":"","title":"46. Remove Nth Node From End of List"},{"location":"remove_nth_node_from_end_of_list/#problem-statement","text":"Given the head of a linked list, remove the n th node from the end of the list and return its head. Example 1: Input: head = [1,2,3,4,5], n = 2 Output: [1,2,3,5] Example 2: Input: head = [1], n = 1 Output: [] Example 3: Input: head = [1,2], n = 1 Output: [1]","title":"Problem Statement"},{"location":"remove_nth_node_from_end_of_list/#solution","text":"# Definition for singly-linked list. class ListNode : def __init__ ( self , val = 0 , next = None ): self . val = val self . next = next class Solution : def removeNthFromEnd ( self , head : ListNode , n : int ) -> ListNode : # Create a dummy node to handle edge cases (e.g., removing the head) dummy = ListNode ( 0 , head ) first = dummy second = dummy # Move first pointer n+1 steps ahead # This creates a gap of n nodes between first and second for _ in range ( n + 1 ): first = first . next # Move both pointers until first reaches the end # When first reaches the end, second will be at the node just before # the one to be removed. while first : first = first . next second = second . next # Remove the nth node from the end second . next = second . next . next return dummy . next","title":"Solution"},{"location":"remove_nth_node_from_end_of_list/#explanation","text":"This problem can be efficiently solved using the two-pointer technique. Core Idea: We want to find the node that is n positions away from the end of the list. If we have two pointers, first and second , and first is n steps ahead of second , then when first reaches the end of the list, second will be at the node just before the n th node from the end. Dummy Node: We create a dummy node and point its next to the head of the original list. This simplifies handling edge cases, especially when the node to be removed is the head of the original list. Initialize Pointers: Both first and second pointers are initialized to the dummy node. Advance first : We move the first pointer n + 1 steps ahead. This creates a gap of n nodes between first and second . Move Both Pointers: We then move both first and second pointers one step at a time until first reaches None (the end of the list). When first becomes None , second will be pointing to the node before the n th node from the end. Remove Node: We then update second.next to second.next.next , effectively bypassing and removing the n th node from the end. Return Result: We return dummy.next , which is the head of the modified list. Time and Space Complexity: Time Complexity: O(L), where L is the length of the linked list. We traverse the list at most twice (once to advance first , and then both pointers move together). Space Complexity: O(1), as we only use a few extra pointers.","title":"Explanation"},{"location":"reorder_list/","text":"45. Reorder List Problem Statement You are given the head of a singly linked list L : L0 \u2192 L1 \u2192 ... \u2192 Ln-1 \u2192 Ln . Reorder the list to be on the following form: L0 \u2192 Ln \u2192 L1 \u2192 Ln-1 \u2192 L2 \u2192 Ln-2 \u2192 ... You may not modify the values in the list's nodes. Only nodes themselves may be changed. Example 1: Input: head = [1,2,3,4] Output: [1,4,2,3] Example 2: Input: head = [1,2,3,4,5] Output: [1,5,2,4,3] Solution # Definition for singly-linked list. class ListNode : def __init__ ( self , val = 0 , next = None ): self . val = val self . next = next class Solution : def reorderList ( self , head : ListNode ) -> None : \"\"\" Do not return anything, modify head in-place instead. \"\"\" if not head or not head . next : return # Step 1: Find the middle of the linked list slow , fast = head , head while fast and fast . next : slow = slow . next fast = fast . next . next # slow is now at the middle node # Step 2: Split the list into two halves # first_half: head -> ... -> slow (before split) # second_half: slow.next -> ... -> None second_half = slow . next slow . next = None # Break the link to separate the two halves first_half = head # Step 3: Reverse the second half of the list prev = None curr = second_half while curr : next_temp = curr . next curr . next = prev prev = curr curr = next_temp second_half_reversed = prev # Step 4: Merge the two halves # L0 -> L1 -> L2 -> ... # Ln -> Ln-1 -> Ln-2 -> ... # Merge: L0 -> Ln -> L1 -> Ln-1 -> ... p1 , p2 = first_half , second_half_reversed while p2 : temp1 = p1 . next temp2 = p2 . next p1 . next = p2 p2 . next = temp1 p1 = temp1 p2 = temp2 Explanation This problem requires reordering a linked list in a specific pattern. It can be broken down into three main steps: Find the Middle of the Linked List: We use the fast and slow pointer technique. The fast pointer moves two steps at a time, and the slow pointer moves one step at a time. When fast reaches the end (or None ), slow will be at the middle of the list. Split the List into Two Halves: Once slow is at the middle, we break the link between the first half and the second half. slow.next becomes None , effectively terminating the first half. The second half starts from slow.next (before slow.next was set to None ). Reverse the Second Half: We reverse the second half of the linked list. This is a standard linked list reversal operation (as seen in problem 44, \"Reverse Linked List\"). Merge the Two Halves: Now we have two lists: the first half ( L0 -> L1 -> L2 -> ... ) and the reversed second half ( Ln -> Ln-1 -> Ln-2 -> ... ). We merge them by alternating nodes: L0 points to Ln , Ln points to L1 , L1 points to Ln-1 , and so on. We use two pointers, p1 for the first half and p2 for the reversed second half. In each step, we adjust the next pointers to interleave the nodes. Time and Space Complexity: Time Complexity: O(n), where n is the number of nodes in the linked list. Each step (finding middle, splitting, reversing, merging) takes linear time. Space Complexity: O(1), as we are modifying the list in-place and only using a few extra pointers.","title":"Reorder List"},{"location":"reorder_list/#45-reorder-list","text":"","title":"45. Reorder List"},{"location":"reorder_list/#problem-statement","text":"You are given the head of a singly linked list L : L0 \u2192 L1 \u2192 ... \u2192 Ln-1 \u2192 Ln . Reorder the list to be on the following form: L0 \u2192 Ln \u2192 L1 \u2192 Ln-1 \u2192 L2 \u2192 Ln-2 \u2192 ... You may not modify the values in the list's nodes. Only nodes themselves may be changed. Example 1: Input: head = [1,2,3,4] Output: [1,4,2,3] Example 2: Input: head = [1,2,3,4,5] Output: [1,5,2,4,3]","title":"Problem Statement"},{"location":"reorder_list/#solution","text":"# Definition for singly-linked list. class ListNode : def __init__ ( self , val = 0 , next = None ): self . val = val self . next = next class Solution : def reorderList ( self , head : ListNode ) -> None : \"\"\" Do not return anything, modify head in-place instead. \"\"\" if not head or not head . next : return # Step 1: Find the middle of the linked list slow , fast = head , head while fast and fast . next : slow = slow . next fast = fast . next . next # slow is now at the middle node # Step 2: Split the list into two halves # first_half: head -> ... -> slow (before split) # second_half: slow.next -> ... -> None second_half = slow . next slow . next = None # Break the link to separate the two halves first_half = head # Step 3: Reverse the second half of the list prev = None curr = second_half while curr : next_temp = curr . next curr . next = prev prev = curr curr = next_temp second_half_reversed = prev # Step 4: Merge the two halves # L0 -> L1 -> L2 -> ... # Ln -> Ln-1 -> Ln-2 -> ... # Merge: L0 -> Ln -> L1 -> Ln-1 -> ... p1 , p2 = first_half , second_half_reversed while p2 : temp1 = p1 . next temp2 = p2 . next p1 . next = p2 p2 . next = temp1 p1 = temp1 p2 = temp2","title":"Solution"},{"location":"reorder_list/#explanation","text":"This problem requires reordering a linked list in a specific pattern. It can be broken down into three main steps: Find the Middle of the Linked List: We use the fast and slow pointer technique. The fast pointer moves two steps at a time, and the slow pointer moves one step at a time. When fast reaches the end (or None ), slow will be at the middle of the list. Split the List into Two Halves: Once slow is at the middle, we break the link between the first half and the second half. slow.next becomes None , effectively terminating the first half. The second half starts from slow.next (before slow.next was set to None ). Reverse the Second Half: We reverse the second half of the linked list. This is a standard linked list reversal operation (as seen in problem 44, \"Reverse Linked List\"). Merge the Two Halves: Now we have two lists: the first half ( L0 -> L1 -> L2 -> ... ) and the reversed second half ( Ln -> Ln-1 -> Ln-2 -> ... ). We merge them by alternating nodes: L0 points to Ln , Ln points to L1 , L1 points to Ln-1 , and so on. We use two pointers, p1 for the first half and p2 for the reversed second half. In each step, we adjust the next pointers to interleave the nodes. Time and Space Complexity: Time Complexity: O(n), where n is the number of nodes in the linked list. Each step (finding middle, splitting, reversing, merging) takes linear time. Space Complexity: O(1), as we are modifying the list in-place and only using a few extra pointers.","title":"Explanation"},{"location":"reverse_bits/","text":"15. Reverse Bits Problem Statement Reverse bits of a given 32 bits unsigned integer. Note: Note that in some languages like Java, there is no unsigned integer type. In this case, both input and output will be given as a signed integer type. They should not affect your implementation, as the integer's internal binary representation is the same, whether it is signed or unsigned. In Java, the compiler represents the signed integers using 2's complement notation. Therefore, in Example 2, the input represents the signed integer -3 and the output represents the signed integer -1073741825. Example 1: Input: n = 00000010100101000001111010011100 Output: 00111001011110000010100101000000 Example 2: Input: n = 11111111111111111111111111111101 Output: 10111111111111111111111111111111 Solution class Solution : def reverseBits ( self , n : int ) -> int : res = 0 for i in range ( 32 ): # Left shift the result to make space for the next bit res <<= 1 # Get the least significant bit of n bit = n & 1 # Add the bit to the result res |= bit # Right shift n to process the next bit n >>= 1 return res Explanation This solution reverses the bits of a 32-bit integer by iterating 32 times, once for each bit. In each iteration, we do the following: res <<= 1 : We make space in our res (result) variable for the next bit by shifting it to the left. bit = n & 1 : We extract the least significant bit (LSB) of the input n using the AND operator with 1. res |= bit : We add this extracted bit to our result using the OR operator. n >>= 1 : We shift the input n to the right to discard the LSB and expose the next bit for the following iteration. This process effectively builds the reversed number bit by bit, from right to left in the original number, which becomes left to right in the new number. The time complexity is O(1) because the loop runs a fixed 32 times, regardless of the input value. The space complexity is also O(1).","title":"Reverse Bits"},{"location":"reverse_bits/#15-reverse-bits","text":"","title":"15. Reverse Bits"},{"location":"reverse_bits/#problem-statement","text":"Reverse bits of a given 32 bits unsigned integer. Note: Note that in some languages like Java, there is no unsigned integer type. In this case, both input and output will be given as a signed integer type. They should not affect your implementation, as the integer's internal binary representation is the same, whether it is signed or unsigned. In Java, the compiler represents the signed integers using 2's complement notation. Therefore, in Example 2, the input represents the signed integer -3 and the output represents the signed integer -1073741825. Example 1: Input: n = 00000010100101000001111010011100 Output: 00111001011110000010100101000000 Example 2: Input: n = 11111111111111111111111111111101 Output: 10111111111111111111111111111111","title":"Problem Statement"},{"location":"reverse_bits/#solution","text":"class Solution : def reverseBits ( self , n : int ) -> int : res = 0 for i in range ( 32 ): # Left shift the result to make space for the next bit res <<= 1 # Get the least significant bit of n bit = n & 1 # Add the bit to the result res |= bit # Right shift n to process the next bit n >>= 1 return res","title":"Solution"},{"location":"reverse_bits/#explanation","text":"This solution reverses the bits of a 32-bit integer by iterating 32 times, once for each bit. In each iteration, we do the following: res <<= 1 : We make space in our res (result) variable for the next bit by shifting it to the left. bit = n & 1 : We extract the least significant bit (LSB) of the input n using the AND operator with 1. res |= bit : We add this extracted bit to our result using the OR operator. n >>= 1 : We shift the input n to the right to discard the LSB and expose the next bit for the following iteration. This process effectively builds the reversed number bit by bit, from right to left in the original number, which becomes left to right in the new number. The time complexity is O(1) because the loop runs a fixed 32 times, regardless of the input value. The space complexity is also O(1).","title":"Explanation"},{"location":"reverse_linked_list/","text":"44. Reverse Linked List Problem Statement Given the head of a singly linked list, reverse the list, and return the reversed list . Example 1: Input: head = [1,2,3,4,5] Output: [5,4,3,2,1] Example 2: Input: head = [1,2] Output: [2,1] Example 3: Input: head = [] Output: [] Solution # Definition for singly-linked list. class ListNode : def __init__ ( self , val = 0 , next = None ): self . val = val self . next = next class Solution : def reverseList ( self , head : ListNode ) -> ListNode : prev = None curr = head while curr : # Store the next node next_temp = curr . next # Reverse the current node's pointer curr . next = prev # Move pointers one step forward prev = curr curr = next_temp return prev Explanation This problem is a classic linked list manipulation task. The goal is to reverse the direction of the pointers in the list. Iterative Approach: We use three pointers: prev : Initially None . This pointer will eventually become the new head of the reversed list. curr : Initially head . This pointer iterates through the original list. next_temp : A temporary pointer to store curr.next before curr.next is changed. Algorithm: We iterate while curr is not None : Step 1: Store next_temp : Save the curr.next node in next_temp . This is crucial because we are about to change curr.next , and we need to retain the link to the rest of the original list. Step 2: Reverse Pointer: Change curr.next to point to prev . This is the actual reversal step. Step 3: Advance prev : Move prev to curr . The curr node has now been processed and becomes the new prev for the next iteration. Step 4: Advance curr : Move curr to next_temp . This moves curr to the next node in the original list. When the loop finishes, curr will be None , and prev will be pointing to the last node of the original list, which is now the head of the reversed list. Time and Space Complexity: Time Complexity: O(n), where n is the number of nodes in the linked list, as we iterate through the list once. Space Complexity: O(1), as we only use a few extra pointers.","title":"Reverse Linked List"},{"location":"reverse_linked_list/#44-reverse-linked-list","text":"","title":"44. Reverse Linked List"},{"location":"reverse_linked_list/#problem-statement","text":"Given the head of a singly linked list, reverse the list, and return the reversed list . Example 1: Input: head = [1,2,3,4,5] Output: [5,4,3,2,1] Example 2: Input: head = [1,2] Output: [2,1] Example 3: Input: head = [] Output: []","title":"Problem Statement"},{"location":"reverse_linked_list/#solution","text":"# Definition for singly-linked list. class ListNode : def __init__ ( self , val = 0 , next = None ): self . val = val self . next = next class Solution : def reverseList ( self , head : ListNode ) -> ListNode : prev = None curr = head while curr : # Store the next node next_temp = curr . next # Reverse the current node's pointer curr . next = prev # Move pointers one step forward prev = curr curr = next_temp return prev","title":"Solution"},{"location":"reverse_linked_list/#explanation","text":"This problem is a classic linked list manipulation task. The goal is to reverse the direction of the pointers in the list. Iterative Approach: We use three pointers: prev : Initially None . This pointer will eventually become the new head of the reversed list. curr : Initially head . This pointer iterates through the original list. next_temp : A temporary pointer to store curr.next before curr.next is changed. Algorithm: We iterate while curr is not None : Step 1: Store next_temp : Save the curr.next node in next_temp . This is crucial because we are about to change curr.next , and we need to retain the link to the rest of the original list. Step 2: Reverse Pointer: Change curr.next to point to prev . This is the actual reversal step. Step 3: Advance prev : Move prev to curr . The curr node has now been processed and becomes the new prev for the next iteration. Step 4: Advance curr : Move curr to next_temp . This moves curr to the next node in the original list. When the loop finishes, curr will be None , and prev will be pointing to the last node of the original list, which is now the head of the reversed list. Time and Space Complexity: Time Complexity: O(n), where n is the number of nodes in the linked list, as we iterate through the list once. Space Complexity: O(1), as we only use a few extra pointers.","title":"Explanation"},{"location":"same_tree/","text":"59. Same Tree Problem Statement Given the roots of two binary trees p and q , return true if they are the same tree, and false otherwise. Two binary trees are considered the same if they are structurally identical, and the nodes have the same value. Example 1: Input: p = [1,2,3], q = [1,2,3] Output: true Example 2: Input: p = [1,2], q = [1,null,2] Output: false Example 3: Input: p = [1,2,1], q = [1,1,2] Output: false Solution # Definition for a binary tree node. class TreeNode : def __init__ ( self , val = 0 , left = None , right = None ): self . val = val self . left = left self . right = right class Solution : def isSameTree ( self , p : TreeNode , q : TreeNode ) -> bool : # Base Case 1: Both are None, they are the same if not p and not q : return True # Base Case 2: One is None and the other is not, they are different if not p or not q : return False # Base Case 3: Values are different, they are different if p . val != q . val : return False # Recursive Step: Check left subtrees and right subtrees return self . isSameTree ( p . left , q . left ) and self . isSameTree ( p . right , q . right ) Explanation This problem can be solved using a recursive approach, comparing the two trees node by node. Core Idea: Two binary trees are considered the same if: Both are empty ( None ). Both are non-empty, their root nodes have the same value, AND their left subtrees are the same, AND their right subtrees are the same. Recursive Approach: Base Case 1 (Both None ): If both p and q are None , it means we've reached the end of a branch in both trees simultaneously, and they are structurally identical at this point. Return True . Base Case 2 (One None , One Not): If one of p or q is None but the other is not, it means they are structurally different (one has a node where the other doesn't). Return False . Base Case 3 (Different Values): If both p and q are not None , but their val attributes are different, then the trees are not the same. Return False . Recursive Step: If none of the above base cases are met, it means p and q are both non- None and have the same value. Now, we need to recursively check if their left subtrees are the same AND if their right subtrees are the same. We use the logical and operator because both conditions must be true for the trees to be identical. Time and Space Complexity: Time Complexity: O(N), where N is the minimum number of nodes in the two trees. We visit each node at most once. Space Complexity: O(H) in the worst case, where H is the height of the tree, due to the recursion stack. In a skewed tree, H can be N (O(N)), and in a balanced tree, H is log N (O(log N)).","title":"Same Tree"},{"location":"same_tree/#59-same-tree","text":"","title":"59. Same Tree"},{"location":"same_tree/#problem-statement","text":"Given the roots of two binary trees p and q , return true if they are the same tree, and false otherwise. Two binary trees are considered the same if they are structurally identical, and the nodes have the same value. Example 1: Input: p = [1,2,3], q = [1,2,3] Output: true Example 2: Input: p = [1,2], q = [1,null,2] Output: false Example 3: Input: p = [1,2,1], q = [1,1,2] Output: false","title":"Problem Statement"},{"location":"same_tree/#solution","text":"# Definition for a binary tree node. class TreeNode : def __init__ ( self , val = 0 , left = None , right = None ): self . val = val self . left = left self . right = right class Solution : def isSameTree ( self , p : TreeNode , q : TreeNode ) -> bool : # Base Case 1: Both are None, they are the same if not p and not q : return True # Base Case 2: One is None and the other is not, they are different if not p or not q : return False # Base Case 3: Values are different, they are different if p . val != q . val : return False # Recursive Step: Check left subtrees and right subtrees return self . isSameTree ( p . left , q . left ) and self . isSameTree ( p . right , q . right )","title":"Solution"},{"location":"same_tree/#explanation","text":"This problem can be solved using a recursive approach, comparing the two trees node by node. Core Idea: Two binary trees are considered the same if: Both are empty ( None ). Both are non-empty, their root nodes have the same value, AND their left subtrees are the same, AND their right subtrees are the same. Recursive Approach: Base Case 1 (Both None ): If both p and q are None , it means we've reached the end of a branch in both trees simultaneously, and they are structurally identical at this point. Return True . Base Case 2 (One None , One Not): If one of p or q is None but the other is not, it means they are structurally different (one has a node where the other doesn't). Return False . Base Case 3 (Different Values): If both p and q are not None , but their val attributes are different, then the trees are not the same. Return False . Recursive Step: If none of the above base cases are met, it means p and q are both non- None and have the same value. Now, we need to recursively check if their left subtrees are the same AND if their right subtrees are the same. We use the logical and operator because both conditions must be true for the trees to be identical. Time and Space Complexity: Time Complexity: O(N), where N is the minimum number of nodes in the two trees. We visit each node at most once. Space Complexity: O(H) in the worst case, where H is the height of the tree, due to the recursion stack. In a skewed tree, H can be N (O(N)), and in a balanced tree, H is log N (O(log N)).","title":"Explanation"},{"location":"search_in_rotated_sorted_array/","text":"8. Search in Rotated Sorted Array Problem Statement There is an integer array nums sorted in ascending order (with distinct values). Prior to being passed to your function, nums is possibly rotated at an unknown pivot index k ( 1 <= k < nums.length ) such that the resulting array is [nums[k], nums[k+1], ..., nums[n-1], nums[0], nums[1], ..., nums[k-1]] (0-indexed). For example, [0,1,2,4,5,6,7] might be rotated at pivot index 3 and become [4,5,6,7,0,1,2] . Given the array nums after the possible rotation and an integer target , return the index of target if it is in nums , or -1 if it is not in nums . You must write an algorithm with O(log n) runtime complexity. Example 1: Input: nums = [4,5,6,7,0,1,2], target = 0 Output: 4 Example 2: Input: nums = [4,5,6,7,0,1,2], target = 3 Output: -1 Example 3: Input: nums = [1], target = 0 Output: -1 Solution class Solution : def search ( self , nums : list [ int ], target : int ) -> int : left , right = 0 , len ( nums ) - 1 while left <= right : mid = ( left + right ) // 2 if nums [ mid ] == target : return mid # Check if the left half is sorted if nums [ left ] <= nums [ mid ]: if nums [ left ] <= target < nums [ mid ]: right = mid - 1 else : left = mid + 1 # Otherwise, the right half is sorted else : if nums [ mid ] < target <= nums [ right ]: left = mid + 1 else : right = mid - 1 return - 1 Explanation This problem requires a modified binary search. In each step, we need to determine which half of the array is sorted and if the target lies within that sorted half. We calculate the middle index mid . If nums[mid] is the target , we return mid . We check if the left half (from left to mid ) is sorted. This is true if nums[left] <= nums[mid] . If the left half is sorted, we check if the target is within the range [nums[left], nums[mid]) . If yes, we search in the left half. Otherwise, we search in the right half. If the left half is not sorted, it means the right half (from mid to right ) must be sorted. We check if the target is within the range (nums[mid], nums[right]] . If yes, we search in the right half. Otherwise, we search in the left half. This process continues until the target is found or the search space is exhausted. The time complexity is O(log n) due to the binary search, and the space complexity is O(1) .","title":"Search in Rotated Sorted Array"},{"location":"search_in_rotated_sorted_array/#8-search-in-rotated-sorted-array","text":"","title":"8. Search in Rotated Sorted Array"},{"location":"search_in_rotated_sorted_array/#problem-statement","text":"There is an integer array nums sorted in ascending order (with distinct values). Prior to being passed to your function, nums is possibly rotated at an unknown pivot index k ( 1 <= k < nums.length ) such that the resulting array is [nums[k], nums[k+1], ..., nums[n-1], nums[0], nums[1], ..., nums[k-1]] (0-indexed). For example, [0,1,2,4,5,6,7] might be rotated at pivot index 3 and become [4,5,6,7,0,1,2] . Given the array nums after the possible rotation and an integer target , return the index of target if it is in nums , or -1 if it is not in nums . You must write an algorithm with O(log n) runtime complexity. Example 1: Input: nums = [4,5,6,7,0,1,2], target = 0 Output: 4 Example 2: Input: nums = [4,5,6,7,0,1,2], target = 3 Output: -1 Example 3: Input: nums = [1], target = 0 Output: -1","title":"Problem Statement"},{"location":"search_in_rotated_sorted_array/#solution","text":"class Solution : def search ( self , nums : list [ int ], target : int ) -> int : left , right = 0 , len ( nums ) - 1 while left <= right : mid = ( left + right ) // 2 if nums [ mid ] == target : return mid # Check if the left half is sorted if nums [ left ] <= nums [ mid ]: if nums [ left ] <= target < nums [ mid ]: right = mid - 1 else : left = mid + 1 # Otherwise, the right half is sorted else : if nums [ mid ] < target <= nums [ right ]: left = mid + 1 else : right = mid - 1 return - 1","title":"Solution"},{"location":"search_in_rotated_sorted_array/#explanation","text":"This problem requires a modified binary search. In each step, we need to determine which half of the array is sorted and if the target lies within that sorted half. We calculate the middle index mid . If nums[mid] is the target , we return mid . We check if the left half (from left to mid ) is sorted. This is true if nums[left] <= nums[mid] . If the left half is sorted, we check if the target is within the range [nums[left], nums[mid]) . If yes, we search in the left half. Otherwise, we search in the right half. If the left half is not sorted, it means the right half (from mid to right ) must be sorted. We check if the target is within the range (nums[mid], nums[right]] . If yes, we search in the right half. Otherwise, we search in the left half. This process continues until the target is found or the search space is exhausted. The time complexity is O(log n) due to the binary search, and the space complexity is O(1) .","title":"Explanation"},{"location":"subtree_of_another_tree/","text":"60. Subtree of Another Tree Problem Statement Given the roots of two binary trees root and subRoot , return true if there is a subtree of root with the same structure and node values of subRoot and false otherwise. A subtree of a binary tree tree is a tree that consists of a node in tree and all of this node's descendants. The tree tree could also be considered as a subtree of itself. Example 1: Input: root = [3,4,5,1,2], subRoot = [4,1,2] Output: true Example 2: Input: root = [3,4,5,1,2,null,null,null,null,0], subRoot = [4,1,2] Output: false Solution # Definition for a binary tree node. class TreeNode : def __init__ ( self , val = 0 , left = None , right = None ): self . val = val self . left = left self . right = right class Solution : def isSubtree ( self , root : TreeNode , subRoot : TreeNode ) -> bool : if not root : return False if not subRoot : return True # An empty tree is always a subtree # Check if the current root and subRoot are the same tree if self . isSameTree ( root , subRoot ): return True # Otherwise, check if subRoot is a subtree of root.left or root.right return self . isSubtree ( root . left , subRoot ) or self . isSubtree ( root . right , subRoot ) def isSameTree ( self , p : TreeNode , q : TreeNode ) -> bool : # Base Case 1: Both are None, they are the same if not p and not q : return True # Base Case 2: One is None and the other is not, they are different if not p or not q : return False # Base Case 3: Values are different, they are different if p . val != q . val : return False # Recursive Step: Check left subtrees and right subtrees return self . isSameTree ( p . left , q . left ) and self . isSameTree ( p . right , q . right ) Explanation This problem combines two concepts: checking if two trees are identical and traversing a tree to find a match. Core Idea: We need to check if subRoot is identical to root , or if subRoot is identical to any of root 's subtrees (left or right). Recursive Approach: isSubtree(root, subRoot) Function: Base Case 1 ( root is None ): If the root of the main tree is None , then subRoot cannot be a subtree (unless subRoot is also None , which is handled by the next base case). So, return False . Base Case 2 ( subRoot is None ): If subRoot is None , an empty tree is considered a subtree of any tree. Return True . Check for Identity: First, we check if the current root and subRoot are exactly the same tree using a helper function isSameTree . If they are, we've found our subtree, so return True . Recurse on Subtrees: If they are not the same, we recursively check if subRoot is a subtree of root.left OR root.right . The or condition is important because subRoot could be found in either branch. isSameTree(p, q) Helper Function: This is a standard function to check if two binary trees are identical (same structure and same values). It has the following logic: If both p and q are None , return True . If one is None and the other is not, return False . If their values are different, return False . Otherwise, recursively check if their left children are the same AND their right children are the same. Time and Space Complexity: Time Complexity: O(M * N), where M is the number of nodes in root and N is the number of nodes in subRoot . In the worst case, for each node in root , we might perform a isSameTree comparison which takes O(N) time. Space Complexity: O(H_root + H_subRoot) in the worst case, where H is the height of the respective trees, due to the recursion stack.","title":"Subtree of Another Tree"},{"location":"subtree_of_another_tree/#60-subtree-of-another-tree","text":"","title":"60. Subtree of Another Tree"},{"location":"subtree_of_another_tree/#problem-statement","text":"Given the roots of two binary trees root and subRoot , return true if there is a subtree of root with the same structure and node values of subRoot and false otherwise. A subtree of a binary tree tree is a tree that consists of a node in tree and all of this node's descendants. The tree tree could also be considered as a subtree of itself. Example 1: Input: root = [3,4,5,1,2], subRoot = [4,1,2] Output: true Example 2: Input: root = [3,4,5,1,2,null,null,null,null,0], subRoot = [4,1,2] Output: false","title":"Problem Statement"},{"location":"subtree_of_another_tree/#solution","text":"# Definition for a binary tree node. class TreeNode : def __init__ ( self , val = 0 , left = None , right = None ): self . val = val self . left = left self . right = right class Solution : def isSubtree ( self , root : TreeNode , subRoot : TreeNode ) -> bool : if not root : return False if not subRoot : return True # An empty tree is always a subtree # Check if the current root and subRoot are the same tree if self . isSameTree ( root , subRoot ): return True # Otherwise, check if subRoot is a subtree of root.left or root.right return self . isSubtree ( root . left , subRoot ) or self . isSubtree ( root . right , subRoot ) def isSameTree ( self , p : TreeNode , q : TreeNode ) -> bool : # Base Case 1: Both are None, they are the same if not p and not q : return True # Base Case 2: One is None and the other is not, they are different if not p or not q : return False # Base Case 3: Values are different, they are different if p . val != q . val : return False # Recursive Step: Check left subtrees and right subtrees return self . isSameTree ( p . left , q . left ) and self . isSameTree ( p . right , q . right )","title":"Solution"},{"location":"subtree_of_another_tree/#explanation","text":"This problem combines two concepts: checking if two trees are identical and traversing a tree to find a match. Core Idea: We need to check if subRoot is identical to root , or if subRoot is identical to any of root 's subtrees (left or right). Recursive Approach: isSubtree(root, subRoot) Function: Base Case 1 ( root is None ): If the root of the main tree is None , then subRoot cannot be a subtree (unless subRoot is also None , which is handled by the next base case). So, return False . Base Case 2 ( subRoot is None ): If subRoot is None , an empty tree is considered a subtree of any tree. Return True . Check for Identity: First, we check if the current root and subRoot are exactly the same tree using a helper function isSameTree . If they are, we've found our subtree, so return True . Recurse on Subtrees: If they are not the same, we recursively check if subRoot is a subtree of root.left OR root.right . The or condition is important because subRoot could be found in either branch. isSameTree(p, q) Helper Function: This is a standard function to check if two binary trees are identical (same structure and same values). It has the following logic: If both p and q are None , return True . If one is None and the other is not, return False . If their values are different, return False . Otherwise, recursively check if their left children are the same AND their right children are the same. Time and Space Complexity: Time Complexity: O(M * N), where M is the number of nodes in root and N is the number of nodes in subRoot . In the worst case, for each node in root , we might perform a isSameTree comparison which takes O(N) time. Space Complexity: O(H_root + H_subRoot) in the worst case, where H is the height of the respective trees, due to the recursion stack.","title":"Explanation"},{"location":"sum_of_two_integers/","text":"11. Sum of Two Integers Problem Statement Given two integers a and b , return the sum of the two integers without using the operators + and - . Example 1: Input: a = 1, b = 2 Output: 3 Example 2: Input: a = 2, b = 3 Output: 5 Solution class Solution : def getSum ( self , a : int , b : int ) -> int : # 32-bit mask in hexadecimal mask = 0xffffffff # In Python, integers have unlimited precision, so we need to handle # negative numbers and overflow manually by using a mask. while ( b & mask ) > 0 : carry = ( a & b ) << 1 a = a ^ b b = carry # If the result is negative, it will be stored in two's complement # format. We need to convert it back to a standard negative integer. return ( a & mask ) if b > 0 else a Explanation This problem requires us to implement addition using bitwise operations. The core idea is to simulate the way a computer's hardware adder works. We use two main bitwise operators: XOR ( ^ ): This gives the sum without considering the carry. For example, 1 ^ 1 = 0 , 1 ^ 0 = 1 . AND ( & ) and Left Shift ( << ): This combination calculates the carry. (a & b) finds the bits where both a and b are 1, which is where a carry is generated. << 1 shifts this carry to the next significant bit position. The algorithm works as follows: Calculate the sum without carry ( a ^ b ). Calculate the carry ( (a & b) << 1 ). The new a becomes the sum from step 1, and the new b becomes the carry from step 2. We repeat this process until there are no more carries ( b becomes 0). Handling Python's Integers: Python's integers can be arbitrarily large, which can cause issues with negative numbers in bitwise operations. We use a mask ( 0xffffffff for 32-bit integers) to ensure the operations behave as they would on fixed-size integers, correctly handling overflow and two's complement for negative numbers.","title":"Sum of Two Integers"},{"location":"sum_of_two_integers/#11-sum-of-two-integers","text":"","title":"11. Sum of Two Integers"},{"location":"sum_of_two_integers/#problem-statement","text":"Given two integers a and b , return the sum of the two integers without using the operators + and - . Example 1: Input: a = 1, b = 2 Output: 3 Example 2: Input: a = 2, b = 3 Output: 5","title":"Problem Statement"},{"location":"sum_of_two_integers/#solution","text":"class Solution : def getSum ( self , a : int , b : int ) -> int : # 32-bit mask in hexadecimal mask = 0xffffffff # In Python, integers have unlimited precision, so we need to handle # negative numbers and overflow manually by using a mask. while ( b & mask ) > 0 : carry = ( a & b ) << 1 a = a ^ b b = carry # If the result is negative, it will be stored in two's complement # format. We need to convert it back to a standard negative integer. return ( a & mask ) if b > 0 else a","title":"Solution"},{"location":"sum_of_two_integers/#explanation","text":"This problem requires us to implement addition using bitwise operations. The core idea is to simulate the way a computer's hardware adder works. We use two main bitwise operators: XOR ( ^ ): This gives the sum without considering the carry. For example, 1 ^ 1 = 0 , 1 ^ 0 = 1 . AND ( & ) and Left Shift ( << ): This combination calculates the carry. (a & b) finds the bits where both a and b are 1, which is where a carry is generated. << 1 shifts this carry to the next significant bit position. The algorithm works as follows: Calculate the sum without carry ( a ^ b ). Calculate the carry ( (a & b) << 1 ). The new a becomes the sum from step 1, and the new b becomes the carry from step 2. We repeat this process until there are no more carries ( b becomes 0). Handling Python's Integers: Python's integers can be arbitrarily large, which can cause issues with negative numbers in bitwise operations. We use a mask ( 0xffffffff for 32-bit integers) to ensure the operations behave as they would on fixed-size integers, correctly handling overflow and two's complement for negative numbers.","title":"Explanation"},{"location":"swap_nodes_in_pairs/","text":"48. Swap Nodes in Pairs Problem Statement Given a head of a linked list, swap every two adjacent nodes and return its head. You must solve the problem without modifying the values in the list's nodes (i.e., only changes to the nodes themselves are allowed). Example 1: Input: head = [1,2,3,4] Output: [2,1,4,3] Example 2: Input: head = [] Output: [] Example 3: Input: head = [1] Output: [1] Solution # Definition for singly-linked list. class ListNode : def __init__ ( self , val = 0 , next = None ): self . val = val self . next = next class Solution : def swapPairs ( self , head : ListNode ) -> ListNode : # Create a dummy node to handle edge cases (e.g., swapping the head) dummy = ListNode ( 0 ) dummy . next = head prev = dummy while prev . next and prev . next . next : # Nodes to be swapped first = prev . next second = prev . next . next # Swapping logic first . next = second . next second . next = first prev . next = second # Move prev pointer for next iteration prev = first return dummy . next Explanation This problem involves modifying linked list pointers to swap adjacent nodes. An iterative approach is generally preferred. Core Idea: We need to keep track of the node before the pair we are about to swap, as its next pointer will need to be updated to point to the second node of the swapped pair. Dummy Node: We use a dummy node to simplify handling the head of the list, especially if the original head needs to be swapped. prev Pointer: We initialize a prev pointer to the dummy node. This prev pointer will always point to the node before the current pair we are considering for swapping. Iteration: We iterate as long as there is a pair to swap ( prev.next and prev.next.next are not None ). Swapping Logic: Inside the loop: first points to the first node of the pair ( prev.next ). second points to the second node of the pair ( prev.next.next ). first.next = second.next : The first node (which will become the second in the swapped pair) should now point to the node that was originally after second . second.next = first : The second node (which will become the first in the swapped pair) should now point to the first node. prev.next = second : The node before the pair ( prev ) should now point to the second node (which is now the new first node of the swapped pair). Advance prev : After swapping, prev is moved to first (the original first node, which is now the second node of the swapped pair) to prepare for the next pair. Return Result: dummy.next will be the head of the modified list. Time and Space Complexity: Time Complexity: O(n), where n is the number of nodes in the linked list, as we iterate through the list once. Space Complexity: O(1), as we only use a few extra pointers.","title":"Swap Nodes in Pairs"},{"location":"swap_nodes_in_pairs/#48-swap-nodes-in-pairs","text":"","title":"48. Swap Nodes in Pairs"},{"location":"swap_nodes_in_pairs/#problem-statement","text":"Given a head of a linked list, swap every two adjacent nodes and return its head. You must solve the problem without modifying the values in the list's nodes (i.e., only changes to the nodes themselves are allowed). Example 1: Input: head = [1,2,3,4] Output: [2,1,4,3] Example 2: Input: head = [] Output: [] Example 3: Input: head = [1] Output: [1]","title":"Problem Statement"},{"location":"swap_nodes_in_pairs/#solution","text":"# Definition for singly-linked list. class ListNode : def __init__ ( self , val = 0 , next = None ): self . val = val self . next = next class Solution : def swapPairs ( self , head : ListNode ) -> ListNode : # Create a dummy node to handle edge cases (e.g., swapping the head) dummy = ListNode ( 0 ) dummy . next = head prev = dummy while prev . next and prev . next . next : # Nodes to be swapped first = prev . next second = prev . next . next # Swapping logic first . next = second . next second . next = first prev . next = second # Move prev pointer for next iteration prev = first return dummy . next","title":"Solution"},{"location":"swap_nodes_in_pairs/#explanation","text":"This problem involves modifying linked list pointers to swap adjacent nodes. An iterative approach is generally preferred. Core Idea: We need to keep track of the node before the pair we are about to swap, as its next pointer will need to be updated to point to the second node of the swapped pair. Dummy Node: We use a dummy node to simplify handling the head of the list, especially if the original head needs to be swapped. prev Pointer: We initialize a prev pointer to the dummy node. This prev pointer will always point to the node before the current pair we are considering for swapping. Iteration: We iterate as long as there is a pair to swap ( prev.next and prev.next.next are not None ). Swapping Logic: Inside the loop: first points to the first node of the pair ( prev.next ). second points to the second node of the pair ( prev.next.next ). first.next = second.next : The first node (which will become the second in the swapped pair) should now point to the node that was originally after second . second.next = first : The second node (which will become the first in the swapped pair) should now point to the first node. prev.next = second : The node before the pair ( prev ) should now point to the second node (which is now the new first node of the swapped pair). Advance prev : After swapping, prev is moved to first (the original first node, which is now the second node of the swapped pair) to prepare for the next pair. Return Result: dummy.next will be the head of the modified list. Time and Space Complexity: Time Complexity: O(n), where n is the number of nodes in the linked list, as we iterate through the list once. Space Complexity: O(1), as we only use a few extra pointers.","title":"Explanation"},{"location":"unique_paths/","text":"25. Unique Paths Problem Statement There is a robot on an m x n grid. The robot is initially located at the top-left corner (i.e., grid[0][0] ). The robot tries to move to the bottom-right corner (i.e., grid[m - 1][n - 1] ). The robot can only move either down or right at any point in time. Given the two integers m and n , return the number of possible unique paths that the robot can take to reach the bottom-right corner . The test cases are generated so that the answer will be less than or equal to 2 * 10^9 . Example 1: Input: m = 3, n = 7 Output: 28 Example 2: Input: m = 3, n = 2 Output: 3 Explanation: From the top-left corner, there are a total of 3 ways to reach the bottom-right corner: 1. Right -> Down -> Down 2. Down -> Down -> Right 3. Down -> Right -> Down Solution import math class Solution : def uniquePaths ( self , m : int , n : int ) -> int : # This is a combinatorial problem. # To reach the bottom-right corner, the robot must make a total of # (m - 1) down moves and (n - 1) right moves. # The total number of moves is (m - 1) + (n - 1) = m + n - 2. # The problem is to choose which of these total moves are \"down\" moves # (the rest will be \"right\" moves). # This is equivalent to \"(m + n - 2) choose (m - 1)\". total_moves = m + n - 2 down_moves = m - 1 # Using the formula for combinations: C(n, k) = n! / (k! * (n-k)!) return math . comb ( total_moves , down_moves ) Explanation This problem can be solved using dynamic programming, but a more efficient solution comes from combinatorics. To get from the top-left corner (0, 0) to the bottom-right corner (m-1, n-1) , the robot must make a total of (m-1) moves down and (n-1) moves right. The total number of moves is (m-1) + (n-1) = m + n - 2 . The problem then becomes: out of these m + n - 2 total moves, how many ways can we choose m-1 of them to be \"down\" moves? (The remaining n-1 moves will automatically be \"right\" moves). This is a classic combination problem, often denoted as \"N choose K\" or C(N, K) . Here, N = m + n - 2 and K = m - 1 (or n - 1 , the result is the same). The formula for combinations is C(N, K) = N! / (K! * (N-K)!) . Python's math.comb(n, k) function calculates this directly, providing a very concise and efficient solution. Dynamic Programming Approach (for comparison): You could also solve this with a 2D DP grid where dp[i][j] is the number of paths to cell (i, j) . The recurrence would be dp[i][j] = dp[i-1][j] + dp[i][j-1] , as you can only arrive from the cell above or the cell to the left. This would have O(m*n) time and space complexity.","title":"Unique Paths"},{"location":"unique_paths/#25-unique-paths","text":"","title":"25. Unique Paths"},{"location":"unique_paths/#problem-statement","text":"There is a robot on an m x n grid. The robot is initially located at the top-left corner (i.e., grid[0][0] ). The robot tries to move to the bottom-right corner (i.e., grid[m - 1][n - 1] ). The robot can only move either down or right at any point in time. Given the two integers m and n , return the number of possible unique paths that the robot can take to reach the bottom-right corner . The test cases are generated so that the answer will be less than or equal to 2 * 10^9 . Example 1: Input: m = 3, n = 7 Output: 28 Example 2: Input: m = 3, n = 2 Output: 3 Explanation: From the top-left corner, there are a total of 3 ways to reach the bottom-right corner: 1. Right -> Down -> Down 2. Down -> Down -> Right 3. Down -> Right -> Down","title":"Problem Statement"},{"location":"unique_paths/#solution","text":"import math class Solution : def uniquePaths ( self , m : int , n : int ) -> int : # This is a combinatorial problem. # To reach the bottom-right corner, the robot must make a total of # (m - 1) down moves and (n - 1) right moves. # The total number of moves is (m - 1) + (n - 1) = m + n - 2. # The problem is to choose which of these total moves are \"down\" moves # (the rest will be \"right\" moves). # This is equivalent to \"(m + n - 2) choose (m - 1)\". total_moves = m + n - 2 down_moves = m - 1 # Using the formula for combinations: C(n, k) = n! / (k! * (n-k)!) return math . comb ( total_moves , down_moves )","title":"Solution"},{"location":"unique_paths/#explanation","text":"This problem can be solved using dynamic programming, but a more efficient solution comes from combinatorics. To get from the top-left corner (0, 0) to the bottom-right corner (m-1, n-1) , the robot must make a total of (m-1) moves down and (n-1) moves right. The total number of moves is (m-1) + (n-1) = m + n - 2 . The problem then becomes: out of these m + n - 2 total moves, how many ways can we choose m-1 of them to be \"down\" moves? (The remaining n-1 moves will automatically be \"right\" moves). This is a classic combination problem, often denoted as \"N choose K\" or C(N, K) . Here, N = m + n - 2 and K = m - 1 (or n - 1 , the result is the same). The formula for combinations is C(N, K) = N! / (K! * (N-K)!) . Python's math.comb(n, k) function calculates this directly, providing a very concise and efficient solution. Dynamic Programming Approach (for comparison): You could also solve this with a 2D DP grid where dp[i][j] is the number of paths to cell (i, j) . The recurrence would be dp[i][j] = dp[i-1][j] + dp[i][j-1] , as you can only arrive from the cell above or the cell to the left. This would have O(m*n) time and space complexity.","title":"Explanation"},{"location":"valid_anagram/","text":"36. Valid Anagram Problem Statement Given two strings s and t , return true if t is an anagram of s , and false otherwise. An Anagram is a word or phrase formed by rearranging the letters of a different word or phrase, typically using all the original letters exactly once. Example 1: Input: s = \"anagram\", t = \"nagaram\" Output: true Example 2: Input: s = \"rat\", t = \"car\" Output: false Solution from collections import Counter class Solution : def isAnagram ( self , s : str , t : str ) -> bool : if len ( s ) != len ( t ): return False # Use Counter to get frequency maps of characters count_s = Counter ( s ) count_t = Counter ( t ) # Compare the frequency maps return count_s == count_t Explanation An anagram is formed by rearranging the letters of another word or phrase. This implies two conditions: Both strings must have the same length. Both strings must contain the same characters with the same frequencies. Approach using Hash Maps (Counters): Length Check: First, we check if the lengths of s and t are different. If they are, they cannot be anagrams, so we return False . Frequency Counting: We use collections.Counter (which is a specialized dictionary subclass) to count the frequency of each character in both strings s and t . Comparison: Finally, we compare the two Counter objects. If they are equal, it means both strings have the same characters with the same frequencies, and thus t is an anagram of s . Otherwise, it's not. This approach is efficient because Counter builds the frequency maps in O(n) time (where n is the length of the string), and comparing two Counter objects also takes O(alphabet_size) time. So, the overall time complexity is O(n). The space complexity is O(alphabet_size) for storing the character counts. Alternative (Sorting): Another simple approach is to sort both strings and then compare them. If they are anagrams, their sorted versions will be identical. class Solution : def isAnagram_sort ( self , s : str , t : str ) -> bool : if len ( s ) != len ( t ): return False return sorted ( s ) == sorted ( t ) This sorting approach has a time complexity of O(n log n) due to the sorting, and space complexity depends on the sorting algorithm (typically O(n) or O(log n)). The Counter approach is generally preferred for better performance.","title":"Valid Anagram"},{"location":"valid_anagram/#36-valid-anagram","text":"","title":"36. Valid Anagram"},{"location":"valid_anagram/#problem-statement","text":"Given two strings s and t , return true if t is an anagram of s , and false otherwise. An Anagram is a word or phrase formed by rearranging the letters of a different word or phrase, typically using all the original letters exactly once. Example 1: Input: s = \"anagram\", t = \"nagaram\" Output: true Example 2: Input: s = \"rat\", t = \"car\" Output: false","title":"Problem Statement"},{"location":"valid_anagram/#solution","text":"from collections import Counter class Solution : def isAnagram ( self , s : str , t : str ) -> bool : if len ( s ) != len ( t ): return False # Use Counter to get frequency maps of characters count_s = Counter ( s ) count_t = Counter ( t ) # Compare the frequency maps return count_s == count_t","title":"Solution"},{"location":"valid_anagram/#explanation","text":"An anagram is formed by rearranging the letters of another word or phrase. This implies two conditions: Both strings must have the same length. Both strings must contain the same characters with the same frequencies. Approach using Hash Maps (Counters): Length Check: First, we check if the lengths of s and t are different. If they are, they cannot be anagrams, so we return False . Frequency Counting: We use collections.Counter (which is a specialized dictionary subclass) to count the frequency of each character in both strings s and t . Comparison: Finally, we compare the two Counter objects. If they are equal, it means both strings have the same characters with the same frequencies, and thus t is an anagram of s . Otherwise, it's not. This approach is efficient because Counter builds the frequency maps in O(n) time (where n is the length of the string), and comparing two Counter objects also takes O(alphabet_size) time. So, the overall time complexity is O(n). The space complexity is O(alphabet_size) for storing the character counts. Alternative (Sorting): Another simple approach is to sort both strings and then compare them. If they are anagrams, their sorted versions will be identical. class Solution : def isAnagram_sort ( self , s : str , t : str ) -> bool : if len ( s ) != len ( t ): return False return sorted ( s ) == sorted ( t ) This sorting approach has a time complexity of O(n log n) due to the sorting, and space complexity depends on the sorting algorithm (typically O(n) or O(log n)). The Counter approach is generally preferred for better performance.","title":"Explanation"},{"location":"valid_palindrome/","text":"39. Valid Palindrome Problem Statement A phrase is a palindrome if, after converting all uppercase letters into lowercase letters and removing all non-alphanumeric characters, it reads the same forward and backward. Alphanumeric characters include letters and numbers. Given a string s , return true if it is a palindrome, or false otherwise . Example 1: Input: s = \"A man, a plan, a canal: Panama\" Output: true Explanation: \"amanaplanacanalpanama\" is a palindrome. Example 2: Input: s = \"race a car\" Output: false Explanation: \"raceacar\" is not a palindrome. Example 3: Input: s = \" \" Output: true Explanation: s is an empty string \"\". After removing non-alphanumeric characters and converting to lowercase, it becomes an empty string. Since an empty string reads the same forward and backward, it is a palindrome. Solution class Solution : def isPalindrome ( self , s : str ) -> bool : # Create a new string with only alphanumeric characters, converted to lowercase filtered_chars = [ char . lower () for char in s if char . isalnum () ] filtered_s = \"\" . join ( filtered_chars ) # Check if the filtered string is a palindrome return filtered_s == filtered_s [:: - 1 ] Explanation This problem requires us to first preprocess the input string and then check if the processed string is a palindrome. Preprocessing Steps: Filter Alphanumeric Characters: Iterate through the input string s and keep only characters that are alphanumeric (letters or numbers). We can use the isalnum() string method for this. Convert to Lowercase: Convert all the filtered characters to lowercase. This ensures that case doesn't affect the palindrome check (e.g., 'A' and 'a' are treated the same). Join Characters: Join the filtered and lowercased characters back into a new string. Palindrome Check: Once we have the filtered_s string, we can check if it's a palindrome by comparing it to its reverse. In Python, [::-1] is a convenient way to reverse a string. Time and Space Complexity: Time Complexity: O(n), where n is the length of the input string s . We iterate through the string once to filter and convert characters, and then reversing and comparing the string also takes linear time. Space Complexity: O(n) for storing the filtered_s string. In the worst case (e.g., all characters are alphanumeric), the new string will have the same length as the original. Alternative (Two Pointers - In-place): An alternative approach is to use two pointers, one at the beginning and one at the end of the original string. We move the pointers inward, skipping non-alphanumeric characters and comparing the lowercase versions of the alphanumeric characters. This approach can achieve O(1) space complexity (excluding the output string if you were to build one).","title":"Valid Palindrome"},{"location":"valid_palindrome/#39-valid-palindrome","text":"","title":"39. Valid Palindrome"},{"location":"valid_palindrome/#problem-statement","text":"A phrase is a palindrome if, after converting all uppercase letters into lowercase letters and removing all non-alphanumeric characters, it reads the same forward and backward. Alphanumeric characters include letters and numbers. Given a string s , return true if it is a palindrome, or false otherwise . Example 1: Input: s = \"A man, a plan, a canal: Panama\" Output: true Explanation: \"amanaplanacanalpanama\" is a palindrome. Example 2: Input: s = \"race a car\" Output: false Explanation: \"raceacar\" is not a palindrome. Example 3: Input: s = \" \" Output: true Explanation: s is an empty string \"\". After removing non-alphanumeric characters and converting to lowercase, it becomes an empty string. Since an empty string reads the same forward and backward, it is a palindrome.","title":"Problem Statement"},{"location":"valid_palindrome/#solution","text":"class Solution : def isPalindrome ( self , s : str ) -> bool : # Create a new string with only alphanumeric characters, converted to lowercase filtered_chars = [ char . lower () for char in s if char . isalnum () ] filtered_s = \"\" . join ( filtered_chars ) # Check if the filtered string is a palindrome return filtered_s == filtered_s [:: - 1 ]","title":"Solution"},{"location":"valid_palindrome/#explanation","text":"This problem requires us to first preprocess the input string and then check if the processed string is a palindrome. Preprocessing Steps: Filter Alphanumeric Characters: Iterate through the input string s and keep only characters that are alphanumeric (letters or numbers). We can use the isalnum() string method for this. Convert to Lowercase: Convert all the filtered characters to lowercase. This ensures that case doesn't affect the palindrome check (e.g., 'A' and 'a' are treated the same). Join Characters: Join the filtered and lowercased characters back into a new string. Palindrome Check: Once we have the filtered_s string, we can check if it's a palindrome by comparing it to its reverse. In Python, [::-1] is a convenient way to reverse a string. Time and Space Complexity: Time Complexity: O(n), where n is the length of the input string s . We iterate through the string once to filter and convert characters, and then reversing and comparing the string also takes linear time. Space Complexity: O(n) for storing the filtered_s string. In the worst case (e.g., all characters are alphanumeric), the new string will have the same length as the original. Alternative (Two Pointers - In-place): An alternative approach is to use two pointers, one at the beginning and one at the end of the original string. We move the pointers inward, skipping non-alphanumeric characters and comparing the lowercase versions of the alphanumeric characters. This approach can achieve O(1) space complexity (excluding the output string if you were to build one).","title":"Explanation"},{"location":"valid_palindrome_ii/","text":"40. Valid Palindrome II Problem Statement Given a string s , return true if the s can be a palindrome after deleting at most one character from it. Example 1: Input: s = \"aba\" Output: true Example 2: Input: s = \"abca\" Output: true Explanation: You could delete the character 'c'. Example 3: Input: s = \"abc\" Output: false Solution class Solution : def validPalindrome ( self , s : str ) -> bool : left , right = 0 , len ( s ) - 1 while left < right : if s [ left ] != s [ right ]: # Mismatch found. Try deleting s[left] or s[right] # Check if s[left+1...right] is a palindrome # Check if s[left...right-1] is a palindrome return self . is_palindrome_range ( s , left + 1 , right ) or \\ self . is_palindrome_range ( s , left , right - 1 ) left += 1 right -= 1 return True def is_palindrome_range ( self , s : str , left : int , right : int ) -> bool : while left < right : if s [ left ] != s [ right ]: return False left += 1 right -= 1 return True Explanation This problem extends the basic palindrome check. We are allowed to delete at most one character. The approach uses a two-pointer technique. Initial Two-Pointer Scan: We use two pointers, left starting at the beginning and right starting at the end of the string s . Mismatch Handling: We iterate inward as long as s[left] equals s[right] . If s[left] and s[right] are not equal, it means we've found a character that needs to be potentially deleted. At this point, we have two choices: Delete s[left] : Check if the substring s[left+1 ... right] is a palindrome. Delete s[right] : Check if the substring s[left ... right-1] is a palindrome. If either of these two resulting substrings is a palindrome, then the original string s can be made a palindrome by deleting at most one character, so we return True . is_palindrome_range Helper: A helper function is_palindrome_range(s, left, right) is used to check if a given substring (defined by left and right indices) is a palindrome. No Mismatch: If the while loop completes without finding any mismatches, it means the original string s is already a palindrome, so we return True . The time complexity is O(n) because in the worst case, we traverse the string once with the main loop, and then potentially twice more with the is_palindrome_range helper, each taking O(n) time. The space complexity is O(1).","title":"Valid Palindrome II"},{"location":"valid_palindrome_ii/#40-valid-palindrome-ii","text":"","title":"40. Valid Palindrome II"},{"location":"valid_palindrome_ii/#problem-statement","text":"Given a string s , return true if the s can be a palindrome after deleting at most one character from it. Example 1: Input: s = \"aba\" Output: true Example 2: Input: s = \"abca\" Output: true Explanation: You could delete the character 'c'. Example 3: Input: s = \"abc\" Output: false","title":"Problem Statement"},{"location":"valid_palindrome_ii/#solution","text":"class Solution : def validPalindrome ( self , s : str ) -> bool : left , right = 0 , len ( s ) - 1 while left < right : if s [ left ] != s [ right ]: # Mismatch found. Try deleting s[left] or s[right] # Check if s[left+1...right] is a palindrome # Check if s[left...right-1] is a palindrome return self . is_palindrome_range ( s , left + 1 , right ) or \\ self . is_palindrome_range ( s , left , right - 1 ) left += 1 right -= 1 return True def is_palindrome_range ( self , s : str , left : int , right : int ) -> bool : while left < right : if s [ left ] != s [ right ]: return False left += 1 right -= 1 return True","title":"Solution"},{"location":"valid_palindrome_ii/#explanation","text":"This problem extends the basic palindrome check. We are allowed to delete at most one character. The approach uses a two-pointer technique. Initial Two-Pointer Scan: We use two pointers, left starting at the beginning and right starting at the end of the string s . Mismatch Handling: We iterate inward as long as s[left] equals s[right] . If s[left] and s[right] are not equal, it means we've found a character that needs to be potentially deleted. At this point, we have two choices: Delete s[left] : Check if the substring s[left+1 ... right] is a palindrome. Delete s[right] : Check if the substring s[left ... right-1] is a palindrome. If either of these two resulting substrings is a palindrome, then the original string s can be made a palindrome by deleting at most one character, so we return True . is_palindrome_range Helper: A helper function is_palindrome_range(s, left, right) is used to check if a given substring (defined by left and right indices) is a palindrome. No Mismatch: If the while loop completes without finding any mismatches, it means the original string s is already a palindrome, so we return True . The time complexity is O(n) because in the worst case, we traverse the string once with the main loop, and then potentially twice more with the is_palindrome_range helper, each taking O(n) time. The space complexity is O(1).","title":"Explanation"},{"location":"valid_parentheses/","text":"38. Valid Parentheses Problem Statement Given a string s containing just the characters '(' , ')' , '{ ' , '}' , '[' , and ']' , determine if the input string is valid. An input string is valid if: Open brackets must be closed by the same type of open brackets. Open brackets must be closed in the correct order. Every close bracket has a corresponding open bracket of the same type. Example 1: Input: s = \"()\" Output: true Example 2: Input: s = \"()[]{}\" Output: true Example 3: Input: s = \"(]\" Output: false Solution class Solution : def isValid ( self , s : str ) -> bool : stack = [] # Map opening brackets to their corresponding closing brackets mapping = { \")\" : \"(\" , \"}\" : \"{\" , \"]\" : \"[\" } for char in s : if char in mapping . values (): # It's an opening bracket stack . append ( char ) elif char in mapping : # It's a closing bracket # If stack is empty or top of stack doesn't match if not stack or stack . pop () != mapping [ char ]: return False else : # Character is not a valid bracket return False # If the stack is empty, all brackets were matched return not stack Explanation This problem is a classic application of a stack data structure. The idea is to process the string character by character: Initialize a Stack: Create an empty stack to store opening brackets. Define Mapping: Create a dictionary or hash map that maps each closing bracket to its corresponding opening bracket (e.g., ')' -> '(' ). Algorithm: Iterate through each char in the input string s : If char is an opening bracket: Push it onto the stack. If char is a closing bracket: Check if the stack is empty. If it is, it means we encountered a closing bracket without a corresponding opening bracket, so the string is invalid (return False ). Pop the top element from the stack. This should be the most recently encountered opening bracket. Compare the popped opening bracket with the expected opening bracket for the current closing bracket (using our mapping ). If they don't match, the order is incorrect, so the string is invalid (return False ). If char is not a valid bracket: (Optional, depending on problem constraints, but good for robustness) return False . Final Check: After iterating through the entire string, if the stack is empty, it means all opening brackets have been correctly matched with their closing counterparts. If the stack is not empty, it means there are unmatched opening brackets, so the string is invalid. The time complexity is O(n) because we iterate through the string once. The space complexity is O(n) in the worst case (e.g., a string with all opening brackets) for the stack.","title":"Valid Parentheses"},{"location":"valid_parentheses/#38-valid-parentheses","text":"","title":"38. Valid Parentheses"},{"location":"valid_parentheses/#problem-statement","text":"Given a string s containing just the characters '(' , ')' , '{ ' , '}' , '[' , and ']' , determine if the input string is valid. An input string is valid if: Open brackets must be closed by the same type of open brackets. Open brackets must be closed in the correct order. Every close bracket has a corresponding open bracket of the same type. Example 1: Input: s = \"()\" Output: true Example 2: Input: s = \"()[]{}\" Output: true Example 3: Input: s = \"(]\" Output: false","title":"Problem Statement"},{"location":"valid_parentheses/#solution","text":"class Solution : def isValid ( self , s : str ) -> bool : stack = [] # Map opening brackets to their corresponding closing brackets mapping = { \")\" : \"(\" , \"}\" : \"{\" , \"]\" : \"[\" } for char in s : if char in mapping . values (): # It's an opening bracket stack . append ( char ) elif char in mapping : # It's a closing bracket # If stack is empty or top of stack doesn't match if not stack or stack . pop () != mapping [ char ]: return False else : # Character is not a valid bracket return False # If the stack is empty, all brackets were matched return not stack","title":"Solution"},{"location":"valid_parentheses/#explanation","text":"This problem is a classic application of a stack data structure. The idea is to process the string character by character: Initialize a Stack: Create an empty stack to store opening brackets. Define Mapping: Create a dictionary or hash map that maps each closing bracket to its corresponding opening bracket (e.g., ')' -> '(' ). Algorithm: Iterate through each char in the input string s : If char is an opening bracket: Push it onto the stack. If char is a closing bracket: Check if the stack is empty. If it is, it means we encountered a closing bracket without a corresponding opening bracket, so the string is invalid (return False ). Pop the top element from the stack. This should be the most recently encountered opening bracket. Compare the popped opening bracket with the expected opening bracket for the current closing bracket (using our mapping ). If they don't match, the order is incorrect, so the string is invalid (return False ). If char is not a valid bracket: (Optional, depending on problem constraints, but good for robustness) return False . Final Check: After iterating through the entire string, if the stack is empty, it means all opening brackets have been correctly matched with their closing counterparts. If the stack is not empty, it means there are unmatched opening brackets, so the string is invalid. The time complexity is O(n) because we iterate through the string once. The space complexity is O(n) in the worst case (e.g., a string with all opening brackets) for the stack.","title":"Explanation"},{"location":"validate_binary_search_tree/","text":"63. Validate Binary Search Tree Problem Statement Given the root of a binary tree, determine if it is a valid Binary Search Tree (BST). A valid BST is defined as follows: The left subtree of a node contains only nodes with keys less than the node's key. The right subtree of a node contains only nodes with keys greater than the node's key. Both the left and right subtrees must also be binary search trees. Example 1: Input: root = [2,1,3] Output: true Example 2: Input: root = [5,1,4,null,null,3,6] Output: false Explanation: The root node's value is 5 but its right child's value is 4. Solution # Definition for a binary tree node. class TreeNode : def __init__ ( self , val = 0 , left = None , right = None ): self . val = val self . left = left self . right = right class Solution : def isValidBST ( self , root : TreeNode ) -> bool : # Helper function with min_val and max_val bounds def validate ( node , min_val , max_val ): if not node : return True # Check if the current node's value is within the valid range if not ( min_val < node . val < max_val ): return False # Recursively validate left and right subtrees # For left subtree, max_val becomes node.val # For right subtree, min_val becomes node.val return ( validate ( node . left , min_val , node . val ) and validate ( node . right , node . val , max_val )) # Start validation with initial bounds of negative and positive infinity return validate ( root , float ( '-inf' ), float ( 'inf' )) Explanation To validate a Binary Search Tree (BST), it's not enough to just check if a node's left child is smaller and its right child is larger. We need to ensure that all nodes in the left subtree are smaller than the current node, and all nodes in the right subtree are larger than the current node. Core Idea: We can use a recursive approach that passes down a valid range ( min_val , max_val ) for each node. A node's value must be strictly within this range. Recursive validate Function: The validate function takes a node , a min_val , and a max_val as arguments. Base Case: If node is None , it's a valid empty subtree, so return True . Range Check: Check if node.val is strictly greater than min_val AND strictly less than max_val . If not, the BST property is violated, so return False . Recursive Calls: Left Subtree: Recursively call validate on node.left . The min_val for the left subtree remains the same, but the max_val becomes node.val (because all nodes in the left subtree must be less than the current node). Right Subtree: Recursively call validate on node.right . The max_val for the right subtree remains the same, but the min_val becomes node.val (because all nodes in the right subtree must be greater than the current node). Combine Results: The current node is valid only if both its left and right subtrees are also valid BSTs. So, we return the logical and of the two recursive calls. Initial Call: We start the validation from the root with min_val as negative infinity and max_val as positive infinity. Time and Space Complexity: Time Complexity: O(N), where N is the number of nodes in the binary tree. Each node is visited exactly once. Space Complexity: O(H) in the worst case, where H is the height of the tree, due to the recursion stack. In a skewed tree, H can be N (O(N)), and in a balanced tree, H is log N (O(log N)).","title":"Validate Binary Search Tree"},{"location":"validate_binary_search_tree/#63-validate-binary-search-tree","text":"","title":"63. Validate Binary Search Tree"},{"location":"validate_binary_search_tree/#problem-statement","text":"Given the root of a binary tree, determine if it is a valid Binary Search Tree (BST). A valid BST is defined as follows: The left subtree of a node contains only nodes with keys less than the node's key. The right subtree of a node contains only nodes with keys greater than the node's key. Both the left and right subtrees must also be binary search trees. Example 1: Input: root = [2,1,3] Output: true Example 2: Input: root = [5,1,4,null,null,3,6] Output: false Explanation: The root node's value is 5 but its right child's value is 4.","title":"Problem Statement"},{"location":"validate_binary_search_tree/#solution","text":"# Definition for a binary tree node. class TreeNode : def __init__ ( self , val = 0 , left = None , right = None ): self . val = val self . left = left self . right = right class Solution : def isValidBST ( self , root : TreeNode ) -> bool : # Helper function with min_val and max_val bounds def validate ( node , min_val , max_val ): if not node : return True # Check if the current node's value is within the valid range if not ( min_val < node . val < max_val ): return False # Recursively validate left and right subtrees # For left subtree, max_val becomes node.val # For right subtree, min_val becomes node.val return ( validate ( node . left , min_val , node . val ) and validate ( node . right , node . val , max_val )) # Start validation with initial bounds of negative and positive infinity return validate ( root , float ( '-inf' ), float ( 'inf' ))","title":"Solution"},{"location":"validate_binary_search_tree/#explanation","text":"To validate a Binary Search Tree (BST), it's not enough to just check if a node's left child is smaller and its right child is larger. We need to ensure that all nodes in the left subtree are smaller than the current node, and all nodes in the right subtree are larger than the current node. Core Idea: We can use a recursive approach that passes down a valid range ( min_val , max_val ) for each node. A node's value must be strictly within this range. Recursive validate Function: The validate function takes a node , a min_val , and a max_val as arguments. Base Case: If node is None , it's a valid empty subtree, so return True . Range Check: Check if node.val is strictly greater than min_val AND strictly less than max_val . If not, the BST property is violated, so return False . Recursive Calls: Left Subtree: Recursively call validate on node.left . The min_val for the left subtree remains the same, but the max_val becomes node.val (because all nodes in the left subtree must be less than the current node). Right Subtree: Recursively call validate on node.right . The max_val for the right subtree remains the same, but the min_val becomes node.val (because all nodes in the right subtree must be greater than the current node). Combine Results: The current node is valid only if both its left and right subtrees are also valid BSTs. So, we return the logical and of the two recursive calls. Initial Call: We start the validation from the root with min_val as negative infinity and max_val as positive infinity. Time and Space Complexity: Time Complexity: O(N), where N is the number of nodes in the binary tree. Each node is visited exactly once. Space Complexity: O(H) in the worst case, where H is the height of the tree, due to the recursion stack. In a skewed tree, H can be N (O(N)), and in a balanced tree, H is log N (O(log N)).","title":"Explanation"},{"location":"word_break/","text":"20. Word Break Problem Statement Given a string s and a dictionary of strings wordDict , return true if s can be segmented into a space-separated sequence of one or more dictionary words. Note that the same word in the dictionary may be reused multiple times in the segmentation. Example 1: Input: s = \"leetcode\", wordDict = [\"leet\",\"code\"] Output: true Explanation: Return true because \"leetcode\" can be segmented as \"leet code\". Example 2: Input: s = \"applepenapple\", wordDict = [\"apple\",\"pen\"] Output: true Explanation: Return true because \"applepenapple\" can be segmented as \"apple pen apple\". Note that you are allowed to reuse a dictionary word. Example 3: Input: s = \"catsandog\", wordDict = [\"cats\",\"dog\",\"sand\",\"and\",\"cat\"] Output: false Solution class Solution : def wordBreak ( self , s : str , wordDict : list [ str ]) -> bool : word_set = set ( wordDict ) n = len ( s ) # dp[i] will be true if s[0..i-1] can be segmented dp = [ False ] * ( n + 1 ) dp [ 0 ] = True # Base case: an empty string can always be segmented for i in range ( 1 , n + 1 ): for j in range ( i ): # Check if the substring s[j:i] is in the dictionary # and if the prefix s[0:j] is also breakable if dp [ j ] and s [ j : i ] in word_set : dp [ i ] = True break # Found a valid break, move to the next i return dp [ n ] Explanation This problem can be solved using dynamic programming. Let dp[i] be a boolean value indicating whether the prefix of s of length i ( s[0...i-1] ) can be segmented into words from the dictionary. Initialization: We create a dp array of size n+1 . dp[0] is set to True because an empty string can be considered segmented. DP Relation: We iterate from i = 1 to n . For each i , we check all possible split points j before it ( 0 <= j < i ). The prefix s[0...i-1] can be segmented if: The prefix s[0...j-1] can be segmented (i.e., dp[j] is True ). The remaining substring s[j...i-1] is a word in our dictionary. Optimization: We convert wordDict to a set for O(1) average time complexity lookups. Final Result: dp[n] will tell us if the entire string s can be segmented. The time complexity is O(n^2) due to the nested loops. The space complexity is O(n) for the dp array.","title":"Word Break"},{"location":"word_break/#20-word-break","text":"","title":"20. Word Break"},{"location":"word_break/#problem-statement","text":"Given a string s and a dictionary of strings wordDict , return true if s can be segmented into a space-separated sequence of one or more dictionary words. Note that the same word in the dictionary may be reused multiple times in the segmentation. Example 1: Input: s = \"leetcode\", wordDict = [\"leet\",\"code\"] Output: true Explanation: Return true because \"leetcode\" can be segmented as \"leet code\". Example 2: Input: s = \"applepenapple\", wordDict = [\"apple\",\"pen\"] Output: true Explanation: Return true because \"applepenapple\" can be segmented as \"apple pen apple\". Note that you are allowed to reuse a dictionary word. Example 3: Input: s = \"catsandog\", wordDict = [\"cats\",\"dog\",\"sand\",\"and\",\"cat\"] Output: false","title":"Problem Statement"},{"location":"word_break/#solution","text":"class Solution : def wordBreak ( self , s : str , wordDict : list [ str ]) -> bool : word_set = set ( wordDict ) n = len ( s ) # dp[i] will be true if s[0..i-1] can be segmented dp = [ False ] * ( n + 1 ) dp [ 0 ] = True # Base case: an empty string can always be segmented for i in range ( 1 , n + 1 ): for j in range ( i ): # Check if the substring s[j:i] is in the dictionary # and if the prefix s[0:j] is also breakable if dp [ j ] and s [ j : i ] in word_set : dp [ i ] = True break # Found a valid break, move to the next i return dp [ n ]","title":"Solution"},{"location":"word_break/#explanation","text":"This problem can be solved using dynamic programming. Let dp[i] be a boolean value indicating whether the prefix of s of length i ( s[0...i-1] ) can be segmented into words from the dictionary. Initialization: We create a dp array of size n+1 . dp[0] is set to True because an empty string can be considered segmented. DP Relation: We iterate from i = 1 to n . For each i , we check all possible split points j before it ( 0 <= j < i ). The prefix s[0...i-1] can be segmented if: The prefix s[0...j-1] can be segmented (i.e., dp[j] is True ). The remaining substring s[j...i-1] is a word in our dictionary. Optimization: We convert wordDict to a set for O(1) average time complexity lookups. Final Result: dp[n] will tell us if the entire string s can be segmented. The time complexity is O(n^2) due to the nested loops. The space complexity is O(n) for the dp array.","title":"Explanation"},{"location":"arrays_hashing/best_time_to_buy_and_sell_stock/","text":"2. Best Time to Buy and Sell Stock Problem Statement You are given an array prices where prices[i] is the price of a given stock on the i th day. You want to maximize your profit by choosing a single day to buy one stock and choosing a different day in the future to sell that stock. Return the maximum profit you can achieve from this transaction . If you cannot achieve any profit, return 0 . Example 1: Input: prices = [7,1,5,3,6,4] Output: 5 Explanation: Buy on day 2 (price = 1) and sell on day 5 (price = 6), profit = 6-1 = 5. Note that buying on day 2 and selling on day 1 is not allowed because you must buy before you sell. Example 2: Input: prices = [7,6,4,3,1] Output: 0 Explanation: In this case, no transactions are done and the max profit = 0. Solution class Solution : def maxProfit ( self , prices : list [ int ]) -> int : min_price = float ( 'inf' ) max_profit = 0 for price in prices : if price < min_price : min_price = price elif price - min_price > max_profit : max_profit = price - min_price return max_profit Explanation The solution iterates through the prices array, keeping track of the minimum price seen so far ( min_price ) and the maximum profit found ( max_profit ). For each price, we first check if it's a new minimum price. If it is, we update min_price . Otherwise, we calculate the potential profit by subtracting the min_price from the current price. If this potential profit is greater than our current max_profit , we update max_profit . This single-pass approach has a time complexity of O(n) and a space complexity of O(1).","title":"Best Time to Buy and Sell Stock"},{"location":"arrays_hashing/best_time_to_buy_and_sell_stock/#2-best-time-to-buy-and-sell-stock","text":"","title":"2. Best Time to Buy and Sell Stock"},{"location":"arrays_hashing/best_time_to_buy_and_sell_stock/#problem-statement","text":"You are given an array prices where prices[i] is the price of a given stock on the i th day. You want to maximize your profit by choosing a single day to buy one stock and choosing a different day in the future to sell that stock. Return the maximum profit you can achieve from this transaction . If you cannot achieve any profit, return 0 . Example 1: Input: prices = [7,1,5,3,6,4] Output: 5 Explanation: Buy on day 2 (price = 1) and sell on day 5 (price = 6), profit = 6-1 = 5. Note that buying on day 2 and selling on day 1 is not allowed because you must buy before you sell. Example 2: Input: prices = [7,6,4,3,1] Output: 0 Explanation: In this case, no transactions are done and the max profit = 0.","title":"Problem Statement"},{"location":"arrays_hashing/best_time_to_buy_and_sell_stock/#solution","text":"class Solution : def maxProfit ( self , prices : list [ int ]) -> int : min_price = float ( 'inf' ) max_profit = 0 for price in prices : if price < min_price : min_price = price elif price - min_price > max_profit : max_profit = price - min_price return max_profit","title":"Solution"},{"location":"arrays_hashing/best_time_to_buy_and_sell_stock/#explanation","text":"The solution iterates through the prices array, keeping track of the minimum price seen so far ( min_price ) and the maximum profit found ( max_profit ). For each price, we first check if it's a new minimum price. If it is, we update min_price . Otherwise, we calculate the potential profit by subtracting the min_price from the current price. If this potential profit is greater than our current max_profit , we update max_profit . This single-pass approach has a time complexity of O(n) and a space complexity of O(1).","title":"Explanation"},{"location":"arrays_hashing/two_sum/","text":"1. Two Sum Problem Statement Given an array of integers nums and an integer target , return indices of the two numbers such that they add up to target . You may assume that each input would have exactly one solution , and you may not use the same element twice. You can return the answer in any order. Example 1: Input: nums = [2,7,11,15], target = 9 Output: [0,1] Explanation: Because nums[0] + nums[1] == 9, we return [0, 1]. Example 2: Input: nums = [3,2,4], target = 6 Output: [1,2] Example 3: Input: nums = [3,3], target = 6 Output: [0,1] Solution class Solution : def twoSum ( self , nums : list [ int ], target : int ) -> list [ int ]: num_to_index = {} for i , num in enumerate ( nums ): complement = target - num if complement in num_to_index : return [ num_to_index [ complement ], i ] num_to_index [ num ] = i Explanation The solution uses a hash map (dictionary in Python) to store the numbers we've seen so far and their indices. We iterate through the nums array. For each number, we calculate its complement (the number that would add up to the target ). If the complement is already in our hash map, it means we've found our pair. We return the index of the complement (from the hash map) and the index of the current number. If the complement is not in the hash map, we add the current number and its index to the map and continue to the next number. This approach has a time complexity of O(n) because we iterate through the array once. The space complexity is also O(n) for the hash map.","title":"Two Sum"},{"location":"arrays_hashing/two_sum/#1-two-sum","text":"","title":"1. Two Sum"},{"location":"arrays_hashing/two_sum/#problem-statement","text":"Given an array of integers nums and an integer target , return indices of the two numbers such that they add up to target . You may assume that each input would have exactly one solution , and you may not use the same element twice. You can return the answer in any order. Example 1: Input: nums = [2,7,11,15], target = 9 Output: [0,1] Explanation: Because nums[0] + nums[1] == 9, we return [0, 1]. Example 2: Input: nums = [3,2,4], target = 6 Output: [1,2] Example 3: Input: nums = [3,3], target = 6 Output: [0,1]","title":"Problem Statement"},{"location":"arrays_hashing/two_sum/#solution","text":"class Solution : def twoSum ( self , nums : list [ int ], target : int ) -> list [ int ]: num_to_index = {} for i , num in enumerate ( nums ): complement = target - num if complement in num_to_index : return [ num_to_index [ complement ], i ] num_to_index [ num ] = i","title":"Solution"},{"location":"arrays_hashing/two_sum/#explanation","text":"The solution uses a hash map (dictionary in Python) to store the numbers we've seen so far and their indices. We iterate through the nums array. For each number, we calculate its complement (the number that would add up to the target ). If the complement is already in our hash map, it means we've found our pair. We return the index of the complement (from the hash map) and the index of the current number. If the complement is not in the hash map, we add the current number and its index to the map and continue to the next number. This approach has a time complexity of O(n) because we iterate through the array once. The space complexity is also O(n) for the hash map.","title":"Explanation"}]}